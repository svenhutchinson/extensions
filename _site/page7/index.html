<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <!-- Enable responsiveness on mobile devices-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Hyde &middot; A Jekyll theme, with instant search
    
  </title>

  <!-- CSS -->
  <link rel="stylesheet" href="/extensions/public/css/poole.css">
  <link rel="stylesheet" href="/extensions/public/css/syntax.css">
  <link rel="stylesheet" href="/extensions/public/css/hyde.css">
  <link rel="stylesheet" href="/extensions/public/css/algolia.css">
  <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=PT+Sans:400,400italic,700|Abril+Fatface">

  <!-- Icons -->
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/extensions/public/apple-touch-icon-144-precomposed.png">
                                 <link rel="shortcut icon" href="/extensions/public/favicon.ico">

  <!-- RSS -->
  <link rel="alternate" type="application/rss+xml" title="RSS" href="/atom.xml">
</head>


  <body class="theme-base-09">

    <div class="sidebar">
  <div class="container sidebar-sticky">
    <div class="sidebar-about">
      <h1>
        <a href="/extensions/">
          Hyde
        </a>
      </h1>
      <p class="lead">The popular <a href="http://hyde.getpoole.com/" target="_blank">Hyde theme</a> for <a href="http://jekyllrb.com" target="_blank">Jekyll</a>, now with instant-search capabilities. Made by <a href="https://twitter.com/mdo" target="_blank">@mdo</a> and <a href="https://www.algolia.com/" target="_blank">Algolia</a></p>
    </div>

    <input type="text" class="algolia__input js-algolia__input" autocomplete="off" name="query" placeholder="Search in this site..." />

    <nav class="sidebar-nav">
      <a class="sidebar-nav-item" href="/extensions/">Home</a>

      

      
      
        
          
        
      
        
          
          <a class="sidebar-nav-item" href="/extensions/about/">About</a>
          
        
      
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      
        
          
        
      

      <a class="sidebar-nav-item" href="https://github.com/svenhutchinson/extensions">GitHub project</a>
      <span class="sidebar-nav-item">Currently v2.1.0</span>
    </nav>

    <p>&copy; 2016. All rights reserved.</p>
  </div>
</div>


    <div class="content container">
      <div class="algolia__initial-content js-algolia__initial-content"><div class="posts">
  
  <div class="post">
    <h1 class="post-title">
      <a href="/extensions/2014/02/10/mongodb-and-sql-connectors/">
        Introducing Easier Onboarding and Activation with Connectors
      </a>
    </h1>

    <span class="post-date">10 Feb 2014</span>

    <p>Most of our users are <strong>technical</strong>. They love writing code, and we love
providing API clients in the major programming languages to them (we are
currently <a href="http://www.algolia.com/doc/apiclients)">supporting 10 platforms</a>.</p>

<p>They are doers. They love prototyping. Just like us, they work for startups
which need to move fast, and get things done, keeping in mind that done is
better than perfect. It is very important that they <strong>don’t want to waste
time</strong>. In this post, I will explain how one would have used our API up to
now, and how we introduced SQL and MongoDB connectors for easier onboarding,
integration and testing.</p>

<h2 id="beforethe-first-steps-with-our-api">Before: The first steps with our API</h2>

<p>Up until now, our onboarding process asked you to try the API by uploading
your data. We emphasized our <a href="http://www.algolia.com/doc">documentation</a>, and
we made sure our users would not need more than a few minutes to integrate our
<a href="http://www.algolia.com/doc/rest">REST API</a>. Nevertheless, exporting your
application’s data to a JSON or CSV file is often more complex than it
appears, especially when you have millions of rows - and especially because
developers are lazy :) No worries, that’s <a href="http://www.codinghorror.com/blog/2005/08/how-to-be-lazy-dumb-and-successful.html">totally
OK</a>. It is something you may not be willing to do, especially
just to try a service, so we decided to try something else.</p>

<h3 id="initial-import">Initial import</h3>

<p>90% of our users are using a SQL or MongoDB database. Exporting a table or a
collection to a JSON file can be easy if you’re using a framework, for example
Ruby on Rails:</p>

<p><code>ruby
File.open("/tmp/export.json", "w") do |f|
  f &lt;&lt; MyActiveRecordModel.all.to_json
end
</code></p>

<p>…or more annoying, for example when using PHP without any framework:</p>

<p><code>php
mysql_connect('localhost', 'mysql_user', 'mysql_password');
mysql_set_charset('utf8');
$results = array();
$q = mysql_query("SELECT * FROM YourTable");
if ($q) {
  while (($row = mysql_fetch_assoc($q))) {
    array_push($results, $row);
  }
}
$fp = fopen('/tmp/export.json', 'w');
fwrite($fp, json_encode($results));
fclose($fp);
</code></p>

<p>Anyway, in both cases it gets harder if you want to export millions of rows
without consuming hundreds GB of RAM. So you will need to use our API clients:</p>

<p>```ruby
index = Algolia::Index.new “YourIndex”
MyActiveRecordModel.find_in_batches(1000) do |objects|
  index.add_objects(objects)
end
# that’s actually what <code>MyActiveRecordModel.reindex!</code> does</p>

<p>mysql_connect(‘localhost’, ‘mysql_user’, ‘mysql_password’);
mysql_set_charset(‘utf8’);
$limit = 1000;
$start = 0;
$index = $client-&gt;initIndex(‘YourIndexName’);
while (true) {
  $q = mysql_query(“SELECT * FROM YourTable LIMIT “ . $start . “,” . $limit);
  $n = 0;
  if ($q) {
    $objects = array();
    while(($row = mysql_fetch_assoc($q))) {
      array_push($objects, $row);
      ++$n;
    }
    $index-&gt;addObjects($objects);
  }
  if ($n != $limit) {
    break;
  }
  $start += $n;
}
```</p>

<h3 id="incremental-updates">Incremental updates</h3>

<p>Once imported, you will need to go further and keep your DB and our indexes
up-to-date. You can either:</p>

<ul>
  <li>Clear your index and re-import all your records hourly/daily with the previous methods:
    <ul>
      <li>non-intrusive,</li>
      <li>not real-time,</li>
      <li>not durable,</li>
      <li>need to import your data to a temporary index + replace the original one atomically once imported if you want to keep your service running while re-importing</li>
    </ul>
  </li>
</ul>

<p>Or</p>

<ul>
  <li>Patch your application/website code to replicate every add/delete/update operations to our API:
    <ul>
      <li>real-time,</li>
      <li>consistent &amp; durable,</li>
      <li>a little intrusive to some people, even though it is only a few lines of code (<a href="http://www.algolia.com/doc)">see our documentation</a></li>
    </ul>
  </li>
</ul>

<h2 id="after-introducing-connectors">After: Introducing connectors</h2>

<p>Even if we did recommend you to modify your application code to replicate all
add/delete/update operations from your DB to our API, this should not be the
only option, especially to test Algolia. Users want to be convinced before
modifying anything in their production-ready application/website. This is why
we are really proud to release 2 open-source connectors: a non-intrusive and
efficient way to synchronize your current SQL or MongoDB database with our
servers.</p>

<h3 id="sql-connector">SQL connector</h3>

<p>Github project: <a href="https://github.com/algolia/jdbc-java-connector">algolia/jdbc-java-connector</a> (MIT license, we love pull-requests :))</p>

<p>The connector starts by enumerating the table and push all matching rows to
our server. If you store the last modification date of a row in a field, you
can use it in order to send all detected updates every 10 seconds. Every 5
minutes, the connector synchronizes your database with the index by adding the
new rows and removing the deleted ones.</p>

<p><code>java
jdbc-connector.sh --source "jdbc:mysql://localhost/YourDB"  
  --username mysqlUser --password mysqlPassword             
  --selectQuery "SELECT * FROM YourTable" --primaryField id 
  --updateQuery "SELECT * FROM YourTable WHERE updated_at &gt; _$"
  --updatedAtField updated_at 
  --applicationId YourApplicationId --apiKey YourApiKey --index YourIndexName
 </code></p>

<p>If you don’t have an updated_at  field, you can use:</p>

<p><code>java
jdbc-connector.sh --source "jdbc:mysql://localhost/YourDB"  
  --username mysqlUser --password mysqlPassword             
  --selectQuery "SELECT * FROM YourTable" --primaryField id 
  --applicationId YourApplicationId --apiKey YourApiKey --index YourIndexName
</code></p>

<p>The full list of features is available on <a href="https://github.com/algolia/jdbc-java-connector">Github</a> (remember, we ♥ feature and pull-requests)!</p>

<h3 id="mongodb-connector">MongoDB connector</h3>

<p>Github
project: <a href="https://github.com/algolia/mongo-connector">algolia/mongo-connector</a></p>

<p>This connector has been forked from <a href="https://github.com/10gen-labs/mongo-connector">10gen-lab’s official
connector</a> and is based on
MongoDB’s <a href="http://docs.mongodb.org/manual/core/replica-set-oplog/">operation logs</a>. This means you will need to start your mongod  server specifying a
<a href="http://docs.mongodb.org/manual/tutorial/deploy-replica-set/">replica set</a>.
Basically, you need to start your server with: mongod –replSet
REPLICA_SET_IDENTIFIER. Once started, the connector will replicate each
addition/deletion/update to our server, sending a batch of operations every 10
seconds.</p>

<pre><code>mongo-connector -m localhost:27017 -n myDb.myCollection 
  -d ./doc_managers/algolia_doc_manager.py              
  -t YourApplicationID:YourApiKey:YourIndex
</code></pre>

<p>The full features list is available on <a href="https://github.com/algolia/mongo-connector">Github</a> (we ♥ feature and pull-requests).</p>

<h2 id="conclusion-easier-onboarding-larger-audience">Conclusion: Easier Onboarding, Larger Audience!</h2>

<p>Helping our users to onboard and try Algolia without writing a single line of
code is not only a way to attract more non-technical users; It is also a way
to save the time of our technical but overbooked users, allowing them to be
convinced without wasting their time before really implementing it.</p>

<p>Those connectors are open-source and we will continue to improve them based on
your feedback. Your feature requests are welcome!</p>


  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/extensions/2014/01/29/postmortem-todays-8min-indexing-downtime/">
        Postmortem of today's 8min indexing downtime
      </a>
    </h1>

    <span class="post-date">29 Jan 2014</span>

    <p>Today (Jan 29) at 9:30pm UTC, our service experienced an 8 minute partial
outage during which we have rejected many write operations sent to the
indexing API (exactly 2841 calls). We call it “partial” as all search queries
have been honored without any problem. For end-users, there was no visible
problem.</p>

<p>Transparency is in our DNA: this outage is visible on our status page
(<a href="http://status.algolia.com">status.algolia.com</a>) but we also wanted to share
with you all the details of the outage and more importantly the details of our
response.</p>

<h2 id="the-alert">The alert</h2>

<p>This morning I fixed a rare bug in indexing complex hierarchical objects. This
fix successfully passed all the tests after development. We have 6000+ unit
tests and asserts, and 200+ non regression tests. So I felt confident when I
entered the deploy password in our automatic deployment script.</p>

<p>A few seconds after, I started to receive a lot of text messages on my
cellphone.</p>

<p>We developed several embedded probes to detect all kinds of problems and alert
us using Twilio and Hipchat APIs. They detect for example:</p>

<ul>
  <li>a process that restart</li>
  <li>an unusually long query</li>
  <li>a write failure</li>
  <li>a low memory warning</li>
  <li>a low disk-free warning</li>
  <li>etc.</li>
</ul>

<p>In case embedded probes can’t run, other external probes run once a minute
from an independent datacenter (Google App Engine). These also automatically
update our status page when a problem impacts the quality of service.</p>

<p>Our indexing processes were crash looping. I immediately decided to rollback
to the previous version.</p>

<h2 id="the-rollback">The rollback</h2>

<p>Until today, our standard rollback process was to revert the commit, launch
the recompile and finally deploy. This is long, very long when your know that
you have an outage in production. The rollback took about 5 minutes in total
out of the 8 minutes.</p>

<h2 id="how-we-will-avoid-this-situation-in-the-future">How we will avoid this situation in the future</h2>

<p>Even if the outage was on a relatively small period of time, we still believe
it was too long. To make sure this will not happen again:</p>

<ul>
  <li>We have added a very fast rollback process in the way of a simple press button like the one we use to deploy. An automatic deploy is nice, but an automatic rollback is actually more critical when needed!</li>
  <li>Starting now, we will deploy new versions of the service on clusters hosting community projects such as Hacker News Search or Twitter handle search, before pushing the update on clusters hosting paying customers. Having real traffic is key to detect some types of errors. Unit-tests &amp; non-regression tests cannot catch everything.</li>
  <li>And of course we added non-regression tests for this specific error.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Having all these probes in our infrastructure was key to detect today’s
problem and react quickly. In real conditions, it proved not to be enough. In
a few hours we have implemented a much better way to handle this kind of
situation. The quality of our service is our top priority. Thank you for your
support!</p>


  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/extensions/2014/01/24/hacker-news-search-algolia/">
        Hacker News search: 6.5 million articles and comments at your fingertips
      </a>
    </h1>

    <span class="post-date">24 Jan 2014</span>

    <p>We are <a href="https://news.ycombinator.com">Hacker News</a> readers and probably just
like you, there is not a day that goes by we don’t use it. It is a little like
checking the weather app of the tech world. Long story short, Hacker News is
awesome, and we wanted to add our two cents to make it even greater to use.</p>

<p>Indeed, here is our problem: how do we instantly access the old posts we wish
we had saved?</p>

<h2 id="powering-a-newhacker-news-search-engine">Powering a new Hacker News search engine</h2>

<p>Up until now we’ve been using <a href="http://www.hnsearch.com">hnsearch.com</a>,
maintained for years by the great folks at <a href="http://octopart.com/">Octopart</a>. I
hope we speak on behalf of the HN community here, we are all grateful for the
work they put in hnsearch.com and they inspired us to pursue their effort.</p>

<p>Back in September 2013, we created a “<a href="https://news.ycombinator.com/item?id=6476003">homemade Hacker News
crawler</a>” and built a search
engine with the data we could get. It was not perfect but somehow, it did the
job fine.</p>

<p><a href="http://blog.ycombinator.com/algolia-
yc-w14-launches-a-search-api-that-lets-you-provide-apple-spotlight-like-
realtime-search-for-your-app-or-service">Now part of the Ycombinator W14 batch</a>, we have a direct access to the data
and it has allowed us to provide instant search for the entire content of
Hacker News, 1.2 million articles, 5.2 million comments as of today. See for
yourself right here: <a href="http://hn.algolia.com/">hn.algolia.com</a></p>

<h2 id="here-is-how-we-did-it">Here is how we did it</h2>

<ul>
  <li>
    <h3 id="hacker-news-api-access">Hacker News API access</h3>

    <ul>
      <li>YC provides us a private API access to fetch batches of 1000 items (an item being a comment or a post). Every two minutes, we update our database with the latest 1000 items. Last 48,000 items are refreshed every hour to keep the number of votes and comments up to date.</li>
    </ul>

    <p><code>
# Yep, that's a Lisp API :)
EXPORT_REGEXP = %r{^((d+) (story|comment|poll|pollopt) "(.+)" (d+) (?:nil|"(.*)") (?:nil|"(.+)") (?:nil|"(.*)") (?:nil|-?(d+)) (?:nil|(([d ]+))) (?:nil|(d+)))$}
</code></p>
  </li>
  <li>
    <h3 id="thumbnails-generation">Thumbnails generation</h3>

    <ul>
      <li>We use <a href="https://code.google.com/p/wkhtmltopdf/">wkhtmltoimage</a> to render the URLs and generate the associated thumbnails. Playing with connection timeouts and JavaScript infinite loops was a pleasure:</li>
    </ul>

    <p><code>
(timeout 60 xvfb-run --auto-servernum --server-args="-screen 0, 1024x768x24" 
wkhtmltoimage-amd64 --height 768 --use-xserver--javascript-delay 30000 "$URL" "$FILE" || 
timeout 60 xvfb-run --auto-servernum --server-args="-screen 0, 1024x768x24" 
wkhtmltoimage-amd64 --height 768 --use-xserver --disable-javascript "$URL" "$FILE") &amp;&amp; 
convert "$FILE" -resize '100!x100' "$FILE"
</code></p>
  </li>
  <li>
    <h3 id="thumbnails-storage">Thumbnails storage</h3>

    <ul>
      <li>Thumbnails are resized and stored on a S3 bucket.</li>
    </ul>

    <p><code>
AWS::S3::S3Object.store("#{id}.png", open(temp_file), 'hnsearch', access: :public_read)
</code></p>
  </li>
  <li>
    <h3 id="thumbnails-distribution">Thumbnails distribution</h3>

    <ul>
      <li>We configured a CloudFront instance targeting the S3 bucket to distribute thumbnails with low latency and high data transfer speed. We followed Amazon’s associated <a href="http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/MigrateS3ToCloudFront.html">developer guide</a>.</li>
    </ul>
  </li>
  <li>
    <h3 id="indexing">Indexing</h3>

    <ul>
      <li>We used the “<a href="https://github.com/algolia/algoliasearch-rails">algoliasearch-rails</a>” gem and a standard (Ruby on Rails) MySQL-backed ActiveRecord setup. Indexing is performed automatically as soon as new items are added to the database, providing a near-realtime experience.</li>
    </ul>
  </li>
  <li>
    <h3 id="configuration">Configuration</h3>

    <p>```ruby
class Item &lt; ActiveRecord::Base
  include AlgoliaSearch</p>

    <p>algoliasearch per_environment: true do
    # the list of attributes sent to Algolia’s API
    attribute :created_at, :title, :url, :author, :points, :story_text, :comment_text, :author, :num_comments, :story_id, :story_title, :story_url
    attribute :created_at_i do
      created_at.to_i
    end</p>

    <pre><code># The order of the attributes sets their respective importance.
# `title` is more important than `{story,comment}_text`, `{story,comment}_text` more than `url`, `url` more than `author`
# btw, do not take into account position to avoid first word match boost
attributesToIndex ['unordered(title)', 'unordered(story_text)', 'unordered(comment_text)', 'unordered(url)', 'author', 'created_at_i']

# add tags used for filtering
tags do
  [item_type, "author_#{author}", "story_#{story_id}"]
end

# Custom ranking allows to automatically sort the results by a custom criteria
# in this case, a decreasing sort of the number of HN points and comments.
customRanking ['desc(points)', 'desc(num_comments)']

# controls the way results are sorted sorting on the following 4 criteria (one after another)
# I removed the 'exact' match critera (improve 1-words query relevance, doesn't fit HNSearch needs)
ranking ['typo', 'proximity', 'attribute', 'custom']

# google+, $1.5M raises, C#: we love you
separatorsToIndex '+#$'   end
</code></pre>

    <p>def story_text
    item_type_cd != Item.comment ? text : nil
  end</p>

    <p>def story_title
    comment? &amp;&amp; story ? story.title : nil
  end</p>

    <p>def story_url
    comment? &amp;&amp; story ? story.url : nil
  end</p>

    <p>def comment_text
    comment? ? text : nil
  end</p>

    <p>def comment?
    item_type_cd == Item.comment
  end</p>

    <p>def num_comments
    item_type_cd == Item.story ? story_comments.count : nil
  end
end
```</p>
  </li>
  <li>
    <h3 id="search">Search</h3>

    <ul>
      <li>Queries are sent directly to our API via the<a href="https://github.com/algolia/algoliasearch-client-js"> javascript client</a>, the javascript code uses a public API-Key that can only perform queries.</li>
    </ul>
  </li>
</ul>

<h2 id="seeking-feedback-from-the-community">Seeking feedback from the community</h2>

<p>There is still room for improvement and we would love to know how you are
searching for news on HN. What is important for you? Are you searching by
date, by upvote, by comment or by user? All together maybe?</p>

<p>We would love to have your feedback! Don’t hesitate to checkout the code: <a href="https://github.com/algolia/hn-search">We
open-sourced it</a>.</p>

<p>Special thanks to the <a href="http://octopart.com/">Octopart</a> and
<a href="http://ycombinator.com/">YC</a> teams for making this experience possible!</p>

<p>Give it a try now: <a href="http://hn.algolia.com">hn.algolia.com</a></p>


  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/extensions/2014/01/18/search-grader-engine-performing/">
        Search Grader by Algolia: How does your search engine perform?
      </a>
    </h1>

    <span class="post-date">18 Jan 2014</span>

    <p><a href="http://grader.algolia.com"><img src="/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-01-24-01.26.08-600x150.png" alt="algolia-search-grader" /></a></p>

<h2 id="search-is-important">Search is important</h2>

<p>An effective search engine should be a seamless and natural extension of the
user experience. With improved relevance, your users should be able to find
what they are looking for in no time.</p>

<p>Unfortunately, developers often consider search as a second-tier priority.
This is a mistake. Every day, consumers use Google, Amazon, and Youtube to
find what they want on the web quickly and easily. Users of web applications
and eCommerce websites will feel the gap in search experience. As their
expectations are not met, your conversion rate will plummet, your bounce rate
will skyrocket, and the damage to your brand may be irredeemable.</p>

<h2 id="search-is-tricky">Search is tricky</h2>

<p>The reason why many web applications and e-commerce websites suffer from bad
search is because finding a good solution is not easy. Few current search
technologies combine relevancy and business metrics in a way that sorts search
results optimally.</p>

<p>In most cases, they fail on the following items:</p>

<ul>
  <li>long response times,</li>
  <li>no handling of mistakes,</li>
  <li>no search field auto-completion,</li>
  <li>unexplainable or even nonexistent results.</li>
</ul>

<p>To improve your search experience, you first need to understand which areas
are problematic. That’s exactly why we built Search Grader by Algolia.</p>

<h2 id="introducing-search-grader-by-algolia">Introducing Search Grader by Algolia</h2>

<p><a href="http://grader.algolia.com/">Search Grader</a> by Algolia is a tool to help you
quickly find out what your search engine may be missing. We divided the search
user experience in 3 categories in order to get a maximum score of 100:</p>

<ul>
  <li>User Experience: 30 points</li>
  <li>Speed: 20 points</li>
  <li>Relevance: 50 points</li>
</ul>

<p><strong>User Experience: 30/100</strong></p>

<p>User experience is not just design, it’s the key of a good user satisfaction.
If your users cannot find what they’re searching for, they will just leave.</p>

<ul>
  <li><strong>Searchbox visibility (3 pts)</strong>: It is easier for your users to find something if your search bar is clearly visible!</li>
  <li><strong>Descriptive placeholder (2 pts) </strong>: A hint in your search bar is a good way to let your users know what kind of data they can dig into.</li>
  <li><strong>Searchbox auto-completion (6 pts)</strong>: Auto-completion guides your users more efficiently towards what they are looking for.</li>
  <li><strong>Suggestions after the first keystroke (5 pts)</strong>: Delight your users by providing relevant suggestions immediately after the first keystroke.</li>
  <li><strong>Faceting (4 pts)</strong>: Faceting enables users to browse results by filtering them on specific categories (e.g., author, tags, price).</li>
  <li><strong>Highlight (6 pts)</strong>: You need to explain why the displayed results are chosen, especially when you tolerate typos or misspelled queries.</li>
  <li><strong>Pagination (2 pts)</strong>: Providing relevant results on the first page is great. But to keep your users engaged, you need to give them an easy way to access other results.</li>
  <li><strong>Picture (2 pts):</strong> Sometime images are the fastest way to display information. Users will go through results and find the right hits much faster if you show them images.</li>
</ul>

<p><strong>Speed: 20/100</strong></p>

<p>If results show up in more than 200ms, you will lose part of your users. Time
is money, real-time is gold. Because your location is important to the speed
of the search we graded speed 3 times based on the location of the user:</p>

<ul>
  <li>Response time from US East coast</li>
  <li>Response time from US West coast</li>
  <li>Response time from Europe</li>
</ul>

<p><strong>Relevance: 50/100</strong></p>

<p>Relevance is when you give your users what they want in the top results.
Although it’s not very fancy, it’s probably the more critical aspect of a good
search engine.</p>

<ul>
  <li><strong>Typo-tolerance (10 pts)</strong>: People make a lot of typos, especially on mobile devices. Tolerating misspelled queries provides a great value to both your users and the products you promote.</li>
  <li><strong>Auto-completion shows results, not queries (10 pts)</strong>: Suggesting queries is good. Suggesting results directly is a lot better as you spare your users one click and a lot of time.</li>
  <li><strong>Ranking uses business metrics (10 pts)</strong>: Considering customized criteria such as sales numbers or the popularities in the way you rank results makes a key difference. It is THE way to give relevant results with one single keystroke.</li>
  <li><strong>Overall ranking (20 pts)</strong>: Search must always return relevant results. We perform multiple queries to detect if your search is performing well.</li>
</ul>

<h2 id="get-google-amazon-like-search-for-your-website">Get Google, Amazon-like search for your website</h2>

<p>These criteria were defined by our team of experts with over 30+ years of
experience in search.</p>

<p>We tested out some of the biggest names in tech:</p>

<p><strong><a href="http://grader.algolia.com"><img src="/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-01-17-18.22.23.png" alt="Algolia search grader" /></a></strong></p>

<p>As you could expect, Amazon and LinkedIn received an excellent score of
90/100. That’s the kind of quality Algolia can help you achieve in your
application or e-commerce website, for as low as
<a href="http://www.algolia.com/pricing/">$19/month</a>.</p>

<p>Now, how about your search? How is it performing? To find out, use <a href="http://grader.algolia.com/">Search
Grader</a> by Algolia.</p>

<p>If you want to share your ideas with us, please leave your comments!</p>


  </div>
  
  <div class="post">
    <h1 class="post-title">
      <a href="/extensions/2014/01/06/improving-ranking-twitter-handles-search/">
        Improving Search for Twitter Handles
      </a>
    </h1>

    <span class="post-date">06 Jan 2014</span>

    <p>Hello Twitter,</p>

<p>I have been using your service for awhile, and I love it!</p>

<p>At first, I was skeptical about what you could offer: Broadcasting to all my
friends that I was eating a pizza, or taking a walk, is not really my cup of
tea. But 3 years ago I figured out what Twitter was really meant for and how
it could help me in a totally different way from what I first thought:</p>

<ul>
  <li>sharing interesting articles,</li>
  <li>checking if /replace by the service provider you want/ is down,</li>
  <li>or catching up on HackerNews.</li>
</ul>

<p>More recently, I discovered you had a feature that could help me even more: I
can now ask for support by tweeting. Tweeting is often faster and more
productive than sending an email. You taught me to include the recipient’s
Handle in my tweets, and your current Handle auto-completion implementation
works pretty well: but what if you could provide a <strong>better typo-tolerance and
ranking</strong>? (I’m NOT speaking about your official OSX/iOS native clients and
its <a href="http://blog.algolia.com/why-autocomplete-in-twitter-on-mobile-sucks/">totally unusable auto-completion feature</a>… btw, could you explain me why it
is different from the one on your website?).</p>

<p>I have been leading a search-engine development team over the last 5 years and
I’m now VP of engineering at Algolia. I am aware that considering my job, I
have kind of an “expert” point of view about search. But search has become so
essential that I am convinced it <strong>must</strong> be irreproachable. Did you know
that 1.7M+ people are currently following</p>

<p>expecting great things from your search-engine, Twitter :) Here is how I would
improve search for Twitter handles:</p>

<p>For example, it would be nice if I could find President
<a href="https://twitter.com/barackobama">@barackobama</a> with his last name:</p>

<p><a href="https://blog.algolia.com/wp-
content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.40.09.png"><img src="/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.40.09-263x300.png" alt="Search for Twitter handles including @obama yields less-than-stellar
results." /></a></p>

<p>Same for Justin:</p>

<p><a href="https://blog.algolia.com/wp-
content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.42.01.png"><img src="/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.42.01-262x300.png" alt="Search for Twitter handles that could be Justin Bieber's yields less-than-
stellar results." /></a></p>

<p>Typo-tolerance is now a must-have, especially because we’re all using
smartphones and tablets:</p>

<p><a href="https://blog.algolia.com/wp-
content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.38.19.png"><img src="/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.38.19-263x300.png" alt="Search for Twitter handles should have typo tolerance." /></a></p>

<p>More and more handles are now prefixed/suffixed by “official”, which makes
finding <a href="https://twitter.com/officialadele">@OfficialAdele</a> just impossible:</p>

<p><a href="https://blog.algolia.com/wp-content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.47.52.png"><img src="/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.47.52.png" alt="Search for Twitter handles that start with @official is broken." /></a></p>

<p><strong>For sure we can improve it, let’s code!</strong></p>

<p>First of all Twitter, I need your Handles database :)</p>

<ul>
  <li>I used your <a href="https://dev.twitter.com/docs/streaming-apis">Streaming API</a> to crawl about 20M+ accounts in ~2 weeks: it’s not blazing fast but I must admit it does the job (and it’s free). That’s about 5 lines of Ruby with <a href="https://github.com/tweetstream/tweetstream">TweetStream</a>, good job guys!</li>
  <li>and <a href="https://github.com/bmc/daemonize">Daemonize</a> to create a bin/crawler executable.</li>
</ul>

<p>```ruby
#! /usr/bin/env ruby</p>

<p>require File.expand_path(File.join(File.dirname(<strong>FILE</strong>), ‘..’, ‘config’, ‘environment’))</p>

<p>daemon = TweetStream::Daemon.new(‘crawler’, :log_output =&gt; true)
daemon.on_inited do
  ActiveRecord::Base.connection.reconnect!
  ActiveRecord::Base.logger = Logger.new(File.join(Rails.root, ‘log/stream.log’), ‘w+’)
end
daemon.on_error do |message|
  puts “Error: #{message}”
end
daemon.sample do |status|
  Handle.create_from_status(status)
end
```</p>

<p>For each new tweet you send to me, I store the author (name + screen_name +
description + followers_count) and all his/her user mentions.</p>

<p>```ruby
class Handle &lt; ActiveRecord::Base</p>

<p>def self.create_from_user(user)
    h = Handle.find_or_initialize_by(screen_name: user.screen_name)
    puts h.screen_name if h.new_record?
    h.name = user.name
    h.description = (user.description || “”)[0..255]
    h.followers_count = user.followers_count
    h.updated_at ||= DateTime.now
    h.save
    h
  end</p>

<p>def self.create_from_status(status)
    Handle.create_from_user(status.user)
    status.user_mentions.each do |mention|
      m = Handle.find_or_initialize_by(screen_name: mention.screen_name)
      m.updated_at ||= DateTime.now
      m.name = mention.name
      m.mentions_count ||= 0
      m.mentions_count += 1
      m.save
    end
  end</p>

<p>end
```</p>

<p>And every minute, I re-index the last-updated accounts with a batch request
using <a href="https://github.com/algolia/algoliasearch-rails">algoliasearch-rails</a>,</p>

<p><code>ruby
every 1.minute, roles: [:cron] do
  runner "Handle.where('updated_at &gt;= ?', 1.minute.ago).reindex!"
end
</code></p>

<p>The result order is based on several criteria:</p>

<ul>
  <li>the number of typos,</li>
  <li>the matching attributes: the name/handle is more important than the description,</li>
  <li>the proximity between matched words,</li>
  <li>and the followers count (I also use the “mentions count” if my crawler didn’t get the followers count yet).</li>
</ul>

<p>I could have improved the results by using the user’s list of
followers/following but I was limited by your <a href="https://dev.twitter.com/docs/rate-limiting/1.1">Rate
Limits</a>. <strong>Instead, I chose to
emphasize your top-users </strong>(accounts having 10M+ followers).</p>

<p>Here is the configuration I used</p>

<p>```ruby
class Handle &lt; ActiveRecord::Base</p>

<p>include AlgoliaSearch
  algoliasearch per_environment: true, auto_index: false, auto_remove: false do
    # add an extra score attribute
    add_attribute :score</p>

<pre><code># add an extra full_name attribute: screen_name + name
add_attribute :full_name

# do not take `full_name`'s words order into account, `full_name` is more important than `description`
attributesToIndex ['unordered(full_name)', :description]

# list of attributes to highlight
attributesToHighlight [:screen_name, :name, :description]

# use followers_count OR mentions_count to sort results (last sort criteria)
customRanking ['desc(score)']

# @I_love_you
separatorsToIndex '_'

# tag top-users
tags do
  followers_count &gt; 10000000 ? ['top'] : []
end   end
</code></pre>

<p>def full_name
    # consider screen_name and name equal
    # the name should not match exact so we concatenate it with the screen_name
    [screen_name, “#{screen_name} #{name}”]
  end</p>

<p># the custom score
  def score
    return followers_count if followers_count &gt; 0
    if mentions_count &lt; 10
      mentions_count
    elsif mentions_count &lt; 100
      mentions_count * 10
    elsif mentions_count &lt; 1000
      mentions_count * 100
    else
      mentions_count * 1000
    end
  end</p>

<p>end
```</p>

<p>The user query is composed by 2 backend queries:</p>

<ul>
  <li>the first one retrieves all matching top-users (could be replaced by a query targeting your followers/following only)</li>
  <li>the second one the others.</li>
</ul>

<p><a href="http://twittersearch.algolia.io/"><strong>Try it for yourself</strong></a>, and enjoy
relevant and highlighted results after the first keystroke: <a href="http://twittersearch.algolia.io/">Twitter Handles
Search</a>.</p>


  </div>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/extensions/page8">Older</a>
  
  
    
      <a class="pagination-item newer" href="/extensions/page6">Newer</a>
    
  
</div>
</div>

      <div class="algolia__search-content js-algolia__search-content">
        <h1 class="page-title">Search</h1>
        <div class="posts algolia__results"></div>
      </div>
    </div>

  <script>
  window.ALGOLIA_CONFIG = {
    'applicationId': 'MFYV1TCXOX',
    'indexName': 'jekyll_NAME',
    'apiKey': '888511e2a53baf5e4f3fc9656e0da233',
    'baseurl': '/extensions'
  }
</script>
<script id="algolia__template" type="text/template">

  <div class="algolia__result">
    <a class="algolia__result-link" href="{{ full_url }}#algolia:{{ css_selector }}">{{{ _highlightResult.title.value }}}</a>
    {{#posted_at}}
    <div class="algolia__result-date">{{ posted_at_readable }}</div>
    {{/posted_at}}
    <div class="algolia__result-text">{{{ _highlightResult.text.value }}}</div>
  </div>

</script>
<script id="algolia__template--no-results" type="text/template">
  No results found.
</script>
<script src="//cdn.jsdelivr.net/jquery/2.1.4/jquery.min.js"></script>
<script src="//cdn.jsdelivr.net/algoliasearch/3.6.0/algoliasearch.min.js"></script>
<script src="//cdn.jsdelivr.net/algoliasearch.helper/2.1.0/algoliasearch.helper.min.js"></script>
<script src="//cdn.jsdelivr.net/hogan.js/3.0.2/hogan.min.js"></script>
<script src="//cdn.jsdelivr.net/momentjs/2.10.3/moment.min.js"></script>
<script src="/extensions/public/js/algolia.js"></script>

  </body>
</html>
