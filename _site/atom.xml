<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Hyde</title>
 <link href="https://github.com/svenhutchinson/extensions/atom.xml" rel="self"/>
 <link href="https://github.com/svenhutchinson/extensions/"/>
 <updated>2016-06-09T04:11:23+07:00</updated>
 <id>https://github.com/svenhutchinson/extensions</id>
 <author>
   <name>Algolia</name>
   <email></email>
 </author>

 
 <entry>
   <title>Welcome Texas!</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/07/15/new-distributed-search-network-texas/"/>
   <updated>2015-07-15T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/07/15/new-distributed-search-network-texas</id>
   <content type="html">&lt;p&gt;You probably already know it: any millisecond that end-users have to wait to
get their results drives us nuts. But what on Earth does this have to do with
Texas? Actually a lot!&lt;/p&gt;

&lt;h2 id=&quot;you-want-your-search-to-be-instant-lets-talk-network&quot;&gt;You want your search to be instant? Let’s talk network…&lt;/h2&gt;

&lt;p&gt;When looking at the speed of search on a website or a mobile application, the
performance of the search engine is just one part of the equation. When you’re
using an extremely fast engine, network latency and saturated links quickly
become your biggest enemies: it simply takes time for the user query to reach
the engine and for the results to get back to the user’s browser.&lt;/p&gt;

&lt;p&gt;In some cases, the round trip can easily take more than a second. In the US, it
can take up to 300ms to simply establish an SSL connection between the two
coasts.  All this also applies to the communications between your backend and
the servers that host your search engine. The network can simply ruin the real
time experience you hoped to offer with your search engine.&lt;/p&gt;

&lt;h2 id=&quot;a-new-us-central-point-of-presence-to-reach-a-25ms-total-delivery-time-across-the-us&quot;&gt;A new US Central point of presence to reach a 25ms total delivery time across the US&lt;/h2&gt;

&lt;p&gt;A great search experience is to drive end-users towards what they’re looking
as quickly and seamlessly as possible. For us at Algolia it means to be able
to dynamically update the content displayed as the end-user is typing a query.
Being able to offer this find as-you-type experience obviously requires a very
performant search engine but it also requires to host the search engine itself
as close as possible to the end-user in order to tackle the network latency.&lt;/p&gt;

&lt;p&gt;This is why we are adding this new US Central region to our existing twelve
regions. With the addition of the Dallas PoP, Algolia’s API is now accessible
from thirteen different regions including US (East, West and Central),
Australia, Brazil, Canada, France, Germany, Hong Kong, India, Japan, Russia,
and Singapore.&lt;/p&gt;

&lt;p&gt;If your audience is spread out across multiple regions, you can use Algolia
from a combination of these regions to ensure minimal results delivery time
and optimal speed for all your users (Algolia’s Distributed Search Network
automatically routes user queries to your closest region).&lt;/p&gt;

&lt;p&gt;This new US Central PoP, combined with Algolia’s US East and US West PoPs, now
allows to deliver search results across the US with less than 25 milliseconds of
latency. This guarantees a seamless find-as-you-type experience on websites and
mobile applications all across the US.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/07/dallas2.jpg&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/dallas2.jpg&quot; alt=&quot;dallas2&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;getting-closer-to-additional-infrastructure-providers&quot;&gt;Getting closer to additional infrastructure providers&lt;/h2&gt;

&lt;p&gt;When you choose SaaS providers, especially when their service becomes a core
component of your product, you probably prefer the ones hosted close to where
you operate your backend, for latency and availability reasons. This is
actually why we initially started in the US by opening PoPs in Ashburn (VA)
and San Jose (CA), close to the AWS PoPs, which most of our customers rely on
today.&lt;/p&gt;

&lt;p&gt;Our new presence in Texas allows services which rely for their backend on
local infrastructure providers such as Rackspace and Softlayer to also benefit
from the full power of Algolia. This new PoP offers them an extremely low
network latency between their backend and our API.&lt;/p&gt;

&lt;p&gt;If you’re not already an Algolia user and you want to give it a try, simply
&lt;a href=&quot;https://www.algolia.com/users/sign_up&quot;&gt;sign up&lt;/a&gt; for a 14 day trial and select
the US Central region in the process.&lt;/p&gt;

&lt;p&gt;If you are already using Algolia and want to migrate to the US Central region,
simply drop us a line at &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#115;&amp;#117;&amp;#112;&amp;#112;&amp;#111;&amp;#114;&amp;#116;&amp;#064;&amp;#097;&amp;#108;&amp;#103;&amp;#111;&amp;#108;&amp;#105;&amp;#097;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;&amp;#115;&amp;#117;&amp;#112;&amp;#112;&amp;#111;&amp;#114;&amp;#116;&amp;#064;&amp;#097;&amp;#108;&amp;#103;&amp;#111;&amp;#108;&amp;#105;&amp;#097;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&lt;/a&gt; or
on the live chat.&lt;/p&gt;

&lt;p&gt;If you’re none of the two above, we still think you’re awesome!&lt;/p&gt;

&lt;p&gt;Cheers!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>When Solid State Drives are not that solid</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/06/15/when-solid-state-drives-are-not-that-solid/"/>
   <updated>2015-06-15T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/06/15/when-solid-state-drives-are-not-that-solid</id>
   <content type="html">&lt;p&gt;It looked just like another page in the middle of the night. One of the
servers of our search API stopped processing the indexing jobs for an unknown
reason. Since we build systems in Algolia for high availability and
resiliency, nothing bad was happening. The new API calls were correctly
redirected to the rest of the &lt;a href=&quot;http://highscalability.com/blog/2015/3/9/the-architecture-of-
algolias-distributed-search-network.html&quot;&gt;healthy machines in the
cluster&lt;/a&gt; and the only impact on the service
was one woken-up engineer. It was time to find out what was going on.&lt;/p&gt;

&lt;p&gt;UPDATE June 16:&lt;br /&gt;
&lt;a href=&quot;https://hn.algolia.com/story/9723066/when-solid-state-drives-are-not-that-solid&quot;&gt;A lot of
discussions&lt;/a&gt;
started pointing out that the issue is related to the newly introduced queued
TRIM. This is not correct. The TRIM on our drives is un-queued and the issue we
have found is not related to the latest changes in the Linux Kernel to disable
this feature.&lt;/p&gt;

&lt;p&gt;UPDATE June 17:&lt;br /&gt;
We got contacted by Samsung and we provided them all the system specifications and all the information about the issue we had. We will continue to provide Samsung all the necessary information in order to resolve the issue.&lt;/p&gt;

&lt;p&gt;UPDATE June 18:
We just had a conference call with the European branch and the Korean HQ of
Samsung. Their engineers are going to visit one of the datacenters we have
servers in and in cooperation with our server provider they will inspect the
mentioned SSDs in our SW and HW setup.&lt;/p&gt;

&lt;p&gt;UPDATE June 19:&lt;br /&gt;
On Monday June 22, the engineering team from Samsung is going analyze one of our servers in Singapore and if nothing is found on-site, the server will travel to Samsung HQ in Korea for further analysis.&lt;/p&gt;

&lt;p&gt;UPDATE July 13:&lt;br /&gt;
Since the last update of this blog-post, we have been in a cooperation with Samsung trying to help them find the issue, during this investigation we agreed with Samsung not to communicate until their approval.&lt;/p&gt;

&lt;p&gt;As the issue was not reproduced on our server in Singapore, the reproduction
is now running under Samsung supervision in Korea, out of our environment.
Although Samsung requested multiple times an access to our software and
corrupted data, we could not provide it to them in order to protect the
privacy and data of our customers.&lt;/p&gt;

&lt;p&gt;Samsung asked us to inform you about this:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Samsung tried to duplicate the failure with the latest script provided to them, but no single failure has been reproduced so far.&lt;/li&gt;
  &lt;li&gt;Samsung will do further tests, most likely from week 29 onwards, with a much more intensive script provided by Algolia.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After unsuccessful tries to reproduce the issue with Bash scripts we have
decided to help them by creating a small C++ program that simulates the
writing style and pattern of our application (no files are open with
O_DIRECT). We believe that if the issue is coming from a specific way we are
using the standard kernel calls, it might take a couple of days and terabytes
of data to be written to the drive.&lt;/p&gt;

&lt;p&gt;We have been informed by Samsung that no issue of this kind have been reported
to them. Our server provider has modified their Ubuntu 14.04 images to disable
the fstrim cron in order to avoid this issue. For the last couple of months
after not using trim anymore we have not seen the issue again.&lt;/p&gt;

&lt;p&gt;UPDATE July 17:&lt;br /&gt;
We have just finished a conference call with Samsung
considering the failure analysis of this issue. Samsung engineering team has
been able to successfully reproduce the issue with our latest provided binary.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Samsung had a concrete conclusion that the issue is not related to Samsung SSD or Algolia software but is related to the Linux kernel.&lt;/li&gt;
  &lt;li&gt;Samsung has developed a kernel patch to resolve this issue and the official statement with details will be released tomorrow, July 18 on Linux community with the Linux patch guide. Our testing code &lt;a href=&quot;https://github.com/algolia/trimtester&quot;&gt;is available on GitHub&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This has been an amazing ride, thank you everyone for joining, we have arrived
at the destination.&lt;/p&gt;

&lt;hr /&gt;

&lt;p&gt;The &lt;a href=&quot;http://nginx.org/&quot;&gt;NGINX&lt;/a&gt; daemon serving all the HTTP(S) communication of
our API was up and ready to serve the search queries but the indexing process
crashed. Since the indexing process is guarded by
&lt;a href=&quot;http://cr.yp.to/daemontools/supervise.html&quot;&gt;supervise&lt;/a&gt;, crashing in a loop
would have been understandable but a complete crash was not. As it turned out
the filesystem was in a read-only mode. All right, let’s assume it was a
cosmic ray :) the filesystem got fixed, files were restored from another
healthy server and everything looked fine again.&lt;/p&gt;

&lt;p&gt;The next day another server ended with filesystem in read-only, two hours
after another one and then next hour another one. Something was going on.
After restoring the filesystem and the files, it was time for serious analysis
since this was not a one time thing. At this point, we did a breakdown of the
software involved in our storage stack and went through the recent changes.&lt;/p&gt;

&lt;h2 id=&quot;investigation--debugging-time&quot;&gt;Investigation &amp;amp; debugging time!&lt;/h2&gt;

&lt;p&gt;We first asked ourselves if it could be related to our software. Are we using
non-safe system calls or processing the data in an unsafe way? Did we
incorrectly read and write the files in the memory before flushing it to disk?&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Filesystem - Is there a bug in &lt;a href=&quot;https://en.wikipedia.org/wiki/Ext4&quot;&gt;ext4&lt;/a&gt;? Can we access the memory space of allocation tables by accident?&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://raid.wiki.kernel.org/index.php/Linux_Raid&quot;&gt;Mdraid&lt;/a&gt; - Is there a bug in mdadm? Did we use an improper configuration?&lt;/li&gt;
  &lt;li&gt;Driver - Does the driver have a bug?&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Solid-state_drive&quot;&gt;SSD&lt;/a&gt; - Is the SSD dying? Or even worse, is there a problem with the firmware of the drive?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We even started to bet where the problem was and exactly proposed, in this
order, the possible solutions going from easy to super-hard.&lt;/p&gt;

&lt;p&gt;Going through storage procedures of our software stack allowed us to set up
traps and in case the problem happens again, we would be able to better
isolate the corrupted parts. Looking at every single storage call of our
engine gave us enough confidence that the problem was not coming from the way
in which we manipulate the data. Unfortunately.&lt;/p&gt;

&lt;p&gt;One hour later, another server was corrupted. This time we took it out of the
cluster and started to inspect it bit by bit. Before we fixed the filesystem,
we noticed that some pieces of our files were missing (zeroed) - file
modification date was unchanged, size was unchanged, just some parts were
filled with zeros. Small files were completely erased.&lt;/p&gt;

&lt;p&gt;This was weird, so we started to think if it was possible that our application
could access certain portions of the memory where the OS/filesystem had
something mapped because otherwise our application cannot modify a file without
the filesystem noticing. Having our software written in C++ brought a lot of
crazy ideas of what happened. This turned out to be a dead-end as all of these
memory blocks were out of our reach.&lt;/p&gt;

&lt;p&gt;So is there an issue in the ext4? Going through the kernel changelog looking
for ext4 related issues was a terrifying experience. In almost every version
we found a fixed bug that could theoretically impact us. I have to admit, I
slept better before reading the changelog.&lt;/p&gt;

&lt;p&gt;We had kernels 3.2, 3.10, 3.13 and 3.16 distributed between the most often
corrupted machines and waited to see which of the mines blows up. All of them
did. Another dead-end. Maybe there was an issue in ext4 that no one else has
seen before? The chance that we were this “lucky” was quite low and we did not
want to end up in a situation like that. The possibility of a bug in ext4 was
still open but highly improbable.&lt;/p&gt;

&lt;p&gt;What if there was an issue in mdadm? Looking at the changelog gave us
confidence that we should not go down this path.&lt;/p&gt;

&lt;p&gt;The level of despair was reaching a critical level and the pages in the middle
of the night were unstoppable. We spent a big portion of two weeks just
isolating machines as quickly as possible and restoring them as quickly as
possible. The one thing we did was to implement a check in our software that
looked for empty blocks in the index files, even when they were not used, and
alerted us in advance.&lt;/p&gt;

&lt;h2 id=&quot;not-a-single-day-without-corruptions&quot;&gt;Not a single day without corruptions&lt;/h2&gt;

&lt;p&gt;While more and more machines were dying, we had managed to automate the
restore procedure to a level we were comfortable with. At every failure, we
tried to look at different patterns of the corruption in hopes that we would
find the smallest common denominator. They all had the same characteristics.
But one thing started to be more and more clear - we saw the issue only on a
portion of our servers.&lt;/p&gt;

&lt;p&gt;The software stack was identical but the hardware was slightly different. Mainly
the SSDs were different but they were all from the same manufacturer. This was
very alarming and led us to contact our server provider to ask if they have ever
seen something like this before. It’s hard to convince a technical support
person about a problem that you see only once in a while, with the latest
firmware and that you cannot reproduce on demand.  We were not very successful
but at least we had one small victory on our side.&lt;/p&gt;

&lt;p&gt;Knowing that the issue existed somewhere in the combination of the software
and drive itself, we reproduced the identical software stack from our servers
with different drives. And? Nothing, the corruption appeared again. So it was
quite safe to assume the problem was not in the software stack and was more
drive related. But what causes a block to change the content without the rest
of the system noticing? That would be a lot of rotten bits in a sequence…&lt;/p&gt;

&lt;p&gt;The days started to become a routine - long shower, breakfast, restoring
corrupted servers, lunch, restoring corrupted servers, dinner, restoring
corrupted servers. Until one long morning shower full of thinking, “how big
was the sequence?” As it turned out, the lost data was always 512 bytes, which
is one block on the drive.&lt;/p&gt;

&lt;p&gt;One step further, a block ends up to be full of zeroes. A hardware bug? Or is
the block zeroed? What can zero the block?
&lt;a href=&quot;https://en.wikipedia.org/wiki/Trim_(computing)&quot;&gt;TRIM&lt;/a&gt;! Trim instructs the SSD
drive to zero the empty blocks. But these block were not empty and other types
of SSDs were not impacted. We gave it a try and disabled TRIM across all of our
servers. It would explain everything!&lt;/p&gt;

&lt;p&gt;The next day not a single server was corrupted, two days silence, then a week.
The nightmare was over! At least we thought so… a month after we isolated the
problem, a server restarted and came up with corrupted data but only from the
small files - including certificates. Even improper shutdown cannot cause
this.&lt;/p&gt;

&lt;p&gt;Poking around in the source code of the kernel looking for the trim related
code, we came to the &lt;a href=&quot;https://github.com/torvalds/linux/blob/e
64f638483a21105c7ce330d543fa1f1c35b5bc7/drivers/ata/libata-
core.c#L4109-L4286&quot;&gt;trim blacklist&lt;/a&gt;. This blacklist configures a specific behavior for certain
SSD drives and identifies the drives based on the regexp of the model name.
Our working SSDs were explicitly allowed full operation of the TRIM but some
of the SSDs of our affected manufacturer were limited. Our affected drives did
not match any pattern so they were implicitly allowed full operation.&lt;/p&gt;

&lt;h2 id=&quot;the-complete-picture&quot;&gt;The complete picture&lt;/h2&gt;

&lt;p&gt;At this moment we finally got a complete picture of what was going on. The
system was issuing a TRIM to erase empty blocks, the command got
misinterpreted by the drive and the controller erased blocks it was not
supposed to. Therefore our files ended-up with 512 bytes of zeroes, files
smaller than 512 bytes were completely zeroed. When we were lucky enough, the
misbehaving TRIM hit the super-block of the filesystem and caused a
corruption.&lt;/p&gt;

&lt;p&gt;After disabling the TRIM, the live big files were no longer
corrupted but the small files that were once mapped to the memory and never
changed since then had two states - correct content in the memory and
corrupted one on the drive. Running a check on the files found nothing because
they were never fetched again from the drive and just silently read from the
memory. Massive reboot of servers came into play to restore the data
consistency but after many weeks of hunting a ghost we came to the end.&lt;/p&gt;

&lt;p&gt;As a result, we informed our server provider about the affected SSDs and they
informed the manufacturer. Our new deployments were switched to different SSD
drives and we don’t recommend anyone to use any SSD that is anyhow mentioned
in a bad way by the Linux kernel. Also be careful, even when you don’t enable
the TRIM explicitly, at least since Ubuntu 14.04 the explicit
&lt;a href=&quot;http://man7.org/linux/man-pages/man8/fstrim.8.html&quot;&gt;FSTRIM&lt;/a&gt; runs in a cron
once per week on all partitions - the freeze of your storage for a couple of
seconds will be your smallest problem.&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;TL;DR&lt;/h2&gt;

&lt;h3 id=&quot;delbroken-ssdsdel-drives-on-which-we-have-detected-the-issue&quot;&gt;&lt;del&gt;Broken SSDs&lt;/del&gt;: (Drives on which we have detected the issue)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;SAMSUNG MZ7WD480HCGM-00003&lt;/li&gt;
  &lt;li&gt;SAMSUNG MZ7GE480HMHP-00003&lt;/li&gt;
  &lt;li&gt;SAMSUNG MZ7GE240HMGR-00003&lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Samsung SSD 840 PRO Series&lt;br /&gt;
recently blacklisted for 8-series blacklist&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;Samsung SSD 850 PRO 512GB&lt;br /&gt;
recently blacklisted as 850 Pro and later in 8-series blacklist&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;delworking-ssdsdel-drives-on-which-we-have-not-detected-the-issue&quot;&gt;&lt;del&gt;Working SSDs&lt;/del&gt;: (Drives on which we have NOT detected the issue)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Intel S3500&lt;/li&gt;
  &lt;li&gt;Intel S3700&lt;/li&gt;
  &lt;li&gt;Intel S3710&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>We just raised our Series A. What's next?</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/05/28/we-just-raised-our-series-a-whats-next/"/>
   <updated>2015-05-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/05/28/we-just-raised-our-series-a-whats-next</id>
   <content type="html">&lt;p&gt;You may have heard last week in the &lt;a href=&quot;https://www.algolia.com/press&quot;&gt;press&lt;/a&gt;,
Algolia has just raised an $18.3M Series A round of financing led by Accel
Partners! Philippe Botteri from Accel is joining our board and we can’t wait
to benefit from his experience! We are also excited to welcome Lead Edge
Capital and to have received the trust of industry pioneers such as Ilya
Sukhar of Parse, Solomon Hykes of Docker, Erik Swan of Splunk, and Kevin Rose
of Digg.&lt;/p&gt;

&lt;p&gt;This funding represents a major milestone for Algolia. Thanks to the
commitment of our customers our growth last year enabled us to demonstrate a
strong product market fit. We are proud to count many of you as our customers
who have seen in our offer a way to deliver a better search experience,
improving their end-users’ engagement.&lt;/p&gt;

&lt;p&gt;We want to change the way people interact with information. We don’t want
people to “search” in the traditional type-keyword/hit-enter/wait-for-results
/repeat-until-found-or-abandon way; we want them to intuitively access data.
We strongly believe that search should become a frontend and UX priority.
That’s why we focus so much on the two must-haves for building a seamless and
interactive experience: speed which enables updating results as-you-type, and
relevance which ensures that results are good even after only a couple of
keystrokes.&lt;/p&gt;

&lt;p&gt;It’s time for us to accelerate on that vision. With the help of this new
funding, we are going to continue investing in our core product, and in making
it available to an ever-expanding community with many new integrations. Search
is everywhere and you can count on us to come up with new creative ways to
delight your users with an outstanding experience. Stay tuned!&lt;/p&gt;

&lt;p&gt;We will also double down on customer success, which has been so important to
our growth. Please make us accountable and let us know if there is anything we
can improve.&lt;/p&gt;

&lt;p&gt;We have embarked on a journey to change the face of user-facing search,
everywhere. Join us, it’s going to be fun!&lt;/p&gt;

&lt;p&gt;PS: We’re &lt;a href=&quot;https://www.algolia.com/jobs&quot;&gt;hiring&lt;/a&gt;!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>DNS fallback for better resilience</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/05/11/dns-fallback-for-better-resilience/"/>
   <updated>2015-05-11T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/05/11/dns-fallback-for-better-resilience</id>
   <content type="html">&lt;p&gt;At Algolia, we are obsessed with finding a way to have a 99.9999% available
architecture. On our way to achieve that, we have to make sure every piece of
the architecture can safely fail without affecting the service.&lt;/p&gt;

&lt;p&gt;The first point of the architecture where a customer’s request starts to
interact with our service is not the router in the datacenter, but a DNS
resolving a domain name to the IP address “long time” before that. This piece
of architecture is very often overlooked and that is no surprise as you mostly
get best-effort DNS service automatically with your server.&lt;/p&gt;

&lt;h2 id=&quot;latency&quot;&gt;Latency&lt;/h2&gt;

&lt;p&gt;For couple months we are a happy user of &lt;a href=&quot;https://nsone.net&quot;&gt;NSONE&lt;/a&gt; that
provides us with the first level of logic. We use NSONE for its superb
performance and data-driven DNS that gives us control in steering the traffic
of our &lt;a href=&quot;https://www.algolia.com/dsn&quot;&gt;Distributed Search Network&lt;/a&gt; to the proper
server - whether it means closest or simply available one. But as any other
network dependent service, there are factors outside of NSONE’s control that
can influence availability of its DNS resolves and consequently Algolia. BGP
routing is still a huge magic and “optimizations” of some ISPs are beyond
understanding. Well, they do not always make the optimizations in the
direction we would like to. For some services the change of DNS resolution
time from 10 to 500ms does not mean a lot but for us it is a deal breaker.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/05/nsone-dig-latency.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/nsone-dig-latency.png&quot; alt=&quot;nsone-dig-latency&quot; /&gt;&lt;/a&gt; Resolution of latency-1 via NSONE&lt;/p&gt;

&lt;h2 id=&quot;ddos&quot;&gt;DDoS&lt;/h2&gt;

&lt;p&gt;When we started to think about our DNS dependency, we remembered the &lt;a href=&quot;https://threatpost.com/ultradns-dealing-with-ddos-attack/105806&quot;&gt;2014
DDoS attack on UltraDNS&lt;/a&gt; and the situation when there was not enough
&lt;a href=&quot;https://twitter.com/hashtag/hugops&quot;&gt;#hugops&lt;/a&gt; for all the services impacted.
During the previous &lt;a href=&quot;http://www.zdnet.com/article/ddos-attack-on-ultradns-affects-amazon-com-salesforce-com-petco-com/&quot;&gt;attack on UltraDNS in 2009&lt;/a&gt; even
big names like Amazon and SalesForce got impacted.&lt;/p&gt;

&lt;h2 id=&quot;solution&quot;&gt;Solution&lt;/h2&gt;

&lt;p&gt;In most of the cases it would mean adding another DNS name server from a
different provider and replicate the records. But not in ours. NSONE has some
unique features that we would have to give up and find a common feature subset
with a different provider. In the end we would have to serve a portion of DNS
resolutions via slower provider for no good reason.&lt;/p&gt;

&lt;p&gt;Since we provide custom made API clients we have one more place where to put
additional logic. Now came a time to choose a resilient provider for our
secondary DNS and since we like AWS, Route53 was a clear choice. Route53 has
ok performance, many POPs around the world and API we already had integration
for.&lt;/p&gt;

&lt;p&gt;In the last moment, one more paranoid idea came to us - let’s not rely on a
single &lt;a href=&quot;http://en.wikipedia.org/wiki/Top-level_domain&quot;&gt;TLD&lt;/a&gt;. No good reason
for that, it was just “what if…?” moment.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/05/route53-dig-latency.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/route53-dig-latency.png&quot; alt=&quot;route53-dig-latency&quot; /&gt;&lt;/a&gt; Resolution of latency-1 via
Route53&lt;/p&gt;

&lt;p&gt;Right now, all the latest versions of our API clients (detailed list below)
use multiple domain names. “algolia.net” is served by NSONE and provides all
the speed and intelligence, “algolianet.com” is served by Route53 in case that
for any reason contacting server via “algolia.net” fails. It brings more work
to our side, brings more cost on our side but it also brings better sleep for
our customers, their customers and us.&lt;/p&gt;

&lt;p&gt;And now we can think what else can fail…&lt;/p&gt;

&lt;p&gt;Minimal versions of API clients with support of multiple DNS:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/releases/tag/2.9.6&quot;&gt;Javascript v2: 2.9.6&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt;Javascript v3: 3.1.0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-node&quot;&gt;Node.js: 1.8.0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-ruby&quot;&gt;Ruby: 1.4.1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-rails&quot;&gt;Ruby on rails: Ruby dependency 1.4.1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-python&quot;&gt;Python: 1.5.2&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-php&quot;&gt;PHP: 1.5.5&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-java&quot;&gt;Java: 1.3.5&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-android&quot;&gt;Android: 1.6.3&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-objc&quot;&gt;Objective-C: 3.4.1&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-csharp&quot;&gt;C-Sharp: 3.1.0&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-go&quot;&gt;Go: 1.2.0&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Modern JavaScript libraries: the isomorphic way</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/05/06/modern-javascript-libraries-the-isomorphic-way/"/>
   <updated>2015-05-06T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/05/06/modern-javascript-libraries-the-isomorphic-way</id>
   <content type="html">&lt;p&gt;Algolia’s DNA is really about performance. We want our search engine to answer
relevant results as fast as possible.&lt;/p&gt;

&lt;p&gt;To achieve the best end-to-end performance we’ve decided to go with JavaScript
since the total beginning of Algolia. Our end-users search using our REST API
directly from their browser - with JavaScript - without going through the
websites’ backends.&lt;/p&gt;

&lt;p&gt;Our JavaScript &amp;amp; Node.js API clients were implemented 2 years ago and were now
lacking of all modern best practices:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;not following the &lt;a href=&quot;http://fredkschott.com/post/2014/03/understanding-error-first-callbacks-in-node-js/&quot;&gt;error-first&lt;/a&gt; or &lt;a href=&quot;http://blog.izs.me/post/59142742143/designing-apis-for-asynchrony&quot;&gt;callback-last&lt;/a&gt; conventions;&lt;/li&gt;
  &lt;li&gt;inconsistent API between the Node.js and the browser implementations;&lt;/li&gt;
  &lt;li&gt;no &lt;a href=&quot;https://developer.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise&quot;&gt;Promise&lt;/a&gt; support;&lt;/li&gt;
  &lt;li&gt;Node.js module named &lt;a href=&quot;https://www.npmjs.com/package/algolia-search&quot;&gt;algolia-search&lt;/a&gt;, browser module named &lt;a href=&quot;https://www.npmjs.com/package/algoliasearch&quot;&gt;algoliasearch&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;cannot use the same module in Node.js or the browser (obviously);&lt;/li&gt;
  &lt;li&gt;browser module could not be used with &lt;a href=&quot;http://browserify.org/&quot;&gt;browserify&lt;/a&gt; or &lt;a href=&quot;http://webpack.github.io/&quot;&gt;webpack&lt;/a&gt;. It was exporting multiple properties directly in the window object.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This blog post is a summary of the three main challenges we faced while
modernizing our JavaScript client.&lt;/p&gt;

&lt;h2 id=&quot;tldr&quot;&gt;tl;dr;&lt;/h2&gt;

&lt;p&gt;Now the good news: we have a new isomorphic &lt;a href=&quot;http://github.com/algolia/algoliasearch-client-js&quot;&gt;JavaScript API
client&lt;/a&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Isomorphic JavaScript apps are JavaScript applications that can run both
client-side and server-side.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The backend and frontend share the same code.&lt;/p&gt;

&lt;blockquote&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;&lt;a href=&quot;http://isomorphic.net/&quot;&gt;isomorphic.net&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here are the main features of this new API client:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;works in &lt;a href=&quot;https://nodejs.org/&quot;&gt;Node.js&lt;/a&gt; 0.10, 0.12, &lt;a href=&quot;https://iojs.org/en/index.html&quot;&gt;iojs&lt;/a&gt; and from Internet Explorer 8 up to modern browsers;&lt;/li&gt;
  &lt;li&gt;has a &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js#callback-convention&quot;&gt;Promise + callback&lt;/a&gt; API;&lt;/li&gt;
  &lt;li&gt;is available at &lt;a href=&quot;https://www.npmjs.com/package/algoliasearch&quot;&gt;npmjs.com/algoliasearch&lt;/a&gt; and on &lt;a href=&quot;http://cdn.jsdelivr.net/algoliasearch/3/algoliasearch.min.js&quot;&gt;cdn.jsdelivr.net&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;has &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/tree/master/dist&quot;&gt;builds&lt;/a&gt; for jQuery, AngularJS and Parse.com;&lt;/li&gt;
  &lt;li&gt;is compatible with all module loaders like &lt;a href=&quot;http://browserify.org/&quot;&gt;browserify&lt;/a&gt; or &lt;a href=&quot;http://webpack.github.io/&quot;&gt;webpack&lt;/a&gt;;&lt;/li&gt;
  &lt;li&gt;is fully &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/tree/master/test&quot;&gt;tested&lt;/a&gt; in all supported environments.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you were using our previous libraries, we have migration guides for both
&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/wiki/Node.js-v1.x.x-migration-guide&quot;&gt;Node.js&lt;/a&gt; and &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/wiki/Migration-
guide-from-2.x.x-to-3.x.x&quot;&gt;the
browser&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;#&lt;/p&gt;

&lt;h1 id=&quot;challenge-1-testing&quot;&gt;Challenge #1: testing&lt;/h1&gt;

&lt;p&gt;Before being able to merge the Node.js and browser module, we had to remember
how the current code is working. An easy way to understand what a code is
doing is to read the tests. Unfortunately, in the previous version of the
library, we had &lt;a href=&quot;https://github.com/algolia/algoliasearch-
client-js/tree/ba71a68005945c73f7157a8222a9c758e332eceb/test&quot;&gt;only one test&lt;/a&gt;. One test was
not enough to rewrite our library. Let’s go testing!&lt;/p&gt;

&lt;h2 id=&quot;unit-integration&quot;&gt;Unit? Integration?&lt;/h2&gt;

&lt;p&gt;When no tests are written on a library of &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/ba71a68005945c73f7157a8222a9c758e332eceb/src/algoliasearch.js#L1484&quot;&gt;~1500+
LOC&lt;/a&gt;,
what are the tests you should write first?&lt;/p&gt;

&lt;p&gt;Unit testing would be too close to the implementation. As we are going to
rewrite a lot of code later on, we better not go too far on this road right
now.&lt;/p&gt;

&lt;p&gt;Here’s the flow of our JavaScript library when doing a search:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;initialize the library with &lt;code&gt;algoliasearch()&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;call &lt;code&gt;index.search(&#39;something&#39;, callback)&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;browser issue an HTTP request&lt;/li&gt;
  &lt;li&gt;&lt;code&gt;callback(err, content)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;From a testing point of view, this can be summarized as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;input: method call&lt;/li&gt;
  &lt;li&gt;output: HTTP request&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Integration testing for a JavaScript library doing HTTP calls is interesting
but does not scale well.&lt;/p&gt;

&lt;p&gt;Indeed, having to reach Algolia servers in each test would introduce a shared
testing state amongst developers and continuous integration. It would also
have a slow TDD feedback because of heavy network usage.&lt;/p&gt;

&lt;p&gt;Our strategy for testing our JavaScript API client was to mock (do not run
away right now) the &lt;a href=&quot;https://xhr.spec.whatwg.org/&quot;&gt;XMLHttpRequest&lt;/a&gt; object.
This allowed us to test our module as a black box, providing a good base for a
complete rewrite later on.&lt;/p&gt;

&lt;p&gt;This is not unit testing nor integration testing, but in between. We also
planned in the coming weeks on doing a separate full integration testing suite
that will go from the browser to our servers.&lt;/p&gt;

&lt;h2 id=&quot;faux-jax-to-the-rescue&quot;&gt;faux-jax to the rescue&lt;/h2&gt;

&lt;p&gt;Two serious candidates showed up to help in testing HTTP request based
libraries&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/pgte/nock&quot;&gt;pgte/nock &lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;and &lt;a href=&quot;http://sinonjs.org/docs/#server&quot;&gt;Sinon.js fake XMLHttpRequest&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Unfortunately, none of them met all our requirements. Not to mention, the
AlgoliaSearch JavaScript client had a really smart failover request strategy:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;use &lt;a href=&quot;https://xhr.spec.whatwg.org/&quot;&gt;XMLHttpRequest&lt;/a&gt; for browsers supporting CORS,&lt;/li&gt;
  &lt;li&gt;or use &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/ie/cc288060%28v=vs.85%29.aspx&quot;&gt;XDomainRequest&lt;/a&gt; for &lt;a href=&quot;http://caniuse.com/#feat=cors&quot;&gt;IE &amp;lt; 10&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;or use &lt;a href=&quot;https://blog.algolia.com/jsonp-still-mandatory/&quot;&gt;JSONP&lt;/a&gt; in situations where none of the preceding is available.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This seems complex but we really want to be available and compatible with
every browser environment.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Nock&lt;/strong&gt; works by mocking calls to the Node.js &lt;a href=&quot;https://nodejs.org/api/http.html&quot;&gt;http module&lt;/a&gt;, but we directly use the XMLHttpRequest object.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sinon.js&lt;/strong&gt; was doing a good job but &lt;a href=&quot;https://github.com/cjohansen/Sinon.JS/pull/600#issuecomment-74000915&quot;&gt;was lacking&lt;/a&gt; some &lt;a href=&quot;https://msdn.microsoft.com/en-us/library/ie/cc288060%28v=vs.85%29.aspx&quot;&gt;XDomainRequest&lt;/a&gt; feature detections. Also it was really tied to Sinon.js.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As a result, we created &lt;a href=&quot;https://github.com/algolia/faux-
jax&quot;&gt;algolia/faux-jax&lt;/a&gt;. It is now pretty stable and can mock XMLHttpRequest, XDomainRequest and
even http module from Node.js. It means &lt;strong&gt;faux-jax&lt;/strong&gt; is an isomorphic HTTP
mock testing tool. It was not designed to be isomorphic. It was easy to add
the Node.js support thanks to &lt;a href=&quot;https://github.com/moll/node-
mitm&quot;&gt;moll/node-mitm&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;testing-stack&quot;&gt;Testing stack&lt;/h2&gt;

&lt;p&gt;The testing stack is composed of:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/substack/tape/&quot;&gt;substack/tape&lt;/a&gt;, isomorphic testing and assertion framework&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/defunctzombie/zuul/&quot;&gt;defunctzombie/zuul&lt;/a&gt;, local and continuous integration test runner&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/faux-jax&quot;&gt;algolia/faux-jax&lt;/a&gt;, isomorphic HTTP mocking library&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The fun part is done, now onto the tedious one: &lt;strong&gt;writing tests&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;spliting-tests-cases&quot;&gt;Spliting tests cases&lt;/h2&gt;

&lt;p&gt;We divided our tests in two categories:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;simple test cases&lt;/strong&gt;: check that an API command will generate the corresponding HTTP call&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;advanced tests&lt;/strong&gt;: timeouts, keep-alive, JSONP, request strategy, DNS fallback, ..&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;simple-test-cases&quot;&gt;Simple test cases&lt;/h3&gt;

&lt;p&gt;Simple test cases were written as &lt;a href=&quot;https://github.com/golang/go/wiki/TableDrivenTests&quot;&gt;table driven
tests&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com
/wp-content/uploads/2015/04/2015-04-27-161853_1266x829_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-161853_1266x829_scrot.png&quot; alt=&quot;It&#39;s a simple
JavaScript file, exporting test cases as an
array&quot; /&gt;&lt;/a&gt; It’s a
simple JavaScript file, &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/test/spec/common/index/test-
cases/addUserKey.js#L1&quot;&gt;exporting test cases as an
array&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Creating a testing stack that understands theses test-cases was some work. But
the reward was worth it: the TDD feedback loop is great. Adding a new feature
is easy: fire editor, add test, implement annnnnd done.&lt;/p&gt;

&lt;h3 id=&quot;advanced-tests&quot;&gt;Advanced tests&lt;/h3&gt;

&lt;p&gt;Complex test cases like JSONP fallback, timeouts and errors, were handled in
separate, &lt;a href=&quot;https://github.com/algolia/algoliasearch-
client-js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/test/spec/browser
/request-strategy/use-JSONP-when-XHR-error.js&quot;&gt;more advanced tests&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-27-162229_1258x982_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-162229_1258x982_scrot.png&quot; alt=&quot;Our testing
stack rely on substack/tape&quot; /&gt;&lt;/a&gt; Here we test
that we are using JSONP when XHR fails&lt;/p&gt;

&lt;h2 id=&quot;testing-workflow&quot;&gt;Testing workflow&lt;/h2&gt;

&lt;p&gt;To be able to run our tests we chose
&lt;a href=&quot;https://github.com/defunctzombie/zuul/&quot;&gt;defunctzombie/zuul&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&quot;local-development&quot;&gt;Local development&lt;/h3&gt;

&lt;p&gt;For local development, we have an &lt;strong&gt;npm test&lt;/strong&gt; task that will:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;launch the browser tests using &lt;a href=&quot;http://phantomjs.org/&quot;&gt;phantomjs&lt;/a&gt;,&lt;/li&gt;
  &lt;li&gt;run the Node.js tests,&lt;/li&gt;
  &lt;li&gt;lint using &lt;a href=&quot;http://eslint.org/&quot;&gt;eslint&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;You can &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/package.json#L12&quot;&gt;see the task&lt;/a&gt; in the
package.json. Once run it looks like this:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-27-170339_976x845_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-170339_976x845_scrot.png&quot; alt=&quot;640 passing
assertions and counting!&quot; /&gt;&lt;/a&gt; 640 passing
assertions and counting!&lt;/p&gt;

&lt;p&gt;But phantomjs is no real browser so it should not be the only answer to “Is my
module working in browsers?”. To solve this, we have an &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/package.json#L16&quot;&gt;npm run
dev&lt;/a&gt; task that
will expose our tests in a simple web server accessible by any browser:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-27-170757_1288x486_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-170757_1288x486_scrot.png&quot; alt=&quot;All of theses
features are provided by defunctzombie/zuul&quot; /&gt;&lt;/a&gt; All of theses
features are provided by defunctzombie/zuul&lt;/p&gt;

&lt;p&gt;Finally, if you have &lt;a href=&quot;https://www.virtualbox.org/&quot;&gt;virtual machines&lt;/a&gt;, you can
test in any browser you want, all locally:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-27-171034_1296x385_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-171034_1296x385_scrot.png&quot; alt=&quot;Here&#39;s a
VirtualBox setup created with xdissent/ievms&quot; /&gt;&lt;/a&gt; Here’s a
VirtualBox setup created with
&lt;a href=&quot;https://github.com/xdissent/ievms&quot;&gt;xdissent/ievms&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;What comes next after setting up a good local development workflow? Continuous
integration setup!&lt;/p&gt;

&lt;h3 id=&quot;continuous-integration&quot;&gt;Continuous integration&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/defunctzombie/zuul/&quot;&gt;defunctzombie/zuul&lt;/a&gt; supports running
tests using &lt;a href=&quot;https://saucelabs.com/&quot;&gt;Saucelabs&lt;/a&gt; browsers. Saucelabs provides
browsers as a service (manual testing or Selenium automation). It also has a
nice OSS plan called &lt;a href=&quot;https://saucelabs.com/opensauce/&quot;&gt;Opensauce&lt;/a&gt;. We patched
our &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/.zuul.yml&quot;&gt;.zuul.yml&lt;/a&gt; configuration file
to specify what browsers we want to test. You can find all the details in
&lt;a href=&quot;https://github.com/defunctzombie/zuul/wiki/Cloud-testing&quot;&gt;zuul’s wiki&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now there’s only one missing piece: &lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis CI&lt;/a&gt;.
Travis runs our tests in all browsers defined in our .zuul.yml file. Our
&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/.travis.yml&quot;&gt;travis.yml&lt;/a&gt; looks like this:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-27-172249_1248x868_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-172249_1248x868_scrot.png&quot; alt=&quot;All platforms are tested using travis
matrixes&quot; /&gt;
&lt;/a&gt;
All platforms are tested using a &lt;a href=&quot;http://docs.travis-ci.com/user/build-configuration/#The-Build-Matrix&quot;&gt;travis build
matrix&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Right now tests are taking a bit too long so we will soon split them between
desktop and mobile.&lt;/p&gt;

&lt;p&gt;We also want to to tests on pull requests using only latest stable versions of
all browsers. So that it does not takes too long. As a reward, we get a &lt;a href=&quot;https://docs.saucelabs.com/reference/status-images/&quot;&gt;nice
badge&lt;/a&gt; to display in our
Github &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js#algolia-
search-api-client-for-javascript&quot;&gt;readme&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com
/wp-content/uploads/2015/04/2015-04-27-174139_920x306_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-27-174139_920x306_scrot.png&quot; alt=&quot;Gray color
means the test is currently
running&quot; /&gt;&lt;/a&gt; Gray color
means the test is currently running&lt;/p&gt;

&lt;h1 id=&quot;challenge-2-redesign-and-rewrite&quot;&gt;Challenge #2: redesign and rewrite&lt;/h1&gt;

&lt;p&gt;Once we had a usable testing stack, we started our rewrite, the &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/issues?q=milestone%3AV3&quot;&gt;V3
milestone&lt;/a&gt; on Github.&lt;/p&gt;

&lt;h2 id=&quot;initialization&quot;&gt;Initialization&lt;/h2&gt;

&lt;p&gt;We dropped the &lt;strong&gt;new AlgoliaSearch()&lt;/strong&gt; usage in favor of just
&lt;strong&gt;algoliasearch()&lt;/strong&gt;. It allows us to hide implementation details to our API
users.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;new AlgoliaSearch(applicationID, apiKey, opts);&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;algoliasearch(applicationID, apiKey, opts);&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;callback-convention&quot;&gt;Callback convention&lt;/h2&gt;

&lt;p&gt;Our JavaScript client now follows the &lt;a href=&quot;http://fredkschott.com/post/2014/03/understanding-error-first-
callbacks-in-node-js/&quot;&gt;error-
first&lt;/a&gt; and &lt;a href=&quot;http://blog.izs.me/post/59142742143
/designing-apis-for-asynchrony&quot;&gt;callback-last&lt;/a&gt; conventions. We had to break some methods to
do so.&lt;/p&gt;

&lt;p&gt;Before:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;client.method(param, callback, param, param);&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;After:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;client.method(params, param, param, params, callback);&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;This allows our callback lovers to use libraries like
&lt;a href=&quot;https://github.com/caolan/async&quot;&gt;caolan/async&lt;/a&gt; very easily.&lt;/p&gt;

&lt;h2 id=&quot;promises-and-callbacks-support&quot;&gt;Promises and callbacks support&lt;/h2&gt;

&lt;p&gt;Promises are a great way to handle the asynchronous flow of your application.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Promise partisan? Callback connoisseur? My API now lets you switch between
the two! &lt;a href=&quot;http://t.co/uPhej2yAwF&quot;&gt;http://t.co/uPhej2yAwF&lt;/a&gt; (thanks
&lt;a href=&quot;https://twitter.com/NickColley&quot;&gt;@NickColley&lt;/a&gt;!)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;blockquote&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;— pouchdb (@pouchdb) &lt;a href=&quot;https://twitter.com/pouchdb/status/575310959947956224&quot;&gt;March 10,
2015&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;We implemented both promises and callbacks, it was nearly a no-brainer. In
every command, if you do not provide a callback, you get a &lt;a href=&quot;https://d
eveloper.mozilla.org/en/docs/Web/JavaScript/Reference/Global_Objects/Promise&quot;&gt;Promise&lt;/a&gt;.
We use native promises in &lt;a href=&quot;http://caniuse.com/#feat=promises&quot;&gt;compatible
environments&lt;/a&gt; and
&lt;a href=&quot;https://github.com/jakearchibald/es6-promise/&quot;&gt;jakearchibald/es6-promise&lt;/a&gt; as
a polyfill.&lt;/p&gt;

&lt;h2 id=&quot;algoliasearchhelper-removal&quot;&gt;AlgoliaSearchHelper removal&lt;/h2&gt;

&lt;p&gt;The main library was also previously exporting window.AlgoliaSearchHelper to
ease the development of awesome search UIs. We externalized this project and
it now has now has a new home at &lt;a href=&quot;https://github.com/algolia/algoliasearch-helper-js&quot;&gt;algolia/algoliasearch-helper-
js&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;umd&quot;&gt;UMD&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;UMD: JavaScript modules that run anywhere&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;The previous version was directly exporting multiple properties in the
&lt;strong&gt;window&lt;/strong&gt; object. As we wanted our new library to be easily compatible with a
broad range of module loaders, we made it &lt;a href=&quot;https://github.com/umdjs/umd&quot;&gt;UMD&lt;/a&gt;
compatible. It means our library can be used:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;with a simple &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;, it will export &lt;strong&gt;algoliasearch&lt;/strong&gt; in the &lt;strong&gt;window&lt;/strong&gt; object&lt;/li&gt;
  &lt;li&gt;using &lt;a href=&quot;http://browserify.org/&quot;&gt;browserify&lt;/a&gt;, &lt;a href=&quot;http://webpack.github.io/&quot;&gt;webpack&lt;/a&gt;, &lt;a href=&quot;http://requirejs.org/&quot;&gt;requirejs&lt;/a&gt;: any module loader&lt;/li&gt;
  &lt;li&gt;in &lt;a href=&quot;https://nodejs.org/&quot;&gt;Node.js&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This was achieved by writing our code in a
&lt;a href=&quot;http://en.wikipedia.org/wiki/CommonJS&quot;&gt;CommonJS&lt;/a&gt; style and then use the
standalone build feature of browserify.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-28-224616_1126x129_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-28-224616_1126x129_scrot.png&quot; alt=&quot;see browserify
usage&quot; /&gt;&lt;/a&gt; see
&lt;a href=&quot;https://github.com/substack/node-
browserify#usage&quot;&gt;browserify usage&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;multiple-builds&quot;&gt;Multiple builds&lt;/h2&gt;

&lt;p&gt;Our JavaScript client isn’t only one build, we have multiple builds:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;vanilla JavaScript using native xhrs and Promises&lt;/li&gt;
  &lt;li&gt;jQuery build using &lt;a href=&quot;http://api.jquery.com/jquery.ajax/&quot;&gt;jQuery.ajax&lt;/a&gt; and returns &lt;a href=&quot;https://api.jquery.com/category/deferred-object/&quot;&gt;jQuery promises&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;AngularJS build is using &lt;a href=&quot;https://docs.angularjs.org/api/ng/service/$http&quot;&gt;$http&lt;/a&gt; service and returns &lt;a href=&quot;https://docs.angularjs.org/api/ng/service/$q&quot;&gt;AngularJS promises&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://parse.com/&quot;&gt;Parse.com&lt;/a&gt; build is using parse cloud &lt;a href=&quot;https://parse.com/docs/cloud_code_guide#networking&quot;&gt;http&lt;/a&gt; and &lt;a href=&quot;https://parse.com/docs/js_guide#promises&quot;&gt;promises&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Node.js, iojs are using the &lt;a href=&quot;https://nodejs.org/api/http.html&quot;&gt;http module&lt;/a&gt; and native Promises&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Previously this was all handled in the main JavaScript file, leading to unsafe
&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/blob/ba71a
68005945c73f7157a8222a9c758e332eceb/src/algoliasearch.js#L541-L553&quot;&gt;code like this&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-28-225743_1629x497_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-28-225743_1629x497_scrot.png&quot; alt=&quot;2015-04-28-225743_1629x497_scrot&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;How do we solve this? Using inheritance! JavaScript prototypal inheritance is
the new code smell in 2015. For us it was a good way to share most of the code
between our builds. As a result every entry point of our builds are inheriting
from the &lt;a href=&quot;https://github.com/algolia/algoliasearch-
client-js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/src/AlgoliaSearch.js&quot;&gt;src/AlgoliaSearch.js&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Every build then need to define how to:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;do http request through &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/src/browser/builds/algoliasearch.js#L46-L150&quot;&gt;AlgoliaSearch.prototype._request&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;return promises with &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/src/browser/builds/algoliasearch.js#L167-L179&quot;&gt;AlgoliaSearch.prototype._promise&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;use a request fallback where needed with &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/src/browser/builds/algoliasearch.js#L152-L165&quot;&gt;AlgoliaSearch.prototype._request.fallback&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Using a simple inheritance pattern we were able to solve a great challenge.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com
/wp-content/uploads/2015/04/2015-04-28-232019_1153x526_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-28-232019_1153x526_scrot.png&quot; alt=&quot;Example of the
vanilla JavaScript
build&quot; /&gt;&lt;/a&gt; Example of
the vanilla JavaScript build&lt;/p&gt;

&lt;p&gt;Finally, we have &lt;a href=&quot;https://github.com/algolia/algoliasearch-
client-js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/scripts/build&quot;&gt;a build script&lt;/a&gt; that
will generate all the needed files for each environment.&lt;/p&gt;

&lt;h2 id=&quot;challenge-3-backward-compatibility&quot;&gt;Challenge #3: backward compatibility&lt;/h2&gt;

&lt;p&gt;We could not completely modernize our JavaScript clients while keeping a full
backward compatibility between versions. We had to break some of the previous
usages to level up our JavaScript stack.&lt;/p&gt;

&lt;p&gt;But we also wanted to provide a good experience for our previous users when
they wanted to upgrade:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;we re-exported previous constructors like window.AlgoliaSearch*. But we now &lt;strong&gt;throw&lt;/strong&gt; if it’s used&lt;/li&gt;
  &lt;li&gt;we wrote a clear &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js/wiki/Migration-guide-from-2.x.x-to-3.x.x&quot;&gt;migration guide&lt;/a&gt; for our existing Node.js and JavaScript users&lt;/li&gt;
  &lt;li&gt;we used &lt;a href=&quot;https://docs.npmjs.com/cli/deprecate&quot;&gt;npm deprecate&lt;/a&gt; on our previous Node.js module to inform our current user base that we moved to a new client&lt;/li&gt;
  &lt;li&gt;we created legacy branches so that we can continue to push critical updates to previous versions when needed&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;make-it-isomorphic&quot;&gt;Make it isomorphic!&lt;/h2&gt;

&lt;p&gt;Our final step was to make our JavaScript client work in both Node.js and the
browser.&lt;/p&gt;

&lt;p&gt;Having separated the builds implementation helped us a lot, because the
Node.js build is a regular build only using the http module from Node.js.&lt;/p&gt;

&lt;p&gt;Then we only had to tell module loaders to load &lt;strong&gt;index.js&lt;/strong&gt; on the server and
&lt;strong&gt;src/browser/..&lt;/strong&gt; in browsers.&lt;/p&gt;

&lt;p&gt;This last step was done by configuring browserify in &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-
js/blob/1c8df9d09d683915a414e7df87a14236e50dd53c/package.json#L5-L8&quot;&gt;our
package.json&lt;/a&gt;:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2015/04/2015-04-28-232444_1275x569_scrot.png&quot;&gt;&lt;img src=&quot;assets/2015-04-28-232444_1275x569_scrot.png&quot; alt=&quot;the browser field from browserify also works in webpack&quot; /&gt;&lt;/a&gt; the &lt;a href=&quot;https://github.com/substack/node-browserify#browser-field&quot;&gt;browser
field&lt;/a&gt; from
browserify also works in webpack&lt;/p&gt;

&lt;p&gt;If you are using the &lt;strong&gt;algoliasearch&lt;/strong&gt; module with browserify or webpack, you
will get our browser implementation automatically.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;faux-jax&lt;/strong&gt; library is released under MIT like all our open source
projects. Any feedback or improvement idea are welcome, we are dedicated to
make our JS client your best friend :)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Quadrant.io solves the frustration of economic data search with Algolia</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/04/20/quadrant-io-solves-the-frustration-of-economic-data-search-with-algolia/"/>
   <updated>2015-04-20T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/04/20/quadrant-io-solves-the-frustration-of-economic-data-search-with-algolia</id>
   <content type="html">&lt;p&gt;Browsing the cumbersome interfaces of government websites in the lookout for
reliable data can be a very frustrating experience. It’s full of specific
terminology and there’s not a government website that looks the same. It’s
like each time you want to use a car, you have to learn to drive all over
again.&lt;/p&gt;

&lt;h2 id=&quot;connect-ideas-with-economic-insight-in-a-matter-of-seconds&quot;&gt;Connect ideas with economic insight in a matter of seconds&lt;/h2&gt;

&lt;p&gt;That’s what &lt;a href=&quot;https://www.quadrant.io/find/#/search&quot;&gt;Quadrant.io&lt;/a&gt; is for.
Solving the frustration anyone who makes their points with facts encounters
when routinely performing data search. It offers them with the fastest and
easiest way to find and chart economic data from trusted sources.
Acknowledging that it can quickly become a nightmare to find reliable
information scattered all over the web,
&lt;a href=&quot;https://www.quadrant.io/find/#/search&quot;&gt;Quadrant&lt;/a&gt; is on a mission to &lt;strong&gt;shorten
any data search to seconds&lt;/strong&gt;. &lt;strong&gt;So that data users can spend less time finding
data and more time analysing it.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;To keep this promise, Quadrant provides data users with an intuitive platform
that aggregates more than 400,000 indicators from over 1,000 public sources,
and keep them updated in real time. &lt;strong&gt;A powerful search allowing any user to
find exactly what they are looking for even if they do not use economists’
jargon&lt;/strong&gt; is a must-have functionality in such a service.&lt;/p&gt;

&lt;p&gt;And Algolia stood out as the perfect search solution for Quadrant.&lt;/p&gt;

&lt;h2 id=&quot;provide-a-rewarding-search-experience-to-end-users&quot;&gt;Provide a rewarding search experience to End-Users&lt;/h2&gt;

&lt;p&gt;First because of** the rewarding search experience it allows to deliver to its
users.**&lt;/p&gt;

&lt;p&gt;Algolia surfaces data relevant to people’s search in milliseconds, showing the
most appropriate results from the very first keystroke.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/searchquadrant1.gif&quot; alt=&quot;searchquadrant1&quot; /&gt;&lt;/p&gt;

&lt;p&gt;It enables to search across different entry points corresponding to the
different attributes describing data series (release date, source).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2015-04-13-at-18.06.28.png&quot; alt=&quot;Screen-Shot-2015-04-13-at-18.06.28&quot; /&gt;&lt;/p&gt;

&lt;p&gt;That wasn’t possible with other search solutions they tested before. After
implementing Algolia, Quadrant.io received nice feedback from their customers,
saying that “search was much more comfortable, much more intuitive”.&lt;/p&gt;

&lt;h2 id=&quot;algolia-empowers-anyone-to-be-a-search-expert&quot;&gt;Algolia empowers anyone to be a search expert&lt;/h2&gt;

&lt;p&gt;Second, because of the simple experience it is to deploy Algolia on their web
app. Back-end documentation and customer support was a major help: it took
them &lt;strong&gt;less than a week to implement instant search&lt;/strong&gt;, including relevance
tweaking and front-end development. As Dane Vrabrac, co-founder of Quadrant.io
concluded “with Algolia, it’s awesome all the stuff I can do as a non
developer !”&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Images courtesy of Quadrant.io. Learn more on their
&lt;a href=&quot;https://quadrant.io/&quot;&gt;website&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Don't let network latency ruin the search experience of your international users</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/02/18/distributed-search-network-latency-ruins-search-experience/"/>
   <updated>2015-02-18T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/02/18/distributed-search-network-latency-ruins-search-experience</id>
   <content type="html">&lt;p&gt;At Algolia, we allow developers to provide a unique interactive search
experience with as-you-type search, instant faceting, mobile geo-search and on
the fly spell check.&lt;/p&gt;

&lt;p&gt;Our Distributed Search Network aims at removing the impact of network latency
on the speed of search, allowing our customers to offer this instant
experience to all their end-users, wherever they may be.&lt;/p&gt;

&lt;h2 id=&quot;every-millisecond-matters&quot;&gt;Every millisecond matters&lt;/h2&gt;

&lt;p&gt;We are obsessed with speed and we’re not the only ones: Amazon found out that
100ms in added latency cost them 1% in sales. &lt;a href=&quot;http://glinden.blogspot.fr/2006/11/marissa-mayer-at-web-20.html&quot;&gt;The lack of responsiveness for
a search engine can really be damaging for one’s
business&lt;/a&gt;. As
individuals, we are all spoiled when it comes to our search expectations:
Google has conditioned the whole planet to expect instant results from
anywhere around the world.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/user-experience.jpg&quot; alt=&quot;user-experience&quot; /&gt;&lt;/p&gt;

&lt;p&gt;We have the exact same expectations with any online service we use. The thing
is that for anyone who is not Google, &lt;strong&gt;it is just impossible to meet these
expectations&lt;/strong&gt; because of the network latency due to the physical distance
between the service backend that hosts the search engine and the location of
the end-user.&lt;/p&gt;

&lt;p&gt;Even with the fastest search engine in the world, it can still take hundreds
of milliseconds for a search result to reach Sydney from San Francisco. And
this is without counting the bandwidth limitations of a saturated oversea
fiber!&lt;/p&gt;

&lt;h2 id=&quot;how-we-beat-the-speed-of-light&quot;&gt;How we beat the speed of light&lt;/h2&gt;

&lt;p&gt;Algolia’s Distributed Search Network (DSN) removes the latency from the speed
equation by &lt;strong&gt;replicating your indices to different regions around the world,
where your users are&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Your local search engines are clones synchronized across the world. DSN allows
you to &lt;strong&gt;distribute your search among 12 locations&lt;/strong&gt; including the US,
Australia, Brazil, Canada, France, Germany, Hong Kong, India, Japan, Russia,
and Singapore. Thanks to our 12 data centers, your search engine can now
&lt;strong&gt;deliver search results under 50ms in the world’s top markets&lt;/strong&gt;, ensuring an
optimal experience for all your users.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/DSN-b3ce122c790c492c2f2c8ddbabaae464.jpg&quot; alt=&quot;DSN-b3ce122c790c492c2f2c8ddbabaae464&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;how-you-activate-dsn&quot;&gt;How you activate DSN&lt;/h2&gt;

&lt;p&gt;Today, DSN is only accessible to our Starter, Growth, Pro and Enterprise plan
customers. To activate it, you simply need to go in the &lt;strong&gt;“Region” tab at the
top of your Algolia dashboard and select “Setup DSN”&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.algolia.com/dsn/setup&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/shot.jpg&quot; alt=&quot;shot&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You will then be displayed with a map and a selection of your top countries in
terms of search traffic. Just &lt;strong&gt;select our DSN data centers on the map and see
how performance in those countries is optimized&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Algolia will then automatically take care of the distribution and the
synchronization of your indices around the world. End-users’ queries will be
automatically routed to the closest data center among those you’ve selected,
ensuring the best possible experience. Algolia DSN delivers an ultra low
response time and automatic fail-over on another region if a region is down.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.algolia.com/dsn/setup&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/dsn-shot.jpg&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;It is that simple!&lt;/p&gt;

&lt;p&gt;Today, several services including HackerNews, TeeSpring, Product Hunt and
Zendesk are leveraging &lt;strong&gt;Algolia DSN to provide faster search to their global
users&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;Want to find out more about the Algolia experience ?&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://www.algolia.com/features&quot;&gt;Discover and try it here&lt;/a&gt;!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>New experimental version of Hacker News Search built with Algolia</title>
   <link href="https://github.com/svenhutchinson/extensions/2015/01/12/try-new-experimental-version-hn-search/"/>
   <updated>2015-01-12T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2015/01/12/try-new-experimental-version-hn-search</id>
   <content type="html">&lt;p&gt;Exactly a year ago, we began to power the Hacker News search engine (see our
&lt;a href=&quot;http://blog.algolia.com/hacker-news-search-algolia/)&quot;&gt;blog post&lt;/a&gt;. Since then,
our HN search project has grown a lot, expanding &lt;strong&gt;from 20M to 25M indexed
items&lt;/strong&gt;, and serving** from 900K to 30M searches a month**.&lt;/p&gt;

&lt;p&gt;In addition to &lt;a href=&quot;http://hn.algolia.com&quot;&gt;hn.algolia.com&lt;/a&gt; we’re also providing&lt;/p&gt;

&lt;p&gt;build various readers or monitor tools and we love the applications you’re
building on top of us. The community was also pretty active on
&lt;a href=&quot;https://github.com/algolia/hn-search/issues&quot;&gt;GitHub&lt;/a&gt;, requesting improvements
and catching bugs… keep on contributing!&lt;/p&gt;

&lt;h2 id=&quot;eating-our-own-dog-food-on-hn-search&quot;&gt;Eating our own dog food on HN search&lt;/h2&gt;

&lt;p&gt;We are &lt;strong&gt;power users of Hacker News&lt;/strong&gt; and there isn’t a single day we don’t
use it. Being able to use our own engine on a tool that is so important to us
has been a unique opportunity to &lt;strong&gt;eat our &lt;/strong&gt;&lt;strong&gt;own dog food.&lt;/strong&gt; We’ve added a
lot of API features during the year but unfortunately didn’t have the time to
refresh the UI so far.&lt;/p&gt;

&lt;p&gt;One of our 2015 resolutions was to push the envelope of the HN search UI/UX:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;make it more &lt;strong&gt;readable&lt;/strong&gt;,&lt;/li&gt;
  &lt;li&gt;more &lt;strong&gt;usable&lt;/strong&gt;,&lt;/li&gt;
  &lt;li&gt;and use &lt;strong&gt;modern&lt;/strong&gt; frontend frameworks.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That’s what motivated us to release a &lt;a href=&quot;https://new-hn.algolia.com/?experimental&quot;&gt;new experimental version of HN
Search&lt;/a&gt;. Try it out and tell us what
you think!&lt;/p&gt;

&lt;h2 id=&quot;applying-more-ui-best-practices&quot;&gt;Applying more UI best practices&lt;/h2&gt;

&lt;p&gt;We’ve learned a lot of things from the
&lt;a href=&quot;https://news.ycombinator.com/item?id=7451206&quot;&gt;comments&lt;/a&gt; of the users of the
previous version. We also took a look at all the &lt;a href=&quot;http://hn.algolia.com/cool_apps&quot;&gt;cool
apps&lt;/a&gt; built on top of our API. We wanted to
apply more UI best practices and here is what we ended with:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420906940736_Screen%20Shot%202015-01-10%20at%2017.22.06.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;focus-on-instantaneity&quot;&gt;Focus on instantaneity&lt;/h3&gt;

&lt;p&gt;The whole layout has been designed to provide an instant experience, reducing
the wait time before the actual content is displayed. It’s also a way to
reduce the number of mouse clicks needed to access and navigate through the
content. The danger with that kind of structure can be to end up with a
flickering UI where each user action redraw the page, activating unwanted
behaviors and consuming a huge amount of memory.We focused on a smooth
experience. Some of the techniques used are based on basic performance
optimizations but in the end what really matters for us is the user’s
perception of latency between each interactions, more than objective
performance. Here are some of the tricks we applied:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Toggle comments&lt;/strong&gt;: we wanted the user to be able to read all the comments of a story on the same page, our API on top of Firebase allowed us to load and display them with a single call.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sticky posts&lt;/strong&gt;: in some cases we are loading up to 500 comments, we wanted the user to be able to keep the information of what he is reading and easily collapse it, so we decided to keep the initial post on top of the list.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lazy-loading of non-cached images&lt;/strong&gt;: when you are refreshing the UI for each request you don’t want every thumbnail to flick on the UI when loading. So we applied a simple fade to avoid that. But there is actually no way to know if an image is already loaded or not from a previous query. We manage to detect that with a small timeout.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Loading feedback&lt;/strong&gt;: the most important part of a reactive UI is to always give the user a feedback on the state of the UI. We choose to add this information with a thin loading bar on top of the page.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deferring the load of some unnecessary elements&lt;/strong&gt;: this one is about performance. When you are displaying about 20 repeatable items on each keypress you want them as light as possible. In our case we are using Angular.js with some directives which were too slow to render. So we ended up rendering them only if the user interact with them.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cache every requests&lt;/strong&gt;: It’s mainly about the backspace key. When a user want to modify his query by removing some characters you don’t want to make him wait for the result: that’s cached by the Algolia JS API client.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;focus-on-readability&quot;&gt;Focus on readability&lt;/h3&gt;

&lt;p&gt;We’ve learned a lot from your comments while releasing our first HN Search
version last year. Readability of the search results must be outstanding to
allow you to quickly understand why the results are retrieved and what they
are about. We ended up with 2 gray colors and 2 font weights to ease the
readability without being too distracting.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420909252393_Screen%20Shot%202015-01-10%20at%2018.00.12.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;stay-as-minimal-as-possible&quot;&gt;Stay as minimal as possible&lt;/h3&gt;

&lt;p&gt;If you see unnecessary stuffs, please tell us. We are not looking for the most
‘minimal’ UI but for the right balance between usability and minimalism.&lt;/p&gt;

&lt;h3 id=&quot;sorting--filtering-improvements&quot;&gt;Sorting &amp;amp; Filtering improvements&lt;/h3&gt;

&lt;p&gt;Most HN Search users are advanced users. They know exactly what they are
searching for and want to have the ability to sort and filter their results
precisely. We are now exposing a simple way to either sort results by date or
popularity in addition to the period filtering capabilities we already had.&lt;/p&gt;

&lt;h3 id=&quot;inlined-comments&quot;&gt;Inlined comments&lt;/h3&gt;

&lt;p&gt;We thought it could make a lot of sense to be able to read the comments of a
story directly from the search result page. Keeping in mind it should be super
readable, we went for indentations &amp;amp; author colored avatars making it really
clear to understand who is replying.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420907561110_Screen%20Shot%202015-01-10%20at%2017.32.21.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;search-settings&quot;&gt;Search settings&lt;/h3&gt;

&lt;p&gt;Because HN Search users are advanced users, they want to be able to customize
the way the default ranking is working. So be it, we’ve just exposed a subset
of the underlying settings we’re using for the search to let you customize it.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420907721098_Screen%20Shot%202015-01-10%20at%2017.35.07.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;front-page&quot;&gt;Front page&lt;/h3&gt;

&lt;p&gt;Since Firebase is providing the official API of Hacker News, fetching the
items currently displayed on the front page is really easy. We decided to pair
it with our search, allowing users to search for hot stories &amp;amp; comments
through a discreet menu item.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420907937295_Screen%20Shot%202015-01-10%20at%2017.38.44.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;starred&quot;&gt;Starred&lt;/h3&gt;

&lt;p&gt;Let’s go further; what about being able to star some stories to be able to
search in them later? You’re now able to star any stories directly from the
results page. The stars are stored locally in your browser for now. Let us
know if you find the feature valuable!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420908337814_Screen%20Shot%202015-01-10%20at%2017.45.01.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;contribution&quot;&gt;Contribution&lt;/h2&gt;

&lt;p&gt;As you may know, the whole source code of the HN Search website is open-source
and hosted on GitHub. This new version is still based on a Rails 4 project and
uses Angular.js as the frontend framework. We’ve improved the README to help
you being able to contribute in minutes. Not to mention: we love pull-
requests.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Now is starting again the most important part of this project, user testing&lt;/strong&gt;. We count on you to bring us the necessary information to make this search your favorite one.&lt;/p&gt;

&lt;h2 id=&quot;wanna-test&quot;&gt;Wanna test?&lt;/h2&gt;

&lt;p&gt;To try it, go &lt;a href=&quot;https://new-hn.algolia.com&quot;&gt;to our experimental version of HN Search&lt;/a&gt;, go to “Settings”, and enable the new style:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420907058703_Screen%20Shot%202015-01-10%20at%2017.23.21.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_JoORx6jqcVU_p.233467_1420907103965_Screen%20Shot%202015-01-10%20at%2017.24.51.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;want-to-contribute&quot;&gt;Want to contribute?&lt;/h3&gt;

&lt;p&gt;It’s open-source and we’ll be happy to get your feedback! Just use &lt;a href=&quot;https://github.com/algolia/hn-search/issues&quot;&gt;GitHub’s
issues&lt;/a&gt; to report any idea you
have in mind. We also love pull-requests :)&lt;/p&gt;

&lt;p&gt;Source code: &lt;a href=&quot;https://github.com/algolia
/hn-search&quot;&gt;https://github.com/algolia/hn-search&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;try-it-now18&quot;&gt;&lt;a href=&quot;https://new-hn.algolia.com/?experimental&quot;&gt;Try it now!&lt;/a&gt;&lt;/h2&gt;

</content>
 </entry>
 
 <entry>
   <title>Github Awesome Autocomplete browser extension for Chrome and Firefox</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/12/23/christmas-gifthub-awesome-autocomplete/"/>
   <updated>2014-12-23T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/12/23/christmas-gifthub-awesome-autocomplete</id>
   <content type="html">&lt;p&gt;By working every day on building the best search engine, we’ve become obsessed
with our own search experience on the websites and mobile applications we use.&lt;/p&gt;

&lt;p&gt;We’re git addicts and love using GitHub to store every single idea or project
we work on. We use it both for our private and public repositories (&lt;a href=&quot;https://www.algolia.com/doc/apiclients&quot;&gt;12 API
clients&lt;/a&gt;, &lt;a href=&quot;https://github.com/algolia/hn-search&quot;&gt;HN
Search&lt;/a&gt; or various
&lt;a href=&quot;https://github.com/algolia/instant-search-demo&quot;&gt;d&lt;/a&gt;
&lt;a href=&quot;https://github.com/algolia/facebook-search&quot;&gt;e&lt;/a&gt; &lt;a href=&quot;https://github.com/algolia/linkedin-search&quot;&gt;m&lt;/a&gt; &lt;a href=&quot;https://github.com/algolia/meetup-search&quot;&gt;o&lt;/a&gt;
&lt;a href=&quot;https://github.com/algolia/twitter-search)&quot;&gt;s&lt;/a&gt;. We use every day its search
function and we decided to re-build it the way we thought it should be.  We’re
proud to share it with the community via this &lt;a href=&quot;https://chrome.google.com/webstore/detail/github-awesome-autocomple/djkfdjpoelphhdclfjhnffmnlnoknfnd&quot;&gt;Chrome
extension&lt;/a&gt;. Our Github Awesome Autocomplete
enables a seamless and fast access to GitHub resources via an as-you-type
search functionality.&lt;/p&gt;

&lt;h2 id=&quot;install-your-christmas-gift-now&quot;&gt;Install your Christmas Gift now!&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://chrome.google.com/webstore/detail/github-awesome-
autocomple/djkfdjpoelphhdclfjhnffmnlnoknfnd&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/ChromeWebStore_BadgeWBorder_v2_206x58.png&quot; alt=&quot;Github Awesome Autocomplete Algolia Search&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;features&quot;&gt;Features&lt;/h2&gt;

&lt;p&gt;The Chrome extension replaces GitHub’s search bar and add autocomplete
capabilities on:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;top public repositories&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;last active users&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;your own private repositories (this one is done locally in JavaScript without Algolia: the list of private repositories remains locally in your browser)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_Y3thzadEtdY_p.233467_1419338581444_capture.gif&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;howdoes-itwork&quot;&gt;How does it work?&lt;/h2&gt;

&lt;p&gt;We continuously retrieve the most watched repositories and the last active
users using &lt;a href=&quot;http://www.githubarchive.org/&quot;&gt;GitHub Archive&lt;/a&gt; dataset. Users and
repositories are stored in 2 Algolia indices: users and repositories. The
queries are performed using &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt;our JavaScript API
client&lt;/a&gt; and the
autocomplete menu is based on Twitter’s
&lt;a href=&quot;http://twitter.github.io/typeahead.js/&quot;&gt;typeahead.js&lt;/a&gt; library.&lt;/p&gt;

&lt;p&gt;The underlying Algolia account is replicated in 6 regions using our
&lt;a href=&quot;https://www.algolia.com/dsn&quot;&gt;DSN&lt;/a&gt; feature, answering every query in 50-100ms
wherever you are (network latency included!). Regions include US West, US
East, Europe, Singapore, Australia &amp;amp; India.&lt;/p&gt;

&lt;h2 id=&quot;exporting-the-records-from-github-archive&quot;&gt;Exporting the records from GitHub Archive&lt;/h2&gt;

&lt;p&gt;We used GitHub’s Archive dataset to export top repositories and last active
users using Google’s BigQuery:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;;; export repositories
SELECT
  a.repository_name as name,
  a.repository_owner as owner,
  a.repository_description as description,
  a.repository_organization as organization,
  a.repository_watchers AS watchers,
  a.repository_forks AS forks,
  a.repository_language as language
FROM [githubarchive:github.timeline] a
JOIN EACH
  (
     SELECT MAX(created_at) as max_created, repository_url
     FROM [githubarchive:github.timeline]
     GROUP EACH BY repository_url
  ) b
  ON 
  b.max_created = a.created_at and
  b.repository_url = a.repository_url


;; export users
SELECT
  a.actor_attributes_login as login,
  a.actor_attributes_name as name,
  a.actor_attributes_company as company,
  a.actor_attributes_location as location,
  a.actor_attributes_blog AS blog,
  a.actor_attributes_email AS email
FROM [githubarchive:github.timeline] a
JOIN EACH
  (
     SELECT MAX(created_at) as max_created, actor_attributes_login
     FROM [githubarchive:github.timeline]
     GROUP EACH BY actor_attributes_login
  ) b
  ON 
  b.max_created = a.created_at and
  b.actor_attributes_login = a.actor_attributes_login
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&quot;configuring-algolia-indices&quot;&gt;Configuring Algolia indices&lt;/h2&gt;

&lt;p&gt;Here are the 2 index configurations we used to build the search:&lt;/p&gt;

&lt;h3 id=&quot;repositories&quot;&gt;Repositories&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_Y3thzadEtdY_p.233467_1419338775543_Screen%20Shot%202014-12-23%20at%2013.46.04.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;users&quot;&gt;Users&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hackpad.com_Y3thzadEtdY_p.233467_1419338826276_Screen%20Shot%202014-12-23%20at%2013.45.54.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;section&quot;&gt;#&lt;/h2&gt;

&lt;h2 id=&quot;want-to-contribute&quot;&gt;Want to contribute?&lt;/h2&gt;

&lt;p&gt;It’s open-source and we’ll be happy to get your feedback! Just use &lt;a href=&quot;https://github.com/algolia/github-awesome-autocomplete/issues&quot;&gt;GitHub’s
issues&lt;/a&gt; to
report any idea you have in mind. We also love pull-requests :)&lt;/p&gt;

&lt;p&gt;Source code: &lt;a href=&quot;https://github.com/algolia/github-awesome-autocomplete&quot;&gt;https://github.com/algolia/github-awesome-
autocomplete&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Install it now: [Github Awesome Autocomplete on Google Chrome Store
&lt;a href=&quot;https://chrome.google.com/webstore/detail/github-awesome-autocomple/djkfdjpoelphhdclfjhnffmnlnoknfnd&quot;&gt;FREE&lt;/a&gt;]&lt;/p&gt;

&lt;h2 id=&quot;or-just-want-to-add-an-instant-search-in-yourwebsite-application&quot;&gt;Or just want to add an instant search in your website / application?&lt;/h2&gt;

&lt;p&gt;Feel free to create a 14-days FREE trial at
&lt;a href=&quot;http://www.algolia.com/&quot;&gt;http://www.algolia.com&lt;/a&gt; and follow one of our step
by step tutorials at
&lt;a href=&quot;https://www.algolia.com/doc/tutorials&quot;&gt;https://www.algolia.com/doc/tutorials&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Search inside websites and mobile apps is strategic to engage visitors - Part 1</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/12/01/search-strategic-engage-visitors/"/>
   <updated>2014-12-01T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/12/01/search-strategic-engage-visitors</id>
   <content type="html">&lt;p&gt;In an economic environment where the competition for end-users’ attention and
interest is fierce, overlooking search inside your website and mobile
application may damage your business.&lt;/p&gt;

&lt;p&gt;Powerful and reliable Web search engines such as Google have created deeply
rooted expectations for a responsive and intuitive access to online content
and your users expect the same responsive experience once they access your
service. Yet most websites and mobile applications still provide a frustrating
and cumbersome navigation and exploration experience, supported by a poor
internal search engine. Besides, people cannot stand wasting time and the
Google guys got it: they’ve made moving between websites effortless. What
people don’t find easily with you, Google will find it for them, and it may be
with your competitors. Great site search reinforces retention but also brand
awareness and customer loyalty.&lt;/p&gt;

&lt;h2 id=&quot;end-users-have-high-expectations-when-it-comes-to-search&quot;&gt;End-users have high expectations when it comes to search&lt;/h2&gt;

&lt;p&gt;Google’s mission is to organize the world’s information and make it
universally accessible. This is how people use the Web, they hunt for
information and content. In 2004 already, according to &lt;a href=&quot;http://www.nngroup.com/articles/search-engines-become-answer-engines/&quot;&gt;Nielsen Norman
Group&lt;/a&gt;
(2004), &lt;strong&gt;people would start their web sessions with a search engine 88% of
the time&lt;/strong&gt;. This hunt for content does not stop once users access your
service. By using extremely fast and intuitive Web search engines such as
Google or Yahoo, &lt;strong&gt;users have developed well-established unconscious
expectations about what great search should be&lt;/strong&gt;: the invisible link that
understands an intent and translates it into in the right answer. Users have
been conditioned to rely on such responsive and supportive search interfaces.&lt;/p&gt;

&lt;p&gt;With the ever growing amount of content online services offer their users,
internal search is now more central than ever to keep up with this need for an
immediate access to relevant answers.** Search has become the most important
UX component for information retrieval and exploration inside online
services**. But the gap keeps increasing between this need for a powerful
internal access to content and the poor navigability of some online services.
It has become so important that unconsciously, people would rather trust
Google to find content inside your service than your own internal search and
navigation engine.&lt;/p&gt;

&lt;h2 id=&quot;return-on-time-invested-is-the-searchs-kpi&quot;&gt;Return On Time Invested is the search’s KPI&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;People see the Web as an “integrated whole” where the fundamental units are pieces of information, not websites&lt;/strong&gt;, so it is critical for websites and mobile applications to be able to quickly surface relevant information. In such a system, expecting users to navigate complicated information architectures through endless links and tabs is simply not a viable solution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Users optimize their time and efforts in their hunt for information&lt;/strong&gt; (see the&lt;a href=&quot;http://www.amazon.com/Information-Foraging-Theory-Interaction-Human-Technology/dp/0195387791&quot;&gt; information foraging theory by Pirolli &lt;/a&gt;). They just behave like our ancestors who looked for patches of foods, looking to get the largest benefit with the smallest effort. They exhibit a short attention span, are time-constrained and highly impatient. Thus, &lt;strong&gt;they will exercise judgement and pragmatic decision-making strategies in deciding whether to persevere with a given information resource or to look for a different one&lt;/strong&gt;. The amount of time a user spends on a given website is directly proportional to the travel time between sites and what happens is a phenomenon Jacob Nielsen (2003) describes as &lt;a href=&quot;http://www.nngroup.com/articles/information-scent/&quot;&gt;information snacking&lt;/a&gt;: since information resources are often disappointing and the &lt;em&gt;between-patch&lt;/em&gt; time decreases thanks to Google and fast Internet connections, users simply spend less time on a given website and instead multiply their options. All ecommerce websites know that usability guideline: “If users can’t find a product, they won’t buy it”. But with Google and the shrinking travel time between websites, things have changed: &lt;strong&gt;“If users can’t find it fast, they won’t buy it” would indeed be closer to reality.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;search-is-a-key-element-of-your-users-loyalty&quot;&gt;Search is a key element of your users’ loyalty&lt;/h2&gt;

&lt;p&gt;According to a Kelton Research study conducted among one thousand American
adults  (2007) on &lt;a href=&quot;http://searchengineland.com/report-7
-out-of-10-americans-experience-search-engine-fatigue-12509&quot;&gt;“the state of search”&lt;/a&gt;, &lt;strong&gt;78% of those
who experience &lt;em&gt;search engine fatigue&lt;/em&gt; “wished” that search engines could
actually somehow “read their minds”&lt;/strong&gt;. Visitors need to feel understood and
treated fairly when interacting with a service. If you think about it, &lt;strong&gt;the
search bar of a website or a mobile application is a unique field where the
users express their intent the most clearly.&lt;/strong&gt; This is by far the most
valuable touch point between an end-user and an online service as well as a
unique opportunity to engage a user in a “digital” conversation. Not
surprisingly, returning poor results when a user takes the pain to articulate
his intent translates into poor retention: &lt;strong&gt;would you engage in a
relationship with someone who constantly answers off topic?&lt;/strong&gt; Probably not and
that’s nevertheless what’s happening on the Web today. The disappointment
caused by a lack of relevance unfortunately damages your credibility and your
brand.&lt;/p&gt;

&lt;p&gt;Relevance is mandatory for retention but personalization is the key to
loyalty. And &lt;strong&gt;whereas it’s not really possible to offer a browsing interface
personalized per user, an efficient search function can provide an experience
tailored to the particular needs of end-users&lt;/strong&gt;. Results of a particular query
can be pushed up the search results page according to personal data gathered
during a session. Search rankings can also be tweaked on a per profile basis,
take into account in real-time the preferences of each user, her friends, etc.&lt;/p&gt;

&lt;h2 id=&quot;lets-wrap-up&quot;&gt;Let’s wrap up!&lt;/h2&gt;

&lt;p&gt;Today we are in a paradoxical situation where most efforts are put on external
findability, websites wanting to be immediately accessible from Web search
engines. But &lt;strong&gt;without a strong focus on the search feature of the website to
achieve a great internal findability, all those branding and search engine
optimization tactics are in vain&lt;/strong&gt;. Internal search is about organizing your
own information and making it universally accessible to your own users: &lt;strong&gt;what
Google did for the Web, you now need to it for yourself!&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;blog-post-series-why-you-should-care-about-search&quot;&gt;Blog post series: Why You Should Care About Search&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://blog.algolia.com/search-strategic-engage-visitors&quot;&gt;the strategic importance of search inside websites and mobile applications&lt;/a&gt; (&lt;strong&gt;part 1&lt;/strong&gt;)&lt;/li&gt;
  &lt;li&gt;the main components of a great search experience (&lt;strong&gt;part 2&lt;/strong&gt; - Coming soon)&lt;/li&gt;
  &lt;li&gt;the crucial role of speed (&lt;strong&gt;part 3&lt;/strong&gt; - Coming soon)&lt;/li&gt;
  &lt;li&gt;the short-term and long-term business impacts of an intuitive search (&lt;strong&gt;part 4&lt;/strong&gt; - Coming soon)&lt;/li&gt;
  &lt;li&gt;&lt;em&gt;In our next blog post, we will dig into some of the characteristics of a great search experience.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>FanFootage: Solving the Search problem with Algolia</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/12/01/fanfootage-solving-search-problem-algolia/"/>
   <updated>2014-12-01T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/12/01/fanfootage-solving-search-problem-algolia</id>
   <content type="html">&lt;p&gt;&lt;strong&gt;The following post is a guest post by Eoin O’Driscoll (web developer), and Vinny Glennon (co-founder) of FanFootage.com&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/vinny.png&quot; alt=&quot;vinny&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/eoin-o-driscoll.png&quot; alt=&quot;eoin-o-driscoll&quot; /&gt;&lt;/p&gt;

&lt;p&gt;When we founded FanFootage we knew there was something lacking in the concert
and event experience. Fans were taking videos on their mobile phones during
performances, loading them on YouTube, and the audio was horrible. So we
created FanFootage where fans can upload their own video and we work with the
bands to get the high def audio and put them together. Now fans can come to
our site and see their favorite concerts or sports from any angle. They can
also search for upcoming events and performances.&lt;/p&gt;

&lt;p&gt;For a recent Linkin Park concert the band and the fan group contacted us.
Their fans uploaded more than 1,500 videos from almost every angle. On
FanFootage that single concert has had over 350,000 page views.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/fanfootage.gif&quot; alt=&quot;fanfootage&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;our-user-experience-heavily-relies-on-search&quot;&gt;Our user experience heavily relies on search&lt;/h2&gt;

&lt;p&gt;Earlier in our design &lt;strong&gt;we knew that search would be key to making FanFootage
the ultimate fan experience&lt;/strong&gt;. &lt;strong&gt;When a user comes to our site the first thing
they do is search for the event or artist. And we need to make sure that they
either find the artist they are looking for or something similar, and it has
to be fast&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;As developers, our team isn’t new to search, particularly within the
entertainment space. Our previous startup in the music space was bought by
RealNetworks and a second startup was a competitor to Google. That is where we
learned that search is hard. And when we thought to build our own search on
FanFootage we quickly said it wasn’t going to happen.&lt;/p&gt;

&lt;p&gt;We also know what fans need. &lt;strong&gt;User demands have changed now that they can
access anything from their phones. Today we expect our applications and
services to predict what we are going to do next. And because of Google,
people don’t search with a single phrase. Users expect search to understand
how phrases fit together and are related and of course it needs to spell check
and it must be instant&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;We also had different search requirements than other sites. Normally search on
a site is for one unit or concept; a site for flowers for example. For us we
needed to allow fans to search for artists, bands, friends or upcoming events
in their area and never get a zero result.&lt;/p&gt;

&lt;h2 id=&quot;why-we-chose-algolia&quot;&gt;Why we chose Algolia&lt;/h2&gt;

&lt;p&gt;After looking at a few search applications we agreed on Algolia.&lt;strong&gt;Many search
applications look nice but don’t have the flexibility we needed&lt;/strong&gt; to configure
them they way our business needed. And most weren’t fast.&lt;/p&gt;

&lt;p&gt;Why did we chose Algolia? First it has &lt;strong&gt;a developer-centric approach&lt;/strong&gt;. It
took us 2 hours to configure and a day to test and that was it. We basically
had search up and running in a day. The dashboard lets me know that the API
calls are returned within milliseconds and we have all the flexibility we need
to configure as our content grows.&lt;/p&gt;

&lt;p&gt;Today, more than 250 artists have used FanFootage in 20 countries. We are
growing quickly. As a company we are still learning what our fans are
searching for and Algolia is helping us with that. &lt;strong&gt;As content grows we will
continue to configure search to meet the needs of our fans&lt;/strong&gt;. We will also be
rolling out Algolia for mobile because of its multi-search capabilities.&lt;/p&gt;

&lt;p&gt;Algolia is a simple solution to a complex problem. And it blew our mind away.
It just works. And now we can focus on our own fanbase.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Images courtesy of FanFootage. Learn more on their
&lt;a href=&quot;https://fanfootage.com/&quot;&gt;website&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Black Thursday DNS issue</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/11/28/black-thursday-dns-issue/"/>
   <updated>2014-11-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/11/28/black-thursday-dns-issue</id>
   <content type="html">&lt;p&gt;Today we had a severe DNS issue that impacted some of our users during a total
of 5 hours. Although most of our customers were not impacted, for some of them
search simply went down. This event and its details deserved to be fully
disclosed.&lt;/p&gt;

&lt;h2 id=&quot;the-context&quot;&gt;The context&lt;/h2&gt;

&lt;p&gt;Up until recently, we were using Amazon Route 53 for our DNS routing needs.
When we started to design our Distributed Search Network
(&lt;a href=&quot;https://www.algolia.com/dsn)&quot;&gt;algolia.com/dsn&lt;/a&gt; a few months ago, we quickly
realized that our needs were out of Route 53’s scope: we needed a custom
routing per user and the two options of Route 53 simply didn’t work:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Latency-based routing is limited to the 9 regions of AWS and we have 12;&lt;/li&gt;
  &lt;li&gt;With geography-based routing you need to indicate country per country how you want to resolve the IP.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This is a tedious process for a not even good solution as route 53 does not
support EDNS right now.&lt;/p&gt;

&lt;p&gt;So we started to look for new DNS options. Choosing the best DNS provider is
not something you do overnight. It took us months to benchmark several vendors
and find the right one: NSOne. The &lt;a href=&quot;https://nsone.net/2014/03/nsone-filter-chain-quick-primer/&quot;&gt;filter chain feature of
NSOne&lt;/a&gt; was a
perfect fit for our use case and the NSOne team was great in understanding our
needs and even went the extra mile for us by building a specific module,
allowing better performance.&lt;/p&gt;

&lt;p&gt;Something we also discovered during this benchmark was that the algolia.io
domain was not good for performance compared to algolia.net, as there are far
more DNS servers in the .net anycast network than in the .io one. The NSOne
team offered us a smart solution based on linked domain, so we wouldn’t have
to maintain two zones ourselves.&lt;/p&gt;

&lt;h2 id=&quot;the-migration&quot;&gt;The migration&lt;/h2&gt;

&lt;p&gt;The goal of the migration was to move from Route 53 to NSOne. For several
weeks we have been working on importing the records in NSOne and making sure
Route 53 and NSOne were synchronized. Our initial tests revealed some issues
but after a few days of continuous updates without any difference between
Route 53 and NSOne, we started to be confident about our synchronization and
started the migration of the &lt;a href=&quot;https://www.algolia.com/demos&quot;&gt;demos of our
website&lt;/a&gt; to make them target the new
algolia.net domain. We tested the performance and resolution from all NSOne
POP (&lt;a href=&quot;https://nsone.net/technology/netw
ork/&quot;&gt;https://nsone.net/technology/network/&lt;/a&gt;) to be sure there were no glitches.&lt;/p&gt;

&lt;p&gt;These first production tests were successful, synchronization was ok,
performance and routing were good, so we decided to move the .io domain from
Route 53 to NSOne as well.&lt;/p&gt;

&lt;h2 id=&quot;the-d-day&quot;&gt;The D-day&lt;/h2&gt;

&lt;p&gt;The big issue when changing the DNS is that it is global and involves caching
logics, making rollbacking complex. With users in 45 countries it is almost
impossible to find a suitable time for everyone: DNS changes cannot be done
gradually. We decided to push the update during the night for the US, at 4am
EST.&lt;/p&gt;

&lt;p&gt;We witnessed a quickly rising number of queries targeting NSOne and it’s once
we reached about 1,000 DNS queries per second that we started to receive our
first complain about failed DNS resolution. This routing issue was not
impacting all DNS resolutions but some of them were replying with a NXDOMAIN
answer, the equivalent of a DNS “404 not found”.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;
$ dig APPID-1.algolia.io`
; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.9.5-4.3-Ubuntu &amp;lt;&amp;lt;&amp;gt;&amp;gt; APPID-1.algolia.io
;; global options: +cmd
;; Got answer:
;; -&amp;gt;&amp;gt;HEADER&amp;lt; ;; flags: qr rd ra; QUERY: 1, ANSWER: 0, AUTHORITY: 1, ADDITIONAL: 1
;; OPT PSEUDOSECTION:
; EDNS: version: 0, flags:; udp: 4096
;; QUESTION SECTION:
;APPID-1.algolia.io. IN A
;; AUTHORITY SECTION:
algolia.io. 45 IN SOA dns1.p03.nsone.net. hostmaster.nsone.net.
1414873854 43200 7200 1209600 3600
;; Query time: 24 msec
;; SERVER: 213.133.100.100#53(213.133.100.100)
;; WHEN: Thu Nov 27 10:49:33 CET 2014
;; MSG SIZE rcvd: 115
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;After double-checking our DNS zone for those specific records, we understood
it was a NSOne bug related to our custom routing code. We immediately
rollbacked to Route 53.&lt;/p&gt;

&lt;p&gt;The NSOne support was really quick to react and they found the issue pretty
quickly: the issue only concerned some DNS with EDNS support on the algolia.io
domain. The algolia.net domain was not impacted, explaining why all the tests
we’ve done weren’t able to detect the issue before.&lt;/p&gt;

&lt;p&gt;Unfortunately, it did not stop here and something very unexpected happened:
some customers (even not priorly impacted) started to face issues right after
the rollback to Route 53.&lt;/p&gt;

&lt;p&gt;In order to improve performance, the custom Algolia module developed by NSOne
was doing some translation on our records: APPID-1.algolia.io is translated
into 1.APPID.algolia.io and then resolved to CNAME for the actual server in
the cluster serving that customer. The translation of APPID-1.algolia.io to
1.APPID.algolia.io was done with a TTL of 86400 seconds (1 day). Since these
zones did not exist in Route 53 before, it was not possible to resolve there
records anymore. What made the situation even worse was the TTL far exceeding
the TTL of NS records. Most of the DNS servers flushed their cache for the
domain, once the nameservers changed. But the remaining ones kept the record
cached.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;TL;DR: Do not forget about IPv6.&lt;/strong&gt; As if it was not enough, we eventually discovered something else: our custom DNS module was resolving APPID-X.algolia.io to X.APPID.algolia.io only in a case that there were no direct resolutions to an IP address. This translation worked pretty well as we had all the A records set. But some customers started to report weird resolutions. Normally we resolve APPID-1.algolia.io -&amp;gt; 1.APPID.algolia.io -&amp;gt; servername-1.algolia.io -&amp;gt; IP. Which was completely fine until the moment an IPv6 AAAA request came. Since we did not have AAAA records, the custom filter started to resolve: APPID-1.algolia.io -&amp;gt; 1. APPID.algolia.io -&amp;gt; servername-1.algolia.io -&amp;gt; 1.servername.algolia.io -&amp;gt; nothing.&lt;/p&gt;

&lt;p&gt;We were in a bad situation feared by all engineers, this lonely moment when
you really miss a “purge cache” feature.&lt;/p&gt;

&lt;p&gt;Eventually, as soon as we got confirmation of the fix by NSOne, we changed
again the DNS of algolia.io to NSOne and helped our customers to workaround
the issue before the cache expiration:&lt;/p&gt;

&lt;p&gt;for our customers impacted by the NXDOMAIN issue, a simple migration to the
algolia.net domain instead of the algolia.io problem fixed the issue;&lt;/p&gt;

&lt;p&gt;for those impacted by the Route 53 rollback issue, we created new DNS records
for them to avoid work-around DNS caches.&lt;/p&gt;

&lt;h2 id=&quot;conclusion-what-we-learned&quot;&gt;Conclusion: what we learned&lt;/h2&gt;

&lt;p&gt;This is by far the biggest problem we have encountered since the launch of
Algolia. Although the first issue was almost impossible to anticipate, we have
made mistakes and should have handled a few things differently:&lt;/p&gt;

&lt;p&gt;DNS is a highly critical component and being the first to use an external
custom module was not a good idea, even if it improved performance;&lt;/p&gt;

&lt;p&gt;Putting more thought into the rollback part of our deployment would have
helped us anticipate the second issue. For a component as critical as a DNS,
having a robust rollback process is mandatory, no matter how much work it
represents and even though such an event is extremely unlikely to happen.&lt;/p&gt;

&lt;p&gt;We’re very sorry for this disruption. We wanted to share these technical
details to shed some light on what happened and what we’ve done in response.
Thanks for your patience and support.&lt;/p&gt;

&lt;p&gt;If you think we missed anything or if you’d like to share your advice on your
own best practices, your comments are really welcome.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Jadopado delivers instasearch for mobile and web powered by Algolia</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/11/14/jadopado-delivers-instasearch-mobile-web-powered-algolia/"/>
   <updated>2014-11-14T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/11/14/jadopado-delivers-instasearch-mobile-web-powered-algolia</id>
   <content type="html">&lt;h2 id=&quot;algolia-increases-online-search-sessions-by-60-and-unique-mobile-searches&quot;&gt;Algolia Increases Online Search Sessions By 60% and Unique Mobile Searches&lt;/h2&gt;
&lt;p&gt;by 270%&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;The following post is a guest post by Omar Kassim, co-founder of &lt;a href=&quot;https://jadopado.com/&quot;&gt;JadoPado&lt;/a&gt;.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Omar-Kassim-Founder-of-JadoPado-Image-2-1.jpg&quot; alt=&quot;Omar-Kassim-Founder-of-JadoPado&quot; /&gt; Founded in 2010, JadoPado is one of the largest e-commerce
sites servicing the GCC, Middle East, North Africa and South Asia.  Its CEO
Omar Kassim wanted to bring an Amazon-like experience to the region.  In just
3 years of operations the company now boasts thousands of customers, hundreds
of vendors and over $7 million in annual revenues.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Realizing that search is a key component of their user experience and engagement&lt;/strong&gt;, Omar and his small team of 15 set off to build new search capabilities that would help users find the products they wanted, lightning fast. In addition, the team was developing a revamped mobile experience and saw that search needed to be spot on for both smartphones and tablets. &lt;em&gt;“I saw search as a competitive tool and as a strategy to get a leg up on our competition.  After seeing Algolia on Hacker News I was absolutely blown away.  After looking at the demos, we threw out what we were doing internally in terms of a small search revamp and I had one of our team get cracking with Algolia right away. As a little startup, it really helped that Algolia’s price points were within reach in terms of not breaking the bank to get things rolling.”&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;the-power-of-instant-search&quot;&gt;The Power of Instant Search&lt;/h3&gt;

&lt;p&gt;After configuring and testing Algolia for two weeks, JadoPado had the results
they were looking for. Branded internally as InstaSearch, JadoPado knew that
it would dramatically improve how search functioned on both mobile and the web
at JadoPado. &lt;em&gt;“The idea from the outset was to build InstaSearch. I kept
ending up at the Algolia demo and &lt;strong&gt;thought it would be incredible if we could
forget all user interaction aside from typing and just display results right
away&lt;/strong&gt;. Remove what you’ve typed and the results disappear taking you back to
where you were. We then spent a bit of time figuring out how to get each
result “page” to have a URL that could be used with external search or shared
elsewhere,”&lt;/em&gt; explained Omar.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/jadopado.gif&quot; alt=&quot;japopado ecommerce&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;making-search-seamless&quot;&gt;Making Search Seamless&lt;/h3&gt;

&lt;p&gt;&lt;em&gt;“We looked at a number of solutions. &lt;strong&gt;One of our biggest intentions was to
try to get search to be extremely fast and as slick as possible&lt;/strong&gt;. Customers
should feel like search “just works” and that it is a super easy way to get
straight to to whatever they may be looking for. Algolia has allowed us to
accomplish that,”&lt;/em&gt; Omar explained.  &lt;em&gt;“&lt;strong&gt;Moving search from a not really
working internal model to a search as a service platform&lt;/strong&gt; has allowed us to
focus on other areas while knowing that search works and that we’ve got an
edge over our competition.”&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;support-for-arabic&quot;&gt;Support For Arabic&lt;/h3&gt;

&lt;p&gt;With more than 20 countries to support, the JadoPado team knew that the key to
success in the region was to ensure that search be delivered in Arabic as
well. Omar explained, &lt;em&gt;“The final bits were figuring out a separate set of
indexes for Arabic (as we were about to roll out a standalone Arabic version
of JadoPado) and getting the faceting right. This was easy to do with the deep
Algolia documentation.”&lt;/em&gt; &lt;strong&gt;Algolia works with all languages, including
Chinese, Japanese, Korean, and Arabic. No specific configuration required,
speed and ranking perform exactly the same way&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;better-business-through-search&quot;&gt;Better Business Through Search&lt;/h3&gt;

&lt;p&gt;In May the team rolled out InstaSearch, Arabic support and a newly revamped
mobile experience with search at the center. JadoPado immediately experienced
a doubling in conversions and activity that was triple a typical day.
&lt;strong&gt;Compared to the same 30 day period in 2013, JadoPado saw an increase in site
visits through search from 8.2% to 11.3%.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Additionally:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Sessions with search has jumped 59.96%.&lt;/li&gt;
  &lt;li&gt;Unique searches has jumped 46.87%&lt;/li&gt;
  &lt;li&gt;Average search depth has increased by 58.87%.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;mastering-mobile-through-search&quot;&gt;Mastering Mobile Through Search&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;The greater impact of Algolia’s hosted search was JadoPado’s revamped mobile experience&lt;/strong&gt;. Search is often the first action customers take on a mobile device.  With instant search, autocorrect and full language support,  improving search and the quality of results can have a significant impact on revenues.  With Algolia implemented as part of JadoPado’s mobile site, the company saw strong results with &lt;strong&gt;visits from search increasing from 4.3% to 15% over the same time period and session exits decreasing by 16.57%.&lt;/strong&gt; A big change. And &lt;strong&gt;search increased engagement on all levels&lt;/strong&gt;:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Mobile sessions with search jumped by 233.92%&lt;/li&gt;
  &lt;li&gt;Total unique mobile searches jumped 268.37%&lt;/li&gt;
  &lt;li&gt;Average search depth on mobile devices jumped by 41.05%.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;em&gt;Images courtesy of JadoPado. Learn more on their
&lt;a href=&quot;https://jadopado.com/&quot;&gt;website&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>AfterShip Leverages Algolia's Search as a Service to Track 10 Million Packages Around The World</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/10/10/aftership-leverages-algolias-search-service-track-10-million-packages-around-world/"/>
   <updated>2014-10-10T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/10/10/aftership-leverages-algolias-search-service-track-10-million-packages-around-world</id>
   <content type="html">&lt;p&gt;Algolia Speeds Up Search Result Delivery Times From 10 Seconds To 250
Milliseconds.The following post is a guest post by &lt;a href=&quot;http://hk.linkedin.com/in/teddychan/&quot;&gt;Teddy
Chan&lt;/a&gt;, Founder and CEO at
&lt;a href=&quot;https://www.aftership.com/&quot;&gt;AfterShip&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/teddy.png&quot; alt=&quot;Teddy Chan AfterShip&quot; /&gt;&lt;/p&gt;

&lt;p&gt;AfterShip is an online tracking platform which helps online merchants track
their shipment across multiple carriers and notify their customers via email
or mobile. Being an online merchant myself, I shipped more than 30,000
packages a month around the world. When customers contacted me to get an
update on shipments I realized that I couldn’t track shipments from different
carriers and get updates on their status in a single place. So I built
Aftership to allow both consumers and online merchants view all their packages
on a single platform.&lt;/p&gt;

&lt;p&gt;After winning the 2011 Global Startup Battle and 2011 Startup Weekend Hong
Kong Aftership opened into beta and quickly helped thousands of online
merchants to send out over 1,000,000 notifications to customers.&lt;/p&gt;

&lt;p&gt;One of the key parts of our service is providing customers around the world
with up-to-date information about their packages.&lt;/p&gt;

&lt;p&gt;Right now we have more than 10 million tracking numbers in our database. This
causes a few different challenges when it comes to search and we needed
technology that would help us continuously index constantly changing
information.&lt;/p&gt;

&lt;h3 id=&quot;our-first-challenge-is-that-we-are-a-small-team-with-only-1-engineer&quot;&gt;Our first challenge is that we are a small team with only 1 engineer.&lt;/h3&gt;

&lt;p&gt;We are not in the search business, so we needed a solution that would be easy
to implement and work well with our existing infrastructure. Algolia’s
extensive documentation made it easy to see that our set up and implementation
time would be extremely fast and would work with any language and database, so
we could get back to our core business.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algolia was super easy, we had it tested, up and running in a week.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;our-second-challenge-was-quickly-delivering-search-results&quot;&gt;Our second challenge was quickly delivering search results.&lt;/h3&gt;

&lt;p&gt;On Redis, searching for packages was simply impossible. For each query, it
would simply lock up until the result was found, so it could run only one
search at a time. Each search with Redis was taking up to 10 seconds. &lt;strong&gt;With
Algolia we reduced search result delivery times to 250 milliseconds for any
customer anywhere in the world.&lt;/strong&gt; When you think about thousands of merchants
who send more than 1 million packages per month, you can see how speed is
critical.&lt;/p&gt;

&lt;p&gt;Downtime also is not an option when tracking packages around the globe.&lt;/p&gt;

&lt;p&gt;We are very strict when adopting new technologies and SaaS technologies can’t
slow down our system.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algolia had the highest uptime of the other solutions we looked at. There was no physical downtime.&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;our-final-challenge-was-search-complexity&quot;&gt;Our final challenge was search complexity.&lt;/h3&gt;

&lt;p&gt;Sometimes you need to know how many shipments are coming from Hong Kong and
exactly where they are in transit to and from the U.S.. Shipments going around
the globe can change status several times within a single day. With Algolia’s
indexing we are able to instantly deliver up-to-date notifications on all 10
million packages, so that customers can not only track their package on its
journey, but they can also go to their online merchant’s shop and see a real-
time status of their package.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;In the end, it was Algolia’s customer service that won us over.&lt;/strong&gt;&lt;br /&gt;
Similar services and platforms were not responsive. With Algolia we either had
the documentation we needed, immediately were able to get advice from an
engineer or had our problem solved in less than a day. With such a small team
this means a lot. And with the Enterprise package we know that Algolia will
grow with us as quickly as our business does.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Want to find out more about the Algolia experience ?&lt;br /&gt;
&lt;a href=&quot;https://www.algolia.com/features&quot;&gt; Discover and try it here &lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia opened its 4th datacenter is in California!</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/09/01/4th-datacenter-california/"/>
   <updated>2014-09-01T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/09/01/4th-datacenter-california</id>
   <content type="html">&lt;p&gt;Do you know the 3 most important things in search? Speed, speed, and speed!&lt;/p&gt;

&lt;p&gt;At Algolia, we work at making access to content and information completely
seamless. And that can only be done if search results are returned so fast
that they seem instant.&lt;/p&gt;

&lt;p&gt;That means two things for us: getting server &lt;strong&gt;response time under 10ms&lt;/strong&gt;
(checked), and getting the servers close to end-users to lower latency.&lt;/p&gt;

&lt;p&gt;We are on a quest to make search faster than 100ms from anywhere in the world,
and today is an important step. We are thrilled to announce the &lt;strong&gt;opening of
our 4th datacenter, located in California&lt;/strong&gt;!&lt;/p&gt;

&lt;p&gt;You can now choose to be hosted on this datacenter when &lt;a href=&quot;https://www.algolia.com/users/sign_up&quot;&gt;signing
up&lt;/a&gt; (multi-datacenter distribution is
also available for enterprise users).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Concertwith.me's Competitive Edge: A Revamped Search UX with Algolia</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/08/28/concertwith-mes-competitive-edge-revamped-search-ux-algolia/"/>
   <updated>2014-08-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/08/28/concertwith-mes-competitive-edge-revamped-search-ux-algolia</id>
   <content type="html">&lt;p&gt;There are a lot of music discovery apps on the market, yet sifting through
concert listings is anything but seamless. That’s why Cyprus-based startup
&lt;a href=&quot;http://concertwith.me/&quot;&gt;Concertwith.me&lt;/a&gt; aims to make finding local concerts
and festivals as intuitive as possible. Automatically showing upcoming events
in your area, the site offers personalized recommendations based on your
preferences and your Facebook friends’ favorited music. Covering over 220,000
events globally, the site uses Algolia to offer meaningful results for
visitors who are also looking for something different.&lt;/p&gt;

&lt;p&gt;Founder Vit Myshlaev admits that concert sites often share the same pool of
information. The differentiator is how that information is presented. “The
biggest advantage one can have is user experience,” he explains. “There’s
information out there, but do users find it? The reason that people don’t go
to cool concerts is that they still don’t know about them!”&lt;/p&gt;

&lt;p&gt;As an example, he showed me one of the largest live music discovery sites on
the web. Searching for an artist required navigating a convoluted maze of
links before pulling up irrelevant results. “Users have to type in queries
without autocomplete, typo-tolerance, or internationalization. They have to
scroll through a long list of answers and click on paginated links. That’s not
what people want in 2014,” said Myshlaev.&lt;/p&gt;

&lt;p&gt;To simplify search and make the results more relevant, Concertwith.me used our
API. “We got a lot of user feedback for natural search,” Myshlaev wrote. Now
visitors can search for artists and concerts instantly. With large user bases
in the United States, Germany, France, Spain, Italy, Russia and Poland,
Concertwith.me also benefits from Algolia’s &lt;a href=&quot;https://www.algolia.com/doc#Multilingual&quot;&gt;multi-lingual search
feature&lt;/a&gt;. “We’ve localized our app
to many countries. For example, you can search in Russian or for artists that
are Russian, and results will still come up,” says Myshlaev.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2014/08/search.gif&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/search.gif&quot; alt=&quot;search&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;For users with a less targeted idea of what they’re looking for,
Concertwith.me implemented structured search via
&lt;a href=&quot;http://faq.algolia.com/basics/what-is-faceting/&quot;&gt;faceting&lt;/a&gt;. “We also realized
that some visitors don’t know what they want. Algolia search helps them find
answers to questions like, Where will my favorite artist perform? How much do
tickets cost? Are there any upcoming shows?”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2014/08/recommendations.gif&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/recommendations.gif&quot; alt=&quot;recommendations&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Concertwith.me’s goal is to reduce informational noise so that users can find
and discover music as soon as possible. The start up experimented with a
number of other search technologies before reading an &lt;a href=&quot;http://insideintercom.io/7-things-wish-every-search-did/&quot;&gt;article about us on
Intercom.io&lt;/a&gt;, which
inspired Myshlaev. “When I saw what Algolia could do, I knew that this was the
competitive edge I was looking for.”&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;em&gt;Want to build a search bar with multi-category auto-completion like Concertwith.me? &lt;a href=&quot;https://www.algolia.com/doc/tutorials&quot;&gt;Learn how through our tutorial&lt;/a&gt;.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>How Abacus Leverages Algolia for Realtime Expense Reporting</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/08/21/algolia-for-realtime-expense-reporting/"/>
   <updated>2014-08-21T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/08/21/algolia-for-realtime-expense-reporting</id>
   <content type="html">&lt;p&gt;When one thinks of expense reporting, speed is far from the first descriptor
that comes to mind. Companies spend a substantial amount of time tracking
expenses, while employees linger in paperwork purgatory, wondering when they
will be reimbursed for their work-related charges. That’s why Abacus has made
it their mission to simplify expense management so that it occurs in real
time. Their creative implementation of Algolia helps make it happen.&lt;/p&gt;

&lt;p&gt;Abacus is a mobile and desktop application that allows small businesses to
track and verify expenses on the go. Employees can upload a photo of their
receipt on the mobile app, and Abacus takes care of the rest. “For each
expense, we have a lot of data. We have the person who expensed it, the amount
of the expense, the time, and where it took place. We also have a lot of
metadata. For example, if you went out to breakfast, we pull in the name of
the restaurant, the address, the URL of the merchant. There’s tags and
categories and so on,” explains Ted Power, Co-Founder of Abacus. “And we
wanted to make all of that searchable.”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2014/08/Screen-Shot-2014-08-14-at-16.37.25.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2014-08-14-at-16.37.25.png&quot; alt=&quot;Abacus Algolia&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;To make all of that data accessible and interpretable for a financial manager,
Abacus turned to our API. “Algolia made it super easy for us to get faceted,
advanced search options. If you are the finance person at your company, you
can basically say ‘Show me all of the expenses over $50,’ or ‘Show me all the
expenses that don’t have a receipt.’ You can look at expenses for one person
or one category, like travel. You can even pivot off of 8 of these different
things. Algolia makes it super easy to do,” says Power. This accelerates the
process of expense verification and approval. “It’s good search. We have tags
like ‘car rental’ on auto-complete, for example. That’s all Algolia.”&lt;/p&gt;

&lt;p&gt;Power adds that a “great implementation experience” was especially beneficial
for the start up. “It’s the kind of thing that would have taken ages to build
from scratch.” Co-Founder Joshua Halickman chimed in: “Being able to get up
and off the ground really quickly was great. In general, I love the speed.
Crazy fast. Really nice.”&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2014/08/Screen-Shot-2014-08-14-at-16.38.34.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2014-08-14-at-16.38.34.png&quot; alt=&quot;Abacus Algolia&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;_Images courtesy of Abacus. Learn more _&lt;a href=&quot;https://www.abacus.com&quot;&gt;&lt;em&gt;on their
website.&lt;/em&gt;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Deploying Algolia to Search on more than 2 Million Products</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/07/11/deploying-algolia-search-2-million-products/"/>
   <updated>2014-07-11T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/07/11/deploying-algolia-search-2-million-products</id>
   <content type="html">&lt;p&gt;The following post is an interview of &lt;a href=&quot;fr.linkedin.com/pub/vincent-paulin/71/1a3/86a&quot;&gt;Vincent Paulin&lt;/a&gt;, R&amp;amp;D Manager at &lt;a href=&quot;http://www.alittlemarket.com/&quot;&gt;A Little
Market&lt;/a&gt; (recently acquired by Etsy).&lt;/p&gt;

&lt;p&gt;As a fast growing ecommerce site for handmade goods in France, A Little Market
has seen its marketplace grow from a few thousand to over 2 million products
in just 5 years. With 90,000 designers and artisans using A Little Market
marketplace to buy, sell and collaborate, search quickly became a major part
of their ecommerce strategy and user experience.&lt;/p&gt;

&lt;h4 id=&quot;alittlemarket3&quot;&gt;&lt;strong&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-07-11-17.31.04-1024x486.png&quot; alt=&quot;ALittleMarket&quot; /&gt;&lt;/strong&gt;&lt;/h4&gt;

&lt;h4 id=&quot;what-did-you-have-in-place-as-a-search-solution&quot;&gt;&lt;strong&gt;What did you have in place as a search solution?&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;“We implemented a Solr based search 5 years ago and had been trying to tweak
it to fit our growing needs.  We had selected this system for its flexibility,
however, over time, that flexibility translated into constant maintenance,
modifications and lower relevance in our search results.&lt;/p&gt;

&lt;p&gt;Then we investigated Elasticsearch. It is complex, yet powerful. As I was
diving deeper into Elasticsearch I realized that I could quickly gain an “ok”
search experience; however, a powerful search experience would mean investing
more time than we had to configure it. Then I did a little math:  learning the
platform would take a few weeks, configuring servers - a few days, and
configuring and tuning semantic search perfectly - several months.&lt;/p&gt;

&lt;p&gt;Then we found Algolia.  We only had 3 months and knew Algolia would be much
easier to implement, so we A/B tested everything to see how it would impact
the search experience.&lt;/p&gt;

&lt;h4 id=&quot;can-you-tell-us-more-about-your-integration-process&quot;&gt;&lt;strong&gt;Can you tell us more about your integration process?&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;The first thing we wanted to get done was to reference all the shops and our
best searches to make an autosuggest widget. Building this autosuggest with a
basic configuration took us 2 days.&lt;/p&gt;

&lt;p&gt;Then we built an automatic task to aggregate shops and best searches every day
and configure Algolia indices. We also took on the task to create the front
javascript plugin. With the Algolia documentation and the examples on Github
it took us less than 1 hour.&lt;/p&gt;

&lt;p&gt;The results of this first test were very encouraging.  With around 500k
requests per day, the response time was about 4 milliseconds on average and we
saw the conversion rate multiplied by 3 compared to the previous conversion
rate with a search bar with “no suggest”. For A Little Mercerie, another
marketplace we manage, the improvement was about 4 times greater.&lt;/p&gt;

&lt;p&gt;After this first test, we were ready to fully commit to Algolia for our whole
search experience. The first step was to create a script to index our entire
product database in Algolia. This was easy to do with batch insert in Algolia
indices. We selected some attributes of our products such as the title,
categories, materials and colors to be indexed. That was a first try. We
wanted it to be quick and simple.&lt;/p&gt;

&lt;p&gt;With the help of the open source demo code we developed a full JS sandbox
which can display paginated results with faceting to show the progress to the
team.  In less than a week, we had a fully working sandbox and the results
were promising.  Our query time averaged less than 20 milliseconds on 2
millions records.  With confidence we started to upgrade the algorithm on
Algolia, test it, again and again, adding some attributes to index such as
specific events (christmas, valentine’s day), custom tags, etc.&lt;/p&gt;

&lt;p&gt;In addition, we implemented sorted results. They are really relevant with the
new numeric ranking option in settings. At that step we were able to sort
results by price, date, etc. You must create a specific index for each
specific ranking you need.  We also created a different index for each
language (French and Italian) and took this opportunity to do the same across
our  other websites, alittlemercerie.com and alittleepicerie.com.&lt;/p&gt;

&lt;p&gt;To do this we created a custom API which abstracts the use of any kind of
search engine for all API clients. We end up losing the real-time search but
we need that for now in order to abstract everything and to collect data
before sending the results.&lt;/p&gt;

&lt;p&gt;The next step was to erase the “no results” pages. For that, we were
progressively adding the last words of the query as optional words until we
had somes results.We never set as optional all the user queries.  We set at
least the first word or the first two words.&lt;/p&gt;

&lt;p&gt;When search was ready, we still had plenty of time left to implement it on our
clients’ applications. We took more time than was needed to implement Algolia.
The speed of iteration with the Algolia API enables us to test everything in a
much shorter timeframe.&lt;/p&gt;

&lt;h4 id=&quot;how-has-algolias-api-helped-search-on-a-little-market&quot;&gt;&lt;strong&gt;How has Algolia’s API helped search on A Little Market?&lt;/strong&gt;&lt;/h4&gt;

&lt;p&gt;We are now able to answer more than 500/1000 requests per minute and we add
6000 new products every day to the search engine while over 3000 are removed,
in real time.&lt;/p&gt;

&lt;p&gt;After this integration of the Algolia API, we saw an increase in our
conversion rate on search by 10%. This represents tens thousands of euros in
turnover per month for us. In a few weeks of work with one engineer, we had
replaced our main search engine for a better solution thanks to Algolia.”&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Keeping Data in your Search Engine Up-to-Date</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/07/09/keeping-data-in-your-search-engine-up-to-date/"/>
   <updated>2014-07-09T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/07/09/keeping-data-in-your-search-engine-up-to-date</id>
   <content type="html">&lt;p&gt;When we developed the first version of Algolia Search, we put a lot of effort
into developing a data update API. It worked like this: You could send us a
modified version of your data as soon as the change appeared, even if it
concerned only a specific part of a record. For example, this batch of
information could be the updated price or number of reviews, and we would only
update this specific attribute in your index.&lt;/p&gt;

&lt;p&gt;However, this initial plan did not take into account that most of our big
customers would not benefit from this API due to their existing
infrastructure. If you had not planned to catch all updates in your
architecture, or if you were not using a framework like Ruby on Rails, it
could be very difficult to even have a notification for any of these updates.
The solution in this case was to use a batch update on a regular basis. It was
a good method to use if you didn’t want to change a single line of code in
your existing infrastructure, but the batch update was far from a cure-all.&lt;/p&gt;

&lt;h2 id=&quot;the-problem-of-batch-update&quot;&gt;The problem of batch update&lt;/h2&gt;

&lt;p&gt;There are two main ways to perform a batch update on a regular basis:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Scan your database and update all objects. This method is good if you have no delete operation, but if some data are removed from your database, you will need to perform an extra check to handle delete, which can be very slow.&lt;/li&gt;
  &lt;li&gt;Clear the content of the index and import all your objects. With this method, you ensure that your index is well synchronized with your database. However, if you receive queries during the import, you will return partial results.  If interrupted, the whole rescan could break your relevance or your service.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;So the two approaches are somewhat buggy and dangerous.&lt;/p&gt;

&lt;h2 id=&quot;another-approach-build-a-new-index-with-another-name&quot;&gt;Another approach: build a new index with another name&lt;/h2&gt;

&lt;p&gt;Since our API allows the creation of a new index with a different name, you
could have made your batch import in a new index. Afterward, you would just
need to update your front end to send queries to this new index.&lt;/p&gt;

&lt;p&gt;Since all indexing jobs are done asynchronously, we first need to check that
an indexing job is finished. In order to do that, we return an integer (called
TaskID) that allows you to check if an update job is applied. Thus, you just
have to use the API to check that the job is indexed.&lt;/p&gt;

&lt;p&gt;But then a problem arises with mobile applications: You cannot change the
index name of an application as easily, since most of the time, it is a
constant in the application code. And even for a website, it means that the
batch will need to inform your frontend that the index name is different. This
can be complex.&lt;/p&gt;

&lt;h2 id=&quot;the-elegant-solution-move-operation&quot;&gt;The elegant solution: move operation&lt;/h2&gt;

&lt;p&gt;To solve these problems, we implemented a command that is well known on file
systems: &lt;strong&gt;move&lt;/strong&gt;. You can move your new index on the old one, and this will
atomically update the content of the old index with the content of the new
one. With this new approach, you can solve all the previous update problems
with one simple procedure. Here’s how you would update an index called
“MyIndex”:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Initialize an index “MyIndex.tmp”&lt;/li&gt;
  &lt;li&gt;Scan your database and import all your data in “MyIndex.tmp”&lt;/li&gt;
  &lt;li&gt;Move “MyIndex.tmp in “MyIndex”&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;You don’t have to do any modification on your backend to catch modifications,
nor do you need to change the index name on the frontend. Even better, you
don’t need to check the indexing status with our TaskID system since the
“move” operation will simply be queued after all “adds”. All queries will go
to the new index when it is ready.&lt;/p&gt;

&lt;h2 id=&quot;the-beauty-of-the-move-command&quot;&gt;The beauty of the move command&lt;/h2&gt;

&lt;p&gt;This command is so elegant that even customers who had been sending us
realtime updates via our updates API have decided to use this batch update on
a regular basis. The move command is a good way to ensure that there are no
bugs in your update code, nor divergence between your database and Algolia.&lt;/p&gt;

&lt;p&gt;This operation is supported in our twelve API Clients. We go even further in
our Ruby on Rails integration: You need only use the ’reindex’ command
(introduced in 1.10.5) to automatically build a new temporary index and move
it on top of the existing one.&lt;/p&gt;

&lt;p&gt;The move command is an example of how we try to simplify the life of
developers. If you see any other way we can help you, let us know and we’ll do
our best to remove your pain!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Common Misperceptions about Search as a Service</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/06/05/popular-misperceptions-search-service/"/>
   <updated>2014-06-05T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/06/05/popular-misperceptions-search-service</id>
   <content type="html">&lt;p&gt;Since the first SaaS IPO by &lt;a href=&quot;http://www.salesforce.com/&quot;&gt;salesforce.com&lt;/a&gt;, the
SaaS (Software as a Service) model has boomed in the last decade to become a
global market that is worth billions today. It has taken a long way and a lot
of evangelisation to get there.&lt;/p&gt;

&lt;p&gt;Before &lt;a href=&quot;http://www.salesforce.com/&quot;&gt;salesforce.com&lt;/a&gt; and the other SaaS
pioneers succeeded at making SaaS a standard model, the IT departments were
clear: the infrastructure as well as the whole stack had to be behind their
walls. Since then, mindsets have shifted with the cloud revolution, and you
can now find several softwares such as Box, Jive or Workday used by a lot of
Fortune 500 companies and millions of SMBs and startups.&lt;/p&gt;

&lt;p&gt;Everything is now going SaaS, even core product components such as internal
search. This new generation of SaaS products is facing the same misperceptions
their peers faced years ago. So today, we wanted to dig into the
misperceptions about search as a service in general.&lt;/p&gt;

&lt;h2 id=&quot;hosting-your-search-is-way-more-complex-and-expensive-than-you-may-think&quot;&gt;Hosting your search is way more complex and expensive than you may think&lt;/h2&gt;

&lt;p&gt;Some people prefer to go on-premises as they only pay for the raw resource,
especially if they choose to run open source software on it. By doing this,
they believe they can skip the margin layer in the price of the SaaS
solutions. The problem is that this view highly under-estimates the Total Cost
of Ownership (TCO) of the final solution.&lt;/p&gt;

&lt;p&gt;Here are some reasons why hosting your own search engine can get extremely
complex &amp;amp; expensive:&lt;/p&gt;

&lt;h3 id=&quot;hardware-selection&quot;&gt;Hardware selection&lt;/h3&gt;

&lt;p&gt;A search engine has the particularity of being very IO (indexing), RAM
(search) and CPU (indexing + search) intensive. If you want to host it
yourself, you need to make sure your hardware is well sized for the kind of
search you will be handling. We often see companies that run on under-sized
EC2 instances to host their search engine are simply unable to add more
resource-consuming features (faceting, spellchecking, auto-completion).
Selecting the right instance is more difficult than it seems, and you’ll need
to review your copy if your dataset, feature list or queries per second (QPS)
change. Elasticity is not only about adding more servers, but is also about
being able to add end-users features. Each Algolia cluster is backed by 3
high-end bare metal servers with at least the following hardware
configuration:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;CPU&lt;/strong&gt;: Intel Xeon (E5-1650v2) 6c/12t 3,5 GHz+/3,9 GHz+&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;RAM&lt;/strong&gt;: 128GB DDR3 ECC 1600MHz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Disk&lt;/strong&gt;:  1.2TB  SSD (via 3 or 4 high-durability SSD disks in RAID-0)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This configuration is key to provide instant and realtime search, answering
queries in &amp;lt;10ms.&lt;/p&gt;

&lt;h3 id=&quot;server-configuration&quot;&gt;Server configuration&lt;/h3&gt;

&lt;p&gt;It is a general perception of many technical people that server configuration
is easy: after all it should just be a matter of selecting the right EC2
Amazon Machine Image (AMI) + a puppet/chef configuration, right?
Unfortunately, this isn’t the case for a search engine. Nearly all AMIs
contain standard kernel settings that are okay if you have low traffic, but a
&lt;strong&gt;nightmare&lt;/strong&gt; as soon as your traffic gets heavier. We’ve been working with
search engines for the last 10 years, and we still discover kernel/hardware
corner cases every month! To give you a taste of some heavyweight issues
you’ll encounter, check out the following bullet points:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;IO&lt;/strong&gt;: Default kernel settings are &lt;strong&gt;NOT&lt;/strong&gt; optimized for SSDs!!! For example, Linux’s I/O scheduler is configured to merge some I/Os to reduce the hard-drive latency while seeking the disk sectors: non-sense on SSD and slowing the overall server performance.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Memory&lt;/strong&gt;: The kernel caches a lot, and that’s cool… most of the time. When you write data on the disk, it will actually be written in the RAM and flushed to disk later by the pdflush process. There are some advanced kernel parameters that allow configuration. vm.dirty_background_ratio is one of them: it configures the maximum percentage of memory that can be “dirty” (in cache) before it is written on the disk.  In other words, if you have 128GB of RAM, and you are using the default value of 10% for dirty_background_ratio, the system will only flush the cache when it reaches 12GB!!!! Flushing such bursts of writes will &lt;strong&gt;slow down your entire system&lt;/strong&gt; (even on SSD), killing the speed of all searches &amp;amp; reads. &lt;a href=&quot;http://lonesysadmin.net/2013/12/22/better-linux-disk-caching-performance-vm-dirty_ratio/&quot;&gt;Read more&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Network&lt;/strong&gt;:  When calling the listen function in BSD and POSIX sockets, an argument called the backlog is accepted. The backlog argument defines the maximum length of the queue of pending connections for sockfd. If the backlog argument is higher than the value in net.core.somaxconn, it is silently truncated to that value. The default value is 128 which is &lt;strong&gt;way too low&lt;/strong&gt;! If a connection request arrives when the queue is full, the client may receive an error with an indication of ECONNREFUSED. &lt;a href=&quot;http://engineering.chartbeat.com/2014/01/02/part-1-lessons-learned-tuning-tcp-and-nginx-in-ec2/&quot;&gt;Read more&lt;/a&gt; &amp;amp; &lt;a href=&quot;https://www.youtube.com/watch?v=yL4Q7D4ynxU&quot;&gt;even more&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We’ve been working hard to fine-tune such settings and it has allowed us to
handle today several thousands of search operations per second on one server.&lt;/p&gt;

&lt;h3 id=&quot;deployment--upgrades-are-complex&quot;&gt;Deployment &amp;amp; upgrades are complex&lt;/h3&gt;

&lt;p&gt;Upgrading software is one of the main reasons of service outages. It should be
fully automated and capable of rolling back in case of a deployment failure.
If you want to have a safe deployment, you would also need a pre-production
setup that duplicates your production’s setup to validate a new deployment, as
well as an A/B test with a part of your traffic. Obviously, such setup
requires additional servers. At Algolia, we have test and pre-production
servers allowing us to validate every deployment before upgrading your
production cluster. Each time a feature is added or a bug is fixed on the
engine, all of our clusters are updated so that everyone benefits from the
upgrade.&lt;/p&gt;

&lt;h3 id=&quot;toolbox-vs-features&quot;&gt;Toolbox vs features&lt;/h3&gt;

&lt;p&gt;On-premises solutions were not built to be exposed as a public service: you
always need to build extra layers on top of it. And even if these solutions
have plenty of APIs and low-level features, turning them into end-user
features requires time, resources and a lot of engineering (more than just a
full-stack developer!). You may need to re-develop:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;**Auto-completion&lt;/strong&gt;:** to suggest best products/queries directly from the search bar while handling security &amp;amp; business filters (not only suggesting popular entries);&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Instant-Faceting:&lt;/strong&gt; to provide realtime faceting refreshed at each keystroke;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;**Multi-datacenter replication&lt;/strong&gt;:** synchronize your data across multiple instances and route the queries to the right datacenter to ensure the best search performance all around the world;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Queries analytics&lt;/strong&gt;: to get valuable information on what and how people search;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt;: To track in realtime the state of your servers, the storage you use, the available memory, the performance of your service, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;on-premises-is-not-as-secure-as-one-might-think&quot;&gt;On-premises is not as secure as one might think&lt;/h2&gt;

&lt;p&gt;Securing a search engine is very complex and if you chose to do it yourself,
you will face three main challenges:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt; &lt;strong&gt;Controlling who can access your data&lt;/strong&gt;: You probably have a model that requires permissions associated with your content. Search as a service providers offer packaged features to handle user based restrictions. For example you can generate an API Key that can only target specific indexes. Most on-premise search engines do not provide any access control feature.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Protecting yourself against attacks&lt;/strong&gt;: There are various attacks that your service can suffer from (denial of service, buffer overflow, access control weakness, code injection, etc.). API SaaS providers put a lot of effort into having the best possible security. For example API providers reacted the most quickly to the “HeartBleed” SSL vulnerability; It only took a few hours after disclosure for &lt;a href=&quot;https://www.twilio.com/blog/2014/04/customer-security-notice-on-cve-2014-0160-heartbleed-disclosure.html&quot;&gt;Twilio&lt;/a&gt;, &lt;a href=&quot;https://www.firebase.com/blog/2014-04-08-open-ssl-security-update.html&quot;&gt;Firebase&lt;/a&gt; and &lt;a href=&quot;http://blog.algolia.com/dealing-openssl-security-issue/&quot;&gt;Algolia&lt;/a&gt; to fix the issue.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Protecting yourself from unwarranted downloads:&lt;/strong&gt; The search feature of your website can easily expose a way to grab all your data. Search as a service providers offer packaged features to help prevent this problem (rate limit, time-limited API Key, user-restricted API Key, etc.).&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Mastering these three areas is difficult, and API providers are challenged
every day by their customers to provide a state-of-the-art level of security
in all of them. Reaching the same level of security with an on-premise
solution would simply require too much investment.&lt;/p&gt;

&lt;h2 id=&quot;search-as-a-service-is-not-reserved-to-simple-use-cases&quot;&gt;Search as a service is not reserved to simple use cases&lt;/h2&gt;

&lt;p&gt;People tend to believe that search as a service is only good for basic use
cases, which prevents developers from implementing fully featured search
experiences. The fact of the matter is that search as a service simply handles
all of the heavy lifting while keeping the flexibility to easily configure the
engine. Therefore it enables any developers, even front-end only developers,
to build complex instant search implementation with filters, faceting or geo-
search. For instance, feel free to take a look at
&lt;a href=&quot;http://jadopado.com&quot;&gt;JadoPado&lt;/a&gt;, a customer who developed a fully featured
instant search for their e-commerce store. Because your solution runs inside
your walls once in production,  you will need a dedicated team to constantly
track and fix the multiple issues you will encounter. Who would think of
having a team dedicated to ensuring their CRM software works fine? It makes no
sense if you use a SaaS software like most people do today. Why should it make
more sense for components such as search? All the heavy lifting and the
operational costs are now concentrated in the SaaS providers’ hands, making it
eventually way more cost-efficient for you..&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>A New Way to Handle Synonyms in a Search Engine</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/05/22/synonym-search-engine/"/>
   <updated>2014-05-22T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/05/22/synonym-search-engine</id>
   <content type="html">&lt;p&gt;We recently added the support for Synonyms in Algolia! It has been the most
requested feature in Algolia since our launch in September. While it may seem
simple, it actually took us some time to implement because we wanted to do it
in a different way than classic search engines.&lt;/p&gt;

&lt;h2 id=&quot;whats-wrong-with-synonyms&quot;&gt;What’s wrong with synonyms&lt;/h2&gt;

&lt;p&gt;There are two main problems with how existing search engines handle synonyms.
These issues disturb the user experience and could make them think &lt;em&gt;“this
search engine is buggy”&lt;/em&gt;.&lt;/p&gt;

&lt;h3 id=&quot;typeahead&quot;&gt;Typeahead&lt;/h3&gt;

&lt;p&gt;In most search engines, synonyms are not compatible with typeahead search. For
example, if you want tablet  to equal  ipad in a query, the prefix search for
t , ta , tab , tabl  &amp;amp; table  will not trigger the expansion on iPad ; Only
the tablet query will. Thus, a single new letter in the search bar could
totally change the result set, catching users off-guard.&lt;/p&gt;

&lt;h3 id=&quot;highlighting&quot;&gt;Highlighting&lt;/h3&gt;

&lt;p&gt;Highlighting matched text is a key element of the user experience, especially
when the search engine tolerates typos. This is the difference between making
users think &lt;em&gt;“I don’t understand this result”&lt;/em&gt; and &lt;em&gt;“This engine was able to
understand my errors”&lt;/em&gt;. Synonym expansions are rarely highlighted, which
breaks the trust of the users in the search results and can feel like a bug.&lt;/p&gt;

&lt;h2 id=&quot;our-implementation&quot;&gt;Our implementation&lt;/h2&gt;

&lt;p&gt;We have identified two different use cases for synonyms: equalities and
placeholders. The first and most common use case is when you tell the search
engine that several words must be considered equal, for example st and street
in an address. The second use case, which we call a &lt;em&gt;placeholder&lt;/em&gt;, is when you
indicate that a specific token can be replaced by a set of possible words and
that the token itself is not searchable. For example, the content &lt;number&gt;
street could be matched by the queries 1st street or 2nd street but not the
query number street.&lt;/number&gt;&lt;/p&gt;

&lt;p&gt;For the first use case, we have added a support of synonyms that is compatible
with prefix search and have implemented two different ways to do highlighting
(controlled by thereplaceSynonymsInHighlight  query parameter):&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;A mode where the original word that matched via a synonym is highlighted. For example if you have a record that contains black ipad 64GB  and a synonym black equals dark, then the following queries will fully highlight the black word : ipad d , ipad da , ipad dar &amp;amp; ipad dark. The typeahead search is working and the synonym expansion is fully highlighted: &lt;code&gt;**black** **ipad** 64GB&lt;/code&gt; .&lt;/li&gt;
  &lt;li&gt;A mode where the original word is replaced by the synonym, and the matched prefix is highlighted. For example ipad d  query will replace black by dark and will highlight the first letter of dark: &lt;code&gt;**d**ark **ipad** 64GB&lt;/code&gt;. This method allows to fully explain the results when the original word can be safely replaced by the matched synonym.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;For the second use case, we have added support for placeholders. You can add a
specific token in your records that will be safely replaced by a set of words
defined in your configuration. The highlighting mode that replaces the
original word by the expansion totally makes sense here. For example if you
have &lt;streetnumber&gt; mission street  record with a placeholder &lt;streetnumber&gt; =
[ &quot;1st&quot;, &quot;2nd&quot;, ....] , then the query 1st missionstreet will replace &lt;number&gt;
by 1st  and will highlight all words: `**1st mission street**`.&lt;/number&gt;&lt;/streetnumber&gt;&lt;/streetnumber&gt;&lt;/p&gt;

&lt;p&gt;We believe this is a better way to handle synonyms and we hope you will like
it :) We would love to get your feedback and ideas for improvement on this
feature! Feel free to contact us at &lt;strong&gt;hey(at)algolia.com&lt;/strong&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Why JSONP is still Mandatory</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/05/14/jsonp-still-mandatory/"/>
   <updated>2014-05-14T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/05/14/jsonp-still-mandatory</id>
   <content type="html">&lt;p&gt;At Algolia, we are convinced that search queries need to be sent directly from
the browser (or mobile app) to the search-engine in order to have a realtime
search experience. This is why we have developed a search backend that replies
within a few milliseconds through an API that &lt;a href=&quot;http://blog.algolia.com/handle-security-realtime-search/&quot;&gt;handles
security&lt;/a&gt; when
called from the browser.&lt;/p&gt;

&lt;h2 id=&quot;cross-domain-requests&quot;&gt;Cross domain requests&lt;/h2&gt;

&lt;p&gt;For security reasons, the default behavior of a web browser is to block all
queries that are going to a domain that is different from the website they are
sent from. So when using an external HTTP-based search API, all your queries
should be blocked because they are sent to an external domain. There are two
methods to call an external API from the browser:&lt;/p&gt;

&lt;h3 id=&quot;jsonp&quot;&gt; JSONP&lt;/h3&gt;

&lt;p&gt;The &lt;a href=&quot;http://en.wikipedia.org/wiki/JSONP&quot;&gt;JSONP&lt;/a&gt; approach is a workaround that
consists of calling an external API  with a DOM &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;  tag. The &lt;code&gt;&amp;lt;script&amp;gt;&lt;/code&gt;
tag is allowed to load content from any domains without security restrictions.
The targeted API needs to expose a HTTP GET endpoint and return Javascript
code instead of the regular JSON data. You can use this jQuery code to
dynamically call a JSONP URL:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;javascript
$.getJSON( &quot;http://api.algolia.io/1/indexes/users?query=test&quot;, function( data ) { .... }
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;In order to retrieve the API answer from the newly included JavaScript code,
jQuery automatically appends a callback argument to your URL (for example
&amp;amp;callback=method12 ) which must be called by the JavaScript code that your API
generates.&lt;/p&gt;

&lt;p&gt;This is what a regular JSON reply would look like:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;json
{
  &quot;results&quot;: [ ...]
}
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Instead, the JSONP-compliant API generates:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;javascript
method12({&quot;results&quot;: [ ...]});
&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;cross-origin-resource-sharing&quot;&gt;Cross Origin Resource Sharing&lt;/h3&gt;

&lt;p&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/Cross-origin_resource_sharing&quot;&gt;CORS&lt;/a&gt; (Cross
Origin Resource Sharing) is the proper approach to perform a call to an
external domain. If the remote API is CORS-compliant, you can use a regular
XMLHttpRequest  JavaScript object to perform the API call. In practice the
browser will first perform an HTTP OPTIONS request to the remote API to check
which caller domains are allowed and if it is authorized to execute the
requested URL.&lt;/p&gt;

&lt;p&gt;For example here is a CORS request issued by a browser. The most important
lines are the last two headers that specify which permissions are checked. In
this case, the method is POST and the three specific HTTP headers that are
requested.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;OPTIONS http://latency.algolia.io/1/indexes/*/queries
&amp;gt; Host: latency.algolia.io
&amp;gt; Origin: http://demos.algolia.com
&amp;gt; Accept-Encoding: gzip,deflate,sdch
&amp;gt; Accept-Language: en-US,en;q=0.8,fr;q=0.6
&amp;gt; User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_2)
&amp;gt; Accept: */*
&amp;gt; Referer: http://demos.algolia.com/eventbrite/
&amp;gt; Connection: keep-alive
&amp;gt; Access-Control-Request-Headers: x-algolia-api-key, x-algolia-application-id, content-type
&amp;gt; Access-Control-Request-Method: POST
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The server reply will be similar to this one:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt; HTTP/1.1 200 OK
&amp;lt; Server: nginx/1.6.0
&amp;lt; Date: Tue, 13 May 2014 08:33:55 GMT
&amp;lt; Content-Type: text/plain
&amp;lt; Content-Length: 0
&amp;lt; Connection: keep-alive
&amp;lt; Access-Control-Allow-Origin: *
&amp;lt; Access-Control-Allow-Methods: GET, PUT, DELETE, POST, OPTIONS
&amp;lt; Access-Control-Allow-Headers: x-algolia-api-key, x-algolia-application-id, content-type
&amp;lt; Access-Control-Allow-Credentials: false &amp;lt; Expires: Wed, 14 May 2014 08:33:55 GMT
&amp;lt; Cache-Control: max-age=86400
&amp;lt; Access-Control-Max-Age: 86400
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This answer indicates that this POST method can be called from any domain
(Access-Control-Allow-Origin: * ) and with the requested headers.&lt;/p&gt;

&lt;p&gt;CORS has many advantages. First, it allows access to a real REST API with all
HTTP verbs (mainly GET, POST, PUT, DELETE) and it also allows to better handle
errors in an API (bad requests, object not found, …). The major drawback is
that it is only supported by modern browsers (Internet Explorer ≥ 10, Firefox
≥ 3.5, Chrome ≥ 3, Safari ≥ 4 &amp;amp; Opera ≥ 12; Internet Explorer 8 &amp;amp; 9 provides
partial support via theXDomainRequest  object).&lt;/p&gt;

&lt;h2 id=&quot;our-initial-conclusion&quot;&gt;Our initial conclusion&lt;/h2&gt;

&lt;p&gt;Because of the advantages of CORS in terms of error handling, we started with
a CORS implementation of our API. We also added a specific support for
Internet Explorer 8 &amp;amp; 9 using the  XDomainRequest  JavaScript object (they do
not support XMLHttpRequest). The main difference is that XDomainRequest  does
not support HTTP headers so we added another way to specify user credentials
in the body of the POST request (it was initially only supported via HTTP
headers).&lt;/p&gt;

&lt;p&gt;We were confident that we were supporting almost all browsers with this
implementation, as only very old browsers could cause problems. But we were
wrong!&lt;/p&gt;

&lt;h2 id=&quot;cors-problems&quot;&gt;CORS problems&lt;/h2&gt;

&lt;p&gt;The reality is that CORS still causes problems, even with modern browsers. The
biggest problem we have found was with some firewalls/proxies that refuse HTTP
OPTIONS queries. We even found software on some computers that were blocking
CORS requests, as the &lt;a href=&quot;http://www.bennadel.com/blog/2559-cisco-anyconnect-vpn-client-may-
block-cors-ajax-options-requests.htm&quot;&gt;Cisco AnyConnect VPN
client&lt;/a&gt;, which is widely used in the enterprise
world. We have found this issue when a TechCrunch employee was not able to
operate search on &lt;a href=&quot;http://www.crunchbase.com&quot;&gt;crunchbase.com&lt;/a&gt; because the
AnyConnect VPN client was installed on his laptop.&lt;/p&gt;

&lt;p&gt;Even in 2014 with a large majority of browsers supporting CORS, it is not
possible to have perfect service quality with a CORS-enabled REST API!&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The solution&lt;/h2&gt;

&lt;p&gt;Using JSONP is the only solution to ensure great compatibility with old
browsers and handle problems with a misconfigured firewall/proxy. However,
CORS offers the advantage of proper error-handling, so we do not want to limit
ourselves to JSONP.&lt;/p&gt;

&lt;p&gt;In the latest version of our JavaScript client, we decided to use CORS with a
fallback on JSONP. At client initialization time, we check if the browser
supports CORS and then perform an OPTIONS query to check that there is no
firewall/proxy that blocks CORS requests. If there is any error we fallback on
JSONP. All this logic is available in our JavaScript client without any
API/code change for our customers.&lt;/p&gt;

&lt;p&gt;Having CORS support with automatic fallback on JSONP is the best way we have
found to ensure great service quality and to support all corner case
scenarios. If you see any other way to do it, your feedback is very welcome.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Inside GrowthHackers.com's Implementation of Algolia</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/05/02/inside-growthhackers-implementation-of-algolia/"/>
   <updated>2014-05-02T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/05/02/inside-growthhackers-implementation-of-algolia</id>
   <content type="html">&lt;p&gt;We interviewed &lt;a href=&quot;https://twitter.com/dylanLaCom&quot;&gt;Dylan La Com&lt;/a&gt;, Growth Product
Manager at &lt;a href=&quot;https://qualaroo.com&quot;&gt;Qualaroo&lt;/a&gt; &amp;amp;
&lt;a href=&quot;http://growthhackers.com&quot;&gt;GrowthHackers.com&lt;/a&gt;, about their Algolia
implementation experience.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2014/05/growthacker.jpg&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/growthacker.jpg&quot; alt=&quot;growthacker&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-role-did-search-play-at-growthhackers-before-the-algolia&quot;&gt;What role did search play at GrowthHackers before the Algolia&lt;/h3&gt;
&lt;p&gt;implementation?&lt;/p&gt;

&lt;p&gt;When we launched our community site
&lt;a href=&quot;http://growthhackers.com/&quot;&gt;GrowthHackers.com&lt;/a&gt; in October 2013, search was
admittedly an afterthought for us. GrowthHackers is a social-voting site where
marketers, founders, and product-people can share and discuss growth-related
content. At launch, it was unclear what role search would have on the site.
GrowthHackers is built on Wordpress, and with that comes Wordpress’ standard
search functionality. What WP search does is append an additional keyword or
phrase parameter to its typical post query and load a new page with the
results. WP search only indexed the outbound URLs of the articles our members
submitted, and this made finding specific content difficult.&lt;/p&gt;

&lt;h3 id=&quot;why-did-you-want-to-give-search-an-update-on-growthhackers&quot;&gt;Why did you want to give search an update on GrowthHackers?&lt;/h3&gt;

&lt;p&gt;We started hearing about our lack of a solid search feature from some of our
more active users. One of our members even put together a slide presentation
to prove just how useless our search was [&lt;a href=&quot;http://www.slideshare.net/andrewmatthewthompson/improving-search-on-growthhackers&quot;&gt;check it out
here&lt;/a&gt;]. At the same time, GrowthHackers was becoming more than just a
way to stay up-to-date on the best growth articles, it was becoming the place
to get answers: an encyclopedia for growth-related information. Search volume
at this time was peaking in the mid-hundreds per week. We needed a search
feature that could support this evolving use-case.&lt;/p&gt;

&lt;h3 id=&quot;why-did-you-choose-algolia&quot;&gt;Why did you choose Algolia?&lt;/h3&gt;

&lt;p&gt;We looked at several search solutions before trying Algolia, including
Swiftype, WP Search (plugin), and Srch2. All are great solutions, but
ultimately, we went with Algolia because they had the right mix of features:
Their integration was simple, the documentation was thorough, and there were
plenty of starter templates. I knew it was a good sign when, while looking
their GitHub repository, I found they had a demo site built with search that
worked very similar to how we hoped ours would work, complete with real-time
results, typo-tolerance, and filters. The Algolia team was incredibly helpful
getting us set up and was there each step of the way through the integration
process, providing resources and best practices for creating a truly top-notch
search experience.&lt;/p&gt;

&lt;h3 id=&quot;tell-me-a-little-about-how-the-new-search-works&quot;&gt;Tell me a little about how the new search works.&lt;/h3&gt;

&lt;p&gt;Our primary use of Algolia is to store and index user submitted content, and
provide real-time search in our growing database of growth-related articles,
questions, videos and slides. The majority of what we index is article titles
and URLs–strings which are generally small. Visitors to our site often come
with specific growth-related questions and use our search to find answers
quickly. For example, someone interested in learning best practices for
running Twitter ads could type in “Twitter ad” and within milliseconds see
dozens of articles and discussions related to maximizing ROI for Twitter ads.
Using Algolia’s admin dashboard, we’re able to set ranking priorities based on
the number of votes and comments of each article, and make sure the top
results are the most relevant. So, the visitor who searches “Twitter ad” is
shown articles with the highest mix of votes and comments. Algolia took the
search ranking process and wrapped it in a clean and simple interface that
allows anyone, regardless of their experience with search, to easily adjust
and manipulate.&lt;/p&gt;

&lt;p&gt;One of the challenges we faced during the integration process was
understanding how to keep our main database synced and up to date with our
Algolia index. User submitted content on GrowthHackers changes often as users
interact with the content. Each post once submitted may receive upvotes and
comments from members in the community. Each post also has a wiki-style
summary field that can be edited by community members. Lastly, posts can have
several states, including published, pending and trashed. In order to ensure
our content on Algolia mirrored the content in our database, we set up a job
queue and a cron process to periodically push updates to our Algolia index.
This has been working quite well for us.&lt;/p&gt;

&lt;h3 id=&quot;how-has-the-new-search-impacted-engagement&quot;&gt;How has the new search impacted engagement?&lt;/h3&gt;

&lt;p&gt;We released the new search mid-February, and since the release we’ve seen
search volume increase 4-5X. Of course there are several factors at play here,
including increased traffic volume and better search bar placement, but it is
clear that Algolia’s search features have contributed to an impressive
increase in search engagement. On average, visitors who utilize search view
2-3X more pages per session and spend 5-6X longer on the site than those who
don’t search. Algolia’s analytics dashboard provides us with an incredible
glimpse of visitor intent on our site by showing us the queries visitors are
searching for, and trend lines to show popularity over time. With this data,
we’re able to better understand how our visitors want to use our site, and
make better decisions about how to organize the content.&lt;/p&gt;

&lt;p&gt;Moving forward, we’re hoping to implement Algolia’s search filters to provide
even better ways to access content on our site. We’re excited to have such a
powerful tool in our stack and hope to experiment with new ways to provide
search functionality throughout GrowthHackers.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Dealing with OpenSSL Heartbleed Vulnerability</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/04/09/dealing-openssl-security-issue/"/>
   <updated>2014-04-09T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/04/09/dealing-openssl-security-issue</id>
   <content type="html">&lt;p&gt;Yesterday, the OpenSSL project released an update to fix a serious security
issue. This vulnerability was disclosed in &lt;a href=&quot;https://web.nvd.nis
t.gov/view/vuln/detail?vulnId=CVE-2014-0160&quot;&gt;CVE-2014-0160&lt;/a&gt; and is more widely known as the
&lt;a href=&quot;http://heartbleed.com/&quot;&gt;Heartbleed vulnerability&lt;/a&gt;. It allows an attacker to
grab the content in memory on a server. Given the widespread use of OpenSSL
and the versions affected, this vulnerability affects a large percentage of
services on the internet.&lt;/p&gt;

&lt;p&gt;Once the exploit was revealed, we responded immediately: All Algolia services
were secured the same day, by 3pm PDT on Monday, April 7th. The fix was
applied on all our API servers and our website. We then generated new SSL
certificates with a new private key.&lt;/p&gt;

&lt;p&gt;Our website is also dependent on Amazon Elastic Load Balance, which was
affected by this issue and &lt;a href=&quot;http://aws.amazon.com/security/security-
bulletins/aws-services-updated-to-address-openssl-vulnerability/&quot;&gt;updated&lt;/a&gt; later on
Tuesday, April 8th. We then changed the website certificate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;All Algolia servers are no longer exposed to this vulnerability.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;your-credentials&quot;&gt;Your credentials&lt;/h2&gt;

&lt;p&gt;We took the time to analyze the past activity on our servers and did not find
any suspicious activity. We are confident that no credentials were leaked.
However, given that this exploit existed in the wild for such a long time, it
is possible that an attacker could have stolen API keys or passwords without
our knowledge. As a result, we recommend that all Algolia users change the
passwords on their accounts. We also recommend that you reset your Algolia
administration API key, which you can do at the bottom of the “Credential”
section in your dashboard. Be careful to update it everywhere you use it in
your code (once you have patched your SSL library if you too are vulnerable).&lt;/p&gt;

&lt;h2 id=&quot;security-at-algolia&quot;&gt;Security at Algolia&lt;/h2&gt;

&lt;p&gt;The safety and security of our customer data are our highest priorities. We
are continuing to monitor the situation and will respond rapidly to any other
potential threats that may be discovered.&lt;/p&gt;

&lt;p&gt;If you have any questions or concerns, please email us directly at
&lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#115;&amp;#101;&amp;#099;&amp;#117;&amp;#114;&amp;#105;&amp;#116;&amp;#121;&amp;#064;&amp;#097;&amp;#108;&amp;#103;&amp;#111;&amp;#108;&amp;#105;&amp;#097;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;&amp;#115;&amp;#101;&amp;#099;&amp;#117;&amp;#114;&amp;#105;&amp;#116;&amp;#121;&amp;#064;&amp;#097;&amp;#108;&amp;#103;&amp;#111;&amp;#108;&amp;#105;&amp;#097;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Introducing Search Analytics: Know Your Users Better</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/03/29/introducing-algolias-search-analytics/"/>
   <updated>2014-03-29T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/03/29/introducing-algolias-search-analytics</id>
   <content type="html">&lt;p&gt;This week we have released a much requested feature by our customers:
analytics.&lt;/p&gt;

&lt;h3 id=&quot;the-importance-of-analytics-to-search&quot;&gt;The importance of analytics to search&lt;/h3&gt;

&lt;p&gt;At Algolia, our goal is to revolutionize the way people search and access
content inside the Web and mobile services. Think about Spotify, LinkedIn,
Amazon: Everyone wants to find the right songs, people and products in just a
couple keystrokes. Our challenge is to provide fast and meaningful access to
all of this content via a simple search box. In March, we answered more than
200 million user queries for our customers on every continent.&lt;/p&gt;

&lt;p&gt;Providing the right content through the right search and browsing experience
is key. For our customers, understanding their users - what they like, what
they want and when they want it -  is just as important, if not more. This is
why we came up with this new analytics section, built on top of our API and
available on our customers’ online dashboards when they log in to their
Algolia account. So what exactly do we track for you?&lt;/p&gt;

&lt;p&gt;We describe here some of the top features that are now available to all our
users.&lt;/p&gt;

&lt;h3 id=&quot;most-popular-queries&quot;&gt;Most popular queries&lt;/h3&gt;

&lt;p&gt;In this chart, we show which items were most queried. It would be useful, for
example, to a procurement department for anticipating their  most frequently-
searched products’ inventory needs. And if you monetize your service through
advertising, know what people are most interested in is especially valuable.&lt;/p&gt;

&lt;p&gt;A new analytics feature supports the most popular queries.&lt;/p&gt;

&lt;h3 id=&quot;queries-with-no-or-a-few-results&quot;&gt;Queries with no or a few results&lt;/h3&gt;

&lt;p&gt;Today, most services are simply clueless when it comes to what is missing in
their content base. How do you know that your catalogue of products fits your
users’ expectations? Knowing whether or not you provide what your users need
is critical for your business.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2014/03/Top-search.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Top-search-1024x409.png&quot; alt=&quot;Search Analytics: Track top queries&quot; /&gt;&lt;/a&gt; Algolia lets you determine which top queries have few or
nonexistent results.&lt;/p&gt;

&lt;h3 id=&quot;how-does-a-query-evolve-over-time&quot;&gt;How does a query evolve over time?&lt;/h3&gt;

&lt;p&gt;Is Chanel more popular than Louis Vuitton in the morning or at night? Are
bikes more popular in June or in December? With this new feature, you can now
answer such questions for your own content by following the number of times a
specific query is typed on an hourly basis.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Trend Louboutin.png&quot; alt=&quot;Search Analytics: Track
popularity of a search query over
time&quot; /&gt; Example: Search
analytics lets you track the evolution of the query “louboutin” over 24
hours.&lt;/p&gt;

&lt;h3 id=&quot;which-categories-do-people-search-the-most&quot;&gt;Which categories do people search the most?&lt;/h3&gt;

&lt;p&gt;When users type in a query, they often use categories to refine the results.
We let you know which categories were the most frequently used for refinement.
We even provide the most used combinations of categories (such as “dress” +
“blue” + “size M”). It should help you understand how your users browse your
content and has broader implications if the ergonomics of your app is
optimized.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Top categories.png&quot; alt=&quot;Search Analytics: Top categories used for filtering an
refinement&quot; /&gt; Track which
combinations of categories people search for the most.&lt;/p&gt;

&lt;p&gt;These new analytics features are included in our existing plans at no extra
cost. The number of days when our analytics tools are available vary based on
the plan you choose. We hope you will like it, and we will be more than happy
to read your feedback and feature requests!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>On HipChat's blog: Algolia extends HipChat to customer support</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/03/25/hipchats-blog-algolia-extends-hipchat-customer-support/"/>
   <updated>2014-03-25T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/03/25/hipchats-blog-algolia-extends-hipchat-customer-support</id>
   <content type="html">&lt;p&gt;As you may probably know, we’re using HipChat to build our live-help chat. If
you want to know more, go ahead and read our &lt;a href=&quot;http://blog.hipchat.com/2014/03/25/algolia-extends-hipchat-to-customer-support/&quot;&gt;guest post on HipChat’s
blog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.hipchat.com/2014/03/25/algolia-extends-hipchat-to-customer-support/&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Divided%20screen%20hipchat%20algolia.png&quot; alt=&quot;Hipchat: Live help chat.&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Algolia uses HipChat to
provide live customer service over chat.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Realtime Search: Security and our Javascript Client</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/03/18/handle-security-realtime-search/"/>
   <updated>2014-03-18T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/03/18/handle-security-realtime-search</id>
   <content type="html">&lt;p&gt;&lt;em&gt;&lt;strong&gt;Edit: As suggested on &lt;a href=&quot;https://news.ycombinator.com/item?id=7419205&quot;&gt;Hacker
News&lt;/a&gt;, SHA256 is not secure, as
it allows a length extension attack. We have replaced it with HMAC-SHA256.&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Instant is in our DNA, so our first priority was to build a search backend
that would be able to return relevant realtime search results in a few
milliseconds. However, the backend is just one variable in our realtime
equation. The response time perceived by the end user is the total lapse of
time between their first keystroke and the final display of their results.
Thus, with an extremely fast backend, solving this equation comes down to
optimising network latency. This is an issue we solve in two steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;First, we have &lt;a href=&quot;http://blog.algolia.com/added-asian-datacenter-offer/&quot;&gt;datacenters in three different locations&lt;/a&gt;, allowing us to answer queries in North America, Europe and Asia in less than 100ms (including search computation).&lt;/li&gt;
  &lt;li&gt;Second, to keep reducing this perceived latency, queries must be sent directly from the end users’ browsers or mobile phones to our servers. To avoid intermediaries like your own servers, we offer a JavaScript client for websites and ObjC/Android/C# clients for mobile apps.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-security-challenge-of-javascript&quot;&gt;The security challenge of JavaScript&lt;/h2&gt;

&lt;p&gt;Using this client means that you need to include an API key in your JavaScript
(or mobile app) code. The first security issue with this approach is that this
key can be easily retrieved by anyone who simply looks at the code of the
page. This gives that person the potential to modify the content behind the
website/mobile application! To fix this problem, we provide search-only API
keys which protect your indexes from unauthorized modifications.&lt;/p&gt;

&lt;p&gt;This was a first step and we’ve quickly had to solve two other security
issues:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;**Limiting the ability to crawl your data: **you may not want people to get all your data by continuous querying. The simple solution was to limit the number of API calls a user could perform in a given period of time. We implemented this by setting a rate limit per IP address. However, this approach is not acceptable if a lot of users are behind a global firewall, thus sharing one IP address. This is very likely for our corporate users.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Securing access control&lt;/strong&gt;:  you may need to restrict the queries of a user to specific content. For example, you may have power users who should get access to more content than “regular” users. The easy way to do it is by using filters. The problem here with simple filters in your JavaScript code is that people can figure out how to modify these filters and get access to content they are not be supposed to see.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-we-solve-it-altogether&quot;&gt;How we solve it altogether&lt;/h2&gt;

&lt;p&gt;Today, most websites and applications require people to create an account and
log in to access a personalized experience (think of CRM applications,
Facebook or even Netflix). We decided to use these user IDs to solve these two
issues by creating signed API keys. Let’s say you have an API key with search
only permission and want to apply a filter on two groups of content (public OR
power_users_only) for a specific user (id=42):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;api_key=20ffce3fdbf036db955d67645bb2c993
query_filters=(public,power_users_only)
user_token=42
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can generate a secured API key in your backend that is defined by a hash
(HMAC SHA 256) of three elements:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;secured_api_key=HMAC_SHA_256(api_key, query_filters + user_token)
secured_api_key=HMAC_SHA_256(&quot;20ffce3fdbf036db955d67645bb2c993&quot;, &quot;(public,power_users_only)&quot; + &quot;42&quot;)
secured_api_key=&quot;3abb95c273455ce9b57c61ee5258ba44093f17022dd4bfb39a37e56bee7d24a5&quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For example, if you are using rails, the code in your backend would be:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;secured_key = Algolia.generate_secured_api_key(&#39;20ffce3fdbf036db955d67645bb2c993&#39;, &#39;(public,power_users_only)&#39;, &#39;42&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can then initialize your JavaScript code with the secured API key and
associated information:&lt;/p&gt;

&lt;p&gt;The user identifier (defined by SetUserToken) is used instead of the IP
address for the rate limit and the security filters (defined by
SetSecurityTags) are automatically applied to the query.&lt;/p&gt;

&lt;p&gt;In practice, if a user wants to overstep her rights, she will need to modify
her security tags and figure out the new hash. Our backend checks if a query
is legit by computing all the possible hashes using all your available API
keys for the queried index, as well as the security tags defined in the query
and the user identifier (if set).  If there is no match between the hash of
the query and the ones we computed, we will return a permission denied (403).
Don’t worry, reverse-engineering the original API key using brute-force would
require years and &lt;a href=&quot;http://en.wikipedia.org/wiki/SHA-2#Comparison_of_SHA_functions&quot;&gt;thousands of
core&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;You may want to apply security filters without limiting the rate of queries,
so if you don’t need both of these features, you can use only one.&lt;/p&gt;

&lt;p&gt;We launched this new feature a few weeks ago and we have received very good
feedback so far. Our customers don’t need to choose anymore between security
and realtime search. If you see any way to improve this approach, we would
love to hear your feedback!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>What Caused Today's Search Performance Issues In Europe and Why It Will Not Happen Again</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/03/17/caused-todays-performance-issues-europe-will-happen/"/>
   <updated>2014-03-17T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/03/17/caused-todays-performance-issues-europe-will-happen</id>
   <content type="html">&lt;p&gt;During a few hours on March 17th you may have noticed longer response times
for some of the queries sent by your users.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/slowerthanaverage.png&quot; alt=&quot;Slower than average search
performance&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Average latency for one of our European clusters on March 17th&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;As you can see above, our slowest average response time (measured from the
user’s browser to our servers and back to the user’s browser) on one of our
European clusters peaked at 858ms. On a normal day, this peak is usually no
higher than 55ms.&lt;/p&gt;

&lt;p&gt;This was clearly not a normal behavior for our API, so we investigated.&lt;/p&gt;

&lt;h2 id=&quot;how-indexing-and-search-calls-share-the-resource&quot;&gt;How indexing and search calls share the resource&lt;/h2&gt;

&lt;p&gt;Each cluster handles two kinds of calls on our REST API: the ones to build and
modify the indexes (Writes) and the ones to answer users’ queries (Search).
The resources of each cluster are shared between these two uses. As Write
operations are far more expensive than Search calls, we designed our API so
that indexing should never use more than 10% of these resources.&lt;/p&gt;

&lt;p&gt;Up until now, we used to set a limitation on the rate of Writes &lt;em&gt;per HTTP
connection&lt;/em&gt;. There was no such limit for queries (Search); We simply limited
Write calls to keep search quality. To avoid reaching the Write rate limit too
quickly, we recommended users to Write by batching up to 1GB of operations per
call, rather than sending them one by one. (A batch, for example, could be
adding 1M products to an index on a single network call.) A loophole in this
recommendation was the origin of yesterday’s issues.&lt;/p&gt;

&lt;p&gt;What happened yesterday is that on one of our European clusters, one customer
pushed so many unbatched indexing calls from different HTTP connections that
they massively outnumbered the search calls of the other users on the cluster.&lt;/p&gt;

&lt;p&gt;This eventually slowed down the average response time for the queries on this
cluster, impacting our usual search performance.&lt;/p&gt;

&lt;h2 id=&quot;the-solution&quot;&gt;The Solution&lt;/h2&gt;

&lt;p&gt;As of today, we now set the rate limit of Writes &lt;em&gt;per account&lt;/em&gt; and not per
HTTP connection. It prevents anyone from using multiple connections to bypass
this Write rate limit. This also implies that customers who want to push a lot
of operations in a short time simply need to send their calls in batches.&lt;/p&gt;

&lt;p&gt;How would you batch your calls? The explanation is in our documentation. See
here for an example with our Ruby client: &lt;a href=&quot;https://github.com/algolia
/algoliasearch-client-ruby#batch-writes&quot;&gt;https://github.com/algolia
/algoliasearch-client-ruby#batch-writes&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Heroku add-on enters general availability</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/03/15/algolia-heroku-add-on-enters-ga/"/>
   <updated>2014-03-15T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/03/15/algolia-heroku-add-on-enters-ga</id>
   <content type="html">&lt;p&gt;We launched the first beta of our Heroku add-on in October 2013 and are now
happy to announce its general availability!&lt;/p&gt;

&lt;p&gt;During the beta period we received excellent feedback (and some bug reports!)
that helped us improve our integration. We are now fully ready to serve
production on both Heroku datacenters. If you were part of our beta program,
we will contact you shortly to invite you to migrate to a standard plan.&lt;/p&gt;

&lt;p&gt;You can directly install it from our &lt;a href=&quot;https://addons.heroku.com/algoliasearch&quot;&gt;Heroku add-on
page&lt;/a&gt; and as ever, please &lt;a href=&quot;&amp;#109;&amp;#097;&amp;#105;&amp;#108;&amp;#116;&amp;#111;:&amp;#104;&amp;#101;&amp;#121;&amp;#064;&amp;#097;&amp;#108;&amp;#103;&amp;#111;&amp;#108;&amp;#105;&amp;#097;&amp;#046;&amp;#099;&amp;#111;&amp;#109;&quot;&gt;let us
know&lt;/a&gt; if you have any feedback!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Now Provides Realtime Search in Asia!</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/03/14/added-asian-datacenter-offer/"/>
   <updated>2014-03-14T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/03/14/added-asian-datacenter-offer</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://blog.algolia.com/added-asian-
datacenter-offer/screen-shot-2014-03-13-at-17-51-50/&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2014-03-13-at-17.51.50-300x199.png&quot; alt=&quot;New datacenter allows realtime search in Asia&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;One of the terrific advantages of building a SaaS company is that your clients
can be anywhere in the world. We now have customers in more than 15 different
countries distributed across South America, Europe, Africa, and, of course,
North America. We feel incredibly lucky to have so many international
customers trusting us with their search.&lt;/p&gt;

&lt;p&gt;Language support is one of the key factors that enabled us to enter these
markets. Since the beginning, we wanted to support every language used on the
Internet. To back our vision with action, we developed a very good support of
Asian languages over time. As an example, we are able to automatically
retrieve results in Traditional Chinese when the query is in Simplified
Chinese (or vice-versa). You simply need to add objects in Chinese, Japanese
or Korean, and we handle the language processing for you.&lt;/p&gt;

&lt;p&gt;Despite the fact that we could process Asian languages well, we didn’t plan to
open an Asian datacenter so early, mainly because we thought the API as a
service market was less mature in Asia than in the US or Europe. But we were
surprised when an article on &lt;a href=&quot;http://www.36kr.com/p/209747.html&quot;&gt;36kr.com&lt;/a&gt;
gave us dozen of signups from China. We got more signups from China in the
past month than from Canada!&lt;/p&gt;

&lt;p&gt;One of our core values is the speed of our search engine. To provide a
realtime search experience, we want the response times to be lower than 100ms,
including the round trip to search servers. In this context a low latency is
essential. Up to now we have been able to cover North America and Europe in
less than 100ms (search computation included) but our latency with Asia was
between 200ms and 300ms.&lt;/p&gt;

&lt;p&gt;The first step of our on-boarding process is to select the datacenter where
your search engine is hosted (we offer multi-datacenter distribution only for
enterprise users). Interestingly, we discovered that we had no drop for
European &amp;amp; US users but it became significant for others. It was a difficult
choice for people outside of these two regions, or even between the two
datacenters. So we also now display the latency from your browser and pre-
select the “closest” datacenter.&lt;/p&gt;

&lt;p&gt;To propose better latency and to reduce friction in the on-boarding process,
it was clear that we had to add a datacenter in Asia. We chose Singapore for
its central location. Unfortunately, the hosting market is very different in
Asia. It’s much more expensive to rent servers, so we sadly had to add a
premium on plan prices when choosing this datacenter.&lt;/p&gt;

&lt;p&gt;We are very happy to open this new datacenter in Asia with a latency that
reaches our quality standard. Now that Algolia provides realtime search in
Asia, we are even happier to be able to help multinational websites and apps
provide a great search experience to all their users across Europe, North
America &amp;amp; Asia in less than 100ms with our multi-datacenter support!*&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Multi-datacenter support is currently only available for Enterprise
accounts.&lt;/em&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Introducing Easier Onboarding and Activation with Connectors</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/02/10/mongodb-and-sql-connectors/"/>
   <updated>2014-02-10T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/02/10/mongodb-and-sql-connectors</id>
   <content type="html">&lt;p&gt;Most of our users are &lt;strong&gt;technical&lt;/strong&gt;. They love writing code, and we love
providing API clients in the major programming languages to them (we are
currently &lt;a href=&quot;http://www.algolia.com/doc/apiclients)&quot;&gt;supporting 10 platforms&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;They are doers. They love prototyping. Just like us, they work for startups
which need to move fast, and get things done, keeping in mind that done is
better than perfect. It is very important that they &lt;strong&gt;don’t want to waste
time&lt;/strong&gt;. In this post, I will explain how one would have used our API up to
now, and how we introduced SQL and MongoDB connectors for easier onboarding,
integration and testing.&lt;/p&gt;

&lt;h2 id=&quot;beforethe-first-steps-with-our-api&quot;&gt;Before: The first steps with our API&lt;/h2&gt;

&lt;p&gt;Up until now, our onboarding process asked you to try the API by uploading
your data. We emphasized our &lt;a href=&quot;http://www.algolia.com/doc&quot;&gt;documentation&lt;/a&gt;, and
we made sure our users would not need more than a few minutes to integrate our
&lt;a href=&quot;http://www.algolia.com/doc/rest&quot;&gt;REST API&lt;/a&gt;. Nevertheless, exporting your
application’s data to a JSON or CSV file is often more complex than it
appears, especially when you have millions of rows - and especially because
developers are lazy :) No worries, that’s &lt;a href=&quot;http://www.codinghorror.com/blog/2005/08/how-to-be-lazy-dumb-and-successful.html&quot;&gt;totally
OK&lt;/a&gt;. It is something you may not be willing to do, especially
just to try a service, so we decided to try something else.&lt;/p&gt;

&lt;h3 id=&quot;initial-import&quot;&gt;Initial import&lt;/h3&gt;

&lt;p&gt;90% of our users are using a SQL or MongoDB database. Exporting a table or a
collection to a JSON file can be easy if you’re using a framework, for example
Ruby on Rails:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ruby
File.open(&quot;/tmp/export.json&quot;, &quot;w&quot;) do |f|
  f &amp;lt;&amp;lt; MyActiveRecordModel.all.to_json
end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;…or more annoying, for example when using PHP without any framework:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;php
mysql_connect(&#39;localhost&#39;, &#39;mysql_user&#39;, &#39;mysql_password&#39;);
mysql_set_charset(&#39;utf8&#39;);
$results = array();
$q = mysql_query(&quot;SELECT * FROM YourTable&quot;);
if ($q) {
  while (($row = mysql_fetch_assoc($q))) {
    array_push($results, $row);
  }
}
$fp = fopen(&#39;/tmp/export.json&#39;, &#39;w&#39;);
fwrite($fp, json_encode($results));
fclose($fp);
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Anyway, in both cases it gets harder if you want to export millions of rows
without consuming hundreds GB of RAM. So you will need to use our API clients:&lt;/p&gt;

&lt;p&gt;```ruby
index = Algolia::Index.new “YourIndex”
MyActiveRecordModel.find_in_batches(1000) do |objects|
  index.add_objects(objects)
end
# that’s actually what &lt;code&gt;MyActiveRecordModel.reindex!&lt;/code&gt; does&lt;/p&gt;

&lt;p&gt;mysql_connect(‘localhost’, ‘mysql_user’, ‘mysql_password’);
mysql_set_charset(‘utf8’);
$limit = 1000;
$start = 0;
$index = $client-&amp;gt;initIndex(‘YourIndexName’);
while (true) {
  $q = mysql_query(“SELECT * FROM YourTable LIMIT “ . $start . “,” . $limit);
  $n = 0;
  if ($q) {
    $objects = array();
    while(($row = mysql_fetch_assoc($q))) {
      array_push($objects, $row);
      ++$n;
    }
    $index-&amp;gt;addObjects($objects);
  }
  if ($n != $limit) {
    break;
  }
  $start += $n;
}
```&lt;/p&gt;

&lt;h3 id=&quot;incremental-updates&quot;&gt;Incremental updates&lt;/h3&gt;

&lt;p&gt;Once imported, you will need to go further and keep your DB and our indexes
up-to-date. You can either:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Clear your index and re-import all your records hourly/daily with the previous methods:
    &lt;ul&gt;
      &lt;li&gt;non-intrusive,&lt;/li&gt;
      &lt;li&gt;not real-time,&lt;/li&gt;
      &lt;li&gt;not durable,&lt;/li&gt;
      &lt;li&gt;need to import your data to a temporary index + replace the original one atomically once imported if you want to keep your service running while re-importing&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Or&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Patch your application/website code to replicate every add/delete/update operations to our API:
    &lt;ul&gt;
      &lt;li&gt;real-time,&lt;/li&gt;
      &lt;li&gt;consistent &amp;amp; durable,&lt;/li&gt;
      &lt;li&gt;a little intrusive to some people, even though it is only a few lines of code (&lt;a href=&quot;http://www.algolia.com/doc)&quot;&gt;see our documentation&lt;/a&gt;&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;after-introducing-connectors&quot;&gt;After: Introducing connectors&lt;/h2&gt;

&lt;p&gt;Even if we did recommend you to modify your application code to replicate all
add/delete/update operations from your DB to our API, this should not be the
only option, especially to test Algolia. Users want to be convinced before
modifying anything in their production-ready application/website. This is why
we are really proud to release 2 open-source connectors: a non-intrusive and
efficient way to synchronize your current SQL or MongoDB database with our
servers.&lt;/p&gt;

&lt;h3 id=&quot;sql-connector&quot;&gt;SQL connector&lt;/h3&gt;

&lt;p&gt;Github project: &lt;a href=&quot;https://github.com/algolia/jdbc-java-connector&quot;&gt;algolia/jdbc-java-connector&lt;/a&gt; (MIT license, we love pull-requests :))&lt;/p&gt;

&lt;p&gt;The connector starts by enumerating the table and push all matching rows to
our server. If you store the last modification date of a row in a field, you
can use it in order to send all detected updates every 10 seconds. Every 5
minutes, the connector synchronizes your database with the index by adding the
new rows and removing the deleted ones.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;java
jdbc-connector.sh --source &quot;jdbc:mysql://localhost/YourDB&quot;  
  --username mysqlUser --password mysqlPassword             
  --selectQuery &quot;SELECT * FROM YourTable&quot; --primaryField id 
  --updateQuery &quot;SELECT * FROM YourTable WHERE updated_at &amp;gt; _$&quot;
  --updatedAtField updated_at 
  --applicationId YourApplicationId --apiKey YourApiKey --index YourIndexName
 &lt;/code&gt;&lt;/p&gt;

&lt;p&gt;If you don’t have an updated_at  field, you can use:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;java
jdbc-connector.sh --source &quot;jdbc:mysql://localhost/YourDB&quot;  
  --username mysqlUser --password mysqlPassword             
  --selectQuery &quot;SELECT * FROM YourTable&quot; --primaryField id 
  --applicationId YourApplicationId --apiKey YourApiKey --index YourIndexName
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The full list of features is available on &lt;a href=&quot;https://github.com/algolia/jdbc-java-connector&quot;&gt;Github&lt;/a&gt; (remember, we ♥ feature and pull-requests)!&lt;/p&gt;

&lt;h3 id=&quot;mongodb-connector&quot;&gt;MongoDB connector&lt;/h3&gt;

&lt;p&gt;Github
project: &lt;a href=&quot;https://github.com/algolia/mongo-connector&quot;&gt;algolia/mongo-connector&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;This connector has been forked from &lt;a href=&quot;https://github.com/10gen-labs/mongo-connector&quot;&gt;10gen-lab’s official
connector&lt;/a&gt; and is based on
MongoDB’s &lt;a href=&quot;http://docs.mongodb.org/manual/core/replica-set-oplog/&quot;&gt;operation logs&lt;/a&gt;. This means you will need to start your mongod  server specifying a
&lt;a href=&quot;http://docs.mongodb.org/manual/tutorial/deploy-replica-set/&quot;&gt;replica set&lt;/a&gt;.
Basically, you need to start your server with: mongod –replSet
REPLICA_SET_IDENTIFIER. Once started, the connector will replicate each
addition/deletion/update to our server, sending a batch of operations every 10
seconds.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;mongo-connector -m localhost:27017 -n myDb.myCollection 
  -d ./doc_managers/algolia_doc_manager.py              
  -t YourApplicationID:YourApiKey:YourIndex
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The full features list is available on &lt;a href=&quot;https://github.com/algolia/mongo-connector&quot;&gt;Github&lt;/a&gt; (we ♥ feature and pull-requests).&lt;/p&gt;

&lt;h2 id=&quot;conclusion-easier-onboarding-larger-audience&quot;&gt;Conclusion: Easier Onboarding, Larger Audience!&lt;/h2&gt;

&lt;p&gt;Helping our users to onboard and try Algolia without writing a single line of
code is not only a way to attract more non-technical users; It is also a way
to save the time of our technical but overbooked users, allowing them to be
convinced without wasting their time before really implementing it.&lt;/p&gt;

&lt;p&gt;Those connectors are open-source and we will continue to improve them based on
your feedback. Your feature requests are welcome!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Postmortem of today's 8min indexing downtime</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/01/29/postmortem-todays-8min-indexing-downtime/"/>
   <updated>2014-01-29T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/01/29/postmortem-todays-8min-indexing-downtime</id>
   <content type="html">&lt;p&gt;Today (Jan 29) at 9:30pm UTC, our service experienced an 8 minute partial
outage during which we have rejected many write operations sent to the
indexing API (exactly 2841 calls). We call it “partial” as all search queries
have been honored without any problem. For end-users, there was no visible
problem.&lt;/p&gt;

&lt;p&gt;Transparency is in our DNA: this outage is visible on our status page
(&lt;a href=&quot;http://status.algolia.com&quot;&gt;status.algolia.com&lt;/a&gt;) but we also wanted to share
with you all the details of the outage and more importantly the details of our
response.&lt;/p&gt;

&lt;h2 id=&quot;the-alert&quot;&gt;The alert&lt;/h2&gt;

&lt;p&gt;This morning I fixed a rare bug in indexing complex hierarchical objects. This
fix successfully passed all the tests after development. We have 6000+ unit
tests and asserts, and 200+ non regression tests. So I felt confident when I
entered the deploy password in our automatic deployment script.&lt;/p&gt;

&lt;p&gt;A few seconds after, I started to receive a lot of text messages on my
cellphone.&lt;/p&gt;

&lt;p&gt;We developed several embedded probes to detect all kinds of problems and alert
us using Twilio and Hipchat APIs. They detect for example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;a process that restart&lt;/li&gt;
  &lt;li&gt;an unusually long query&lt;/li&gt;
  &lt;li&gt;a write failure&lt;/li&gt;
  &lt;li&gt;a low memory warning&lt;/li&gt;
  &lt;li&gt;a low disk-free warning&lt;/li&gt;
  &lt;li&gt;etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In case embedded probes can’t run, other external probes run once a minute
from an independent datacenter (Google App Engine). These also automatically
update our status page when a problem impacts the quality of service.&lt;/p&gt;

&lt;p&gt;Our indexing processes were crash looping. I immediately decided to rollback
to the previous version.&lt;/p&gt;

&lt;h2 id=&quot;the-rollback&quot;&gt;The rollback&lt;/h2&gt;

&lt;p&gt;Until today, our standard rollback process was to revert the commit, launch
the recompile and finally deploy. This is long, very long when your know that
you have an outage in production. The rollback took about 5 minutes in total
out of the 8 minutes.&lt;/p&gt;

&lt;h2 id=&quot;how-we-will-avoid-this-situation-in-the-future&quot;&gt;How we will avoid this situation in the future&lt;/h2&gt;

&lt;p&gt;Even if the outage was on a relatively small period of time, we still believe
it was too long. To make sure this will not happen again:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We have added a very fast rollback process in the way of a simple press button like the one we use to deploy. An automatic deploy is nice, but an automatic rollback is actually more critical when needed!&lt;/li&gt;
  &lt;li&gt;Starting now, we will deploy new versions of the service on clusters hosting community projects such as Hacker News Search or Twitter handle search, before pushing the update on clusters hosting paying customers. Having real traffic is key to detect some types of errors. Unit-tests &amp;amp; non-regression tests cannot catch everything.&lt;/li&gt;
  &lt;li&gt;And of course we added non-regression tests for this specific error.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Having all these probes in our infrastructure was key to detect today’s
problem and react quickly. In real conditions, it proved not to be enough. In
a few hours we have implemented a much better way to handle this kind of
situation. The quality of our service is our top priority. Thank you for your
support!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Hacker News search: 6.5 million articles and comments at your fingertips</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/01/24/hacker-news-search-algolia/"/>
   <updated>2014-01-24T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/01/24/hacker-news-search-algolia</id>
   <content type="html">&lt;p&gt;We are &lt;a href=&quot;https://news.ycombinator.com&quot;&gt;Hacker News&lt;/a&gt; readers and probably just
like you, there is not a day that goes by we don’t use it. It is a little like
checking the weather app of the tech world. Long story short, Hacker News is
awesome, and we wanted to add our two cents to make it even greater to use.&lt;/p&gt;

&lt;p&gt;Indeed, here is our problem: how do we instantly access the old posts we wish
we had saved?&lt;/p&gt;

&lt;h2 id=&quot;powering-a-newhacker-news-search-engine&quot;&gt;Powering a new Hacker News search engine&lt;/h2&gt;

&lt;p&gt;Up until now we’ve been using &lt;a href=&quot;http://www.hnsearch.com&quot;&gt;hnsearch.com&lt;/a&gt;,
maintained for years by the great folks at &lt;a href=&quot;http://octopart.com/&quot;&gt;Octopart&lt;/a&gt;. I
hope we speak on behalf of the HN community here, we are all grateful for the
work they put in hnsearch.com and they inspired us to pursue their effort.&lt;/p&gt;

&lt;p&gt;Back in September 2013, we created a “&lt;a href=&quot;https://news.ycombinator.com/item?id=6476003&quot;&gt;homemade Hacker News
crawler&lt;/a&gt;” and built a search
engine with the data we could get. It was not perfect but somehow, it did the
job fine.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.ycombinator.com/algolia-
yc-w14-launches-a-search-api-that-lets-you-provide-apple-spotlight-like-
realtime-search-for-your-app-or-service&quot;&gt;Now part of the Ycombinator W14 batch&lt;/a&gt;, we have a direct access to the data
and it has allowed us to provide instant search for the entire content of
Hacker News, 1.2 million articles, 5.2 million comments as of today. See for
yourself right here: &lt;a href=&quot;http://hn.algolia.com/&quot;&gt;hn.algolia.com&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;here-is-how-we-did-it&quot;&gt;Here is how we did it&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;hacker-news-api-access&quot;&gt;Hacker News API access&lt;/h3&gt;

    &lt;ul&gt;
      &lt;li&gt;YC provides us a private API access to fetch batches of 1000 items (an item being a comment or a post). Every two minutes, we update our database with the latest 1000 items. Last 48,000 items are refreshed every hour to keep the number of votes and comments up to date.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;code&gt;
# Yep, that&#39;s a Lisp API :)
EXPORT_REGEXP = %r{^((d+) (story|comment|poll|pollopt) &quot;(.+)&quot; (d+) (?:nil|&quot;(.*)&quot;) (?:nil|&quot;(.+)&quot;) (?:nil|&quot;(.*)&quot;) (?:nil|-?(d+)) (?:nil|(([d ]+))) (?:nil|(d+)))$}
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;thumbnails-generation&quot;&gt;Thumbnails generation&lt;/h3&gt;

    &lt;ul&gt;
      &lt;li&gt;We use &lt;a href=&quot;https://code.google.com/p/wkhtmltopdf/&quot;&gt;wkhtmltoimage&lt;/a&gt; to render the URLs and generate the associated thumbnails. Playing with connection timeouts and JavaScript infinite loops was a pleasure:&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;code&gt;
(timeout 60 xvfb-run --auto-servernum --server-args=&quot;-screen 0, 1024x768x24&quot; 
wkhtmltoimage-amd64 --height 768 --use-xserver--javascript-delay 30000 &quot;$URL&quot; &quot;$FILE&quot; || 
timeout 60 xvfb-run --auto-servernum --server-args=&quot;-screen 0, 1024x768x24&quot; 
wkhtmltoimage-amd64 --height 768 --use-xserver --disable-javascript &quot;$URL&quot; &quot;$FILE&quot;) &amp;amp;&amp;amp; 
convert &quot;$FILE&quot; -resize &#39;100!x100&#39; &quot;$FILE&quot;
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;thumbnails-storage&quot;&gt;Thumbnails storage&lt;/h3&gt;

    &lt;ul&gt;
      &lt;li&gt;Thumbnails are resized and stored on a S3 bucket.&lt;/li&gt;
    &lt;/ul&gt;

    &lt;p&gt;&lt;code&gt;
AWS::S3::S3Object.store(&quot;#{id}.png&quot;, open(temp_file), &#39;hnsearch&#39;, access: :public_read)
&lt;/code&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;thumbnails-distribution&quot;&gt;Thumbnails distribution&lt;/h3&gt;

    &lt;ul&gt;
      &lt;li&gt;We configured a CloudFront instance targeting the S3 bucket to distribute thumbnails with low latency and high data transfer speed. We followed Amazon’s associated &lt;a href=&quot;http://docs.aws.amazon.com/AmazonCloudFront/latest/DeveloperGuide/MigrateS3ToCloudFront.html&quot;&gt;developer guide&lt;/a&gt;.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;indexing&quot;&gt;Indexing&lt;/h3&gt;

    &lt;ul&gt;
      &lt;li&gt;We used the “&lt;a href=&quot;https://github.com/algolia/algoliasearch-rails&quot;&gt;algoliasearch-rails&lt;/a&gt;” gem and a standard (Ruby on Rails) MySQL-backed ActiveRecord setup. Indexing is performed automatically as soon as new items are added to the database, providing a near-realtime experience.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;configuration&quot;&gt;Configuration&lt;/h3&gt;

    &lt;p&gt;```ruby
class Item &amp;lt; ActiveRecord::Base
  include AlgoliaSearch&lt;/p&gt;

    &lt;p&gt;algoliasearch per_environment: true do
    # the list of attributes sent to Algolia’s API
    attribute :created_at, :title, :url, :author, :points, :story_text, :comment_text, :author, :num_comments, :story_id, :story_title, :story_url
    attribute :created_at_i do
      created_at.to_i
    end&lt;/p&gt;

    &lt;pre&gt;&lt;code&gt;# The order of the attributes sets their respective importance.
# `title` is more important than `{story,comment}_text`, `{story,comment}_text` more than `url`, `url` more than `author`
# btw, do not take into account position to avoid first word match boost
attributesToIndex [&#39;unordered(title)&#39;, &#39;unordered(story_text)&#39;, &#39;unordered(comment_text)&#39;, &#39;unordered(url)&#39;, &#39;author&#39;, &#39;created_at_i&#39;]

# add tags used for filtering
tags do
  [item_type, &quot;author_#{author}&quot;, &quot;story_#{story_id}&quot;]
end

# Custom ranking allows to automatically sort the results by a custom criteria
# in this case, a decreasing sort of the number of HN points and comments.
customRanking [&#39;desc(points)&#39;, &#39;desc(num_comments)&#39;]

# controls the way results are sorted sorting on the following 4 criteria (one after another)
# I removed the &#39;exact&#39; match critera (improve 1-words query relevance, doesn&#39;t fit HNSearch needs)
ranking [&#39;typo&#39;, &#39;proximity&#39;, &#39;attribute&#39;, &#39;custom&#39;]

# google+, $1.5M raises, C#: we love you
separatorsToIndex &#39;+#$&#39;   end
&lt;/code&gt;&lt;/pre&gt;

    &lt;p&gt;def story_text
    item_type_cd != Item.comment ? text : nil
  end&lt;/p&gt;

    &lt;p&gt;def story_title
    comment? &amp;amp;&amp;amp; story ? story.title : nil
  end&lt;/p&gt;

    &lt;p&gt;def story_url
    comment? &amp;amp;&amp;amp; story ? story.url : nil
  end&lt;/p&gt;

    &lt;p&gt;def comment_text
    comment? ? text : nil
  end&lt;/p&gt;

    &lt;p&gt;def comment?
    item_type_cd == Item.comment
  end&lt;/p&gt;

    &lt;p&gt;def num_comments
    item_type_cd == Item.story ? story_comments.count : nil
  end
end
```&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;h3 id=&quot;search&quot;&gt;Search&lt;/h3&gt;

    &lt;ul&gt;
      &lt;li&gt;Queries are sent directly to our API via the&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt; javascript client&lt;/a&gt;, the javascript code uses a public API-Key that can only perform queries.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;seeking-feedback-from-the-community&quot;&gt;Seeking feedback from the community&lt;/h2&gt;

&lt;p&gt;There is still room for improvement and we would love to know how you are
searching for news on HN. What is important for you? Are you searching by
date, by upvote, by comment or by user? All together maybe?&lt;/p&gt;

&lt;p&gt;We would love to have your feedback! Don’t hesitate to checkout the code: &lt;a href=&quot;https://github.com/algolia/hn-search&quot;&gt;We
open-sourced it&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Special thanks to the &lt;a href=&quot;http://octopart.com/&quot;&gt;Octopart&lt;/a&gt; and
&lt;a href=&quot;http://ycombinator.com/&quot;&gt;YC&lt;/a&gt; teams for making this experience possible!&lt;/p&gt;

&lt;p&gt;Give it a try now: &lt;a href=&quot;http://hn.algolia.com&quot;&gt;hn.algolia.com&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Search Grader by Algolia: How does your search engine perform?</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/01/18/search-grader-engine-performing/"/>
   <updated>2014-01-18T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/01/18/search-grader-engine-performing</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://grader.algolia.com&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-01-24-01.26.08-600x150.png&quot; alt=&quot;algolia-search-grader&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;search-is-important&quot;&gt;Search is important&lt;/h2&gt;

&lt;p&gt;An effective search engine should be a seamless and natural extension of the
user experience. With improved relevance, your users should be able to find
what they are looking for in no time.&lt;/p&gt;

&lt;p&gt;Unfortunately, developers often consider search as a second-tier priority.
This is a mistake. Every day, consumers use Google, Amazon, and Youtube to
find what they want on the web quickly and easily. Users of web applications
and eCommerce websites will feel the gap in search experience. As their
expectations are not met, your conversion rate will plummet, your bounce rate
will skyrocket, and the damage to your brand may be irredeemable.&lt;/p&gt;

&lt;h2 id=&quot;search-is-tricky&quot;&gt;Search is tricky&lt;/h2&gt;

&lt;p&gt;The reason why many web applications and e-commerce websites suffer from bad
search is because finding a good solution is not easy. Few current search
technologies combine relevancy and business metrics in a way that sorts search
results optimally.&lt;/p&gt;

&lt;p&gt;In most cases, they fail on the following items:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;long response times,&lt;/li&gt;
  &lt;li&gt;no handling of mistakes,&lt;/li&gt;
  &lt;li&gt;no search field auto-completion,&lt;/li&gt;
  &lt;li&gt;unexplainable or even nonexistent results.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To improve your search experience, you first need to understand which areas
are problematic. That’s exactly why we built Search Grader by Algolia.&lt;/p&gt;

&lt;h2 id=&quot;introducing-search-grader-by-algolia&quot;&gt;Introducing Search Grader by Algolia&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;http://grader.algolia.com/&quot;&gt;Search Grader&lt;/a&gt; by Algolia is a tool to help you
quickly find out what your search engine may be missing. We divided the search
user experience in 3 categories in order to get a maximum score of 100:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;User Experience: 30 points&lt;/li&gt;
  &lt;li&gt;Speed: 20 points&lt;/li&gt;
  &lt;li&gt;Relevance: 50 points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;User Experience: 30/100&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;User experience is not just design, it’s the key of a good user satisfaction.
If your users cannot find what they’re searching for, they will just leave.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Searchbox visibility (3 pts)&lt;/strong&gt;: It is easier for your users to find something if your search bar is clearly visible!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Descriptive placeholder (2 pts) &lt;/strong&gt;: A hint in your search bar is a good way to let your users know what kind of data they can dig into.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Searchbox auto-completion (6 pts)&lt;/strong&gt;: Auto-completion guides your users more efficiently towards what they are looking for.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Suggestions after the first keystroke (5 pts)&lt;/strong&gt;: Delight your users by providing relevant suggestions immediately after the first keystroke.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Faceting (4 pts)&lt;/strong&gt;: Faceting enables users to browse results by filtering them on specific categories (e.g., author, tags, price).&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Highlight (6 pts)&lt;/strong&gt;: You need to explain why the displayed results are chosen, especially when you tolerate typos or misspelled queries.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pagination (2 pts)&lt;/strong&gt;: Providing relevant results on the first page is great. But to keep your users engaged, you need to give them an easy way to access other results.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Picture (2 pts):&lt;/strong&gt; Sometime images are the fastest way to display information. Users will go through results and find the right hits much faster if you show them images.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Speed: 20/100&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;If results show up in more than 200ms, you will lose part of your users. Time
is money, real-time is gold. Because your location is important to the speed
of the search we graded speed 3 times based on the location of the user:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Response time from US East coast&lt;/li&gt;
  &lt;li&gt;Response time from US West coast&lt;/li&gt;
  &lt;li&gt;Response time from Europe&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Relevance: 50/100&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Relevance is when you give your users what they want in the top results.
Although it’s not very fancy, it’s probably the more critical aspect of a good
search engine.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Typo-tolerance (10 pts)&lt;/strong&gt;: People make a lot of typos, especially on mobile devices. Tolerating misspelled queries provides a great value to both your users and the products you promote.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Auto-completion shows results, not queries (10 pts)&lt;/strong&gt;: Suggesting queries is good. Suggesting results directly is a lot better as you spare your users one click and a lot of time.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ranking uses business metrics (10 pts)&lt;/strong&gt;: Considering customized criteria such as sales numbers or the popularities in the way you rank results makes a key difference. It is THE way to give relevant results with one single keystroke.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Overall ranking (20 pts)&lt;/strong&gt;: Search must always return relevant results. We perform multiple queries to detect if your search is performing well.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;get-google-amazon-like-search-for-your-website&quot;&gt;Get Google, Amazon-like search for your website&lt;/h2&gt;

&lt;p&gt;These criteria were defined by our team of experts with over 30+ years of
experience in search.&lt;/p&gt;

&lt;p&gt;We tested out some of the biggest names in tech:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://grader.algolia.com&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Capture-decran-2014-01-17-18.22.23.png&quot; alt=&quot;Algolia search grader&quot; /&gt;&lt;/a&gt;&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;As you could expect, Amazon and LinkedIn received an excellent score of
90/100. That’s the kind of quality Algolia can help you achieve in your
application or e-commerce website, for as low as
&lt;a href=&quot;http://www.algolia.com/pricing/&quot;&gt;$19/month&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Now, how about your search? How is it performing? To find out, use &lt;a href=&quot;http://grader.algolia.com/&quot;&gt;Search
Grader&lt;/a&gt; by Algolia.&lt;/p&gt;

&lt;p&gt;If you want to share your ideas with us, please leave your comments!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Improving Search for Twitter Handles</title>
   <link href="https://github.com/svenhutchinson/extensions/2014/01/06/improving-ranking-twitter-handles-search/"/>
   <updated>2014-01-06T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2014/01/06/improving-ranking-twitter-handles-search</id>
   <content type="html">&lt;p&gt;Hello Twitter,&lt;/p&gt;

&lt;p&gt;I have been using your service for awhile, and I love it!&lt;/p&gt;

&lt;p&gt;At first, I was skeptical about what you could offer: Broadcasting to all my
friends that I was eating a pizza, or taking a walk, is not really my cup of
tea. But 3 years ago I figured out what Twitter was really meant for and how
it could help me in a totally different way from what I first thought:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;sharing interesting articles,&lt;/li&gt;
  &lt;li&gt;checking if /replace by the service provider you want/ is down,&lt;/li&gt;
  &lt;li&gt;or catching up on HackerNews.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;More recently, I discovered you had a feature that could help me even more: I
can now ask for support by tweeting. Tweeting is often faster and more
productive than sending an email. You taught me to include the recipient’s
Handle in my tweets, and your current Handle auto-completion implementation
works pretty well: but what if you could provide a &lt;strong&gt;better typo-tolerance and
ranking&lt;/strong&gt;? (I’m NOT speaking about your official OSX/iOS native clients and
its &lt;a href=&quot;http://blog.algolia.com/why-autocomplete-in-twitter-on-mobile-sucks/&quot;&gt;totally unusable auto-completion feature&lt;/a&gt;… btw, could you explain me why it
is different from the one on your website?).&lt;/p&gt;

&lt;p&gt;I have been leading a search-engine development team over the last 5 years and
I’m now VP of engineering at Algolia. I am aware that considering my job, I
have kind of an “expert” point of view about search. But search has become so
essential that I am convinced it &lt;strong&gt;must&lt;/strong&gt; be irreproachable. Did you know
that 1.7M+ people are currently following&lt;/p&gt;

&lt;p&gt;expecting great things from your search-engine, Twitter :) Here is how I would
improve search for Twitter handles:&lt;/p&gt;

&lt;p&gt;For example, it would be nice if I could find President
&lt;a href=&quot;https://twitter.com/barackobama&quot;&gt;@barackobama&lt;/a&gt; with his last name:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.40.09.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.40.09-263x300.png&quot; alt=&quot;Search for Twitter handles including @obama yields less-than-stellar
results.&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Same for Justin:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.42.01.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.42.01-262x300.png&quot; alt=&quot;Search for Twitter handles that could be Justin Bieber&#39;s yields less-than-
stellar results.&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Typo-tolerance is now a must-have, especially because we’re all using
smartphones and tablets:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.38.19.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.38.19-263x300.png&quot; alt=&quot;Search for Twitter handles should have typo tolerance.&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;More and more handles are now prefixed/suffixed by “official”, which makes
finding &lt;a href=&quot;https://twitter.com/officialadele&quot;&gt;@OfficialAdele&lt;/a&gt; just impossible:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2013/12/Screen-Shot-2013-12-23-at-11.47.52.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Screen-Shot-2013-12-23-at-11.47.52.png&quot; alt=&quot;Search for Twitter handles that start with @official is broken.&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For sure we can improve it, let’s code!&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;First of all Twitter, I need your Handles database :)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;I used your &lt;a href=&quot;https://dev.twitter.com/docs/streaming-apis&quot;&gt;Streaming API&lt;/a&gt; to crawl about 20M+ accounts in ~2 weeks: it’s not blazing fast but I must admit it does the job (and it’s free). That’s about 5 lines of Ruby with &lt;a href=&quot;https://github.com/tweetstream/tweetstream&quot;&gt;TweetStream&lt;/a&gt;, good job guys!&lt;/li&gt;
  &lt;li&gt;and &lt;a href=&quot;https://github.com/bmc/daemonize&quot;&gt;Daemonize&lt;/a&gt; to create a bin/crawler executable.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;```ruby
#! /usr/bin/env ruby&lt;/p&gt;

&lt;p&gt;require File.expand_path(File.join(File.dirname(&lt;strong&gt;FILE&lt;/strong&gt;), ‘..’, ‘config’, ‘environment’))&lt;/p&gt;

&lt;p&gt;daemon = TweetStream::Daemon.new(‘crawler’, :log_output =&amp;gt; true)
daemon.on_inited do
  ActiveRecord::Base.connection.reconnect!
  ActiveRecord::Base.logger = Logger.new(File.join(Rails.root, ‘log/stream.log’), ‘w+’)
end
daemon.on_error do |message|
  puts “Error: #{message}”
end
daemon.sample do |status|
  Handle.create_from_status(status)
end
```&lt;/p&gt;

&lt;p&gt;For each new tweet you send to me, I store the author (name + screen_name +
description + followers_count) and all his/her user mentions.&lt;/p&gt;

&lt;p&gt;```ruby
class Handle &amp;lt; ActiveRecord::Base&lt;/p&gt;

&lt;p&gt;def self.create_from_user(user)
    h = Handle.find_or_initialize_by(screen_name: user.screen_name)
    puts h.screen_name if h.new_record?
    h.name = user.name
    h.description = (user.description || “”)[0..255]
    h.followers_count = user.followers_count
    h.updated_at ||= DateTime.now
    h.save
    h
  end&lt;/p&gt;

&lt;p&gt;def self.create_from_status(status)
    Handle.create_from_user(status.user)
    status.user_mentions.each do |mention|
      m = Handle.find_or_initialize_by(screen_name: mention.screen_name)
      m.updated_at ||= DateTime.now
      m.name = mention.name
      m.mentions_count ||= 0
      m.mentions_count += 1
      m.save
    end
  end&lt;/p&gt;

&lt;p&gt;end
```&lt;/p&gt;

&lt;p&gt;And every minute, I re-index the last-updated accounts with a batch request
using &lt;a href=&quot;https://github.com/algolia/algoliasearch-rails&quot;&gt;algoliasearch-rails&lt;/a&gt;,&lt;/p&gt;

&lt;p&gt;&lt;code&gt;ruby
every 1.minute, roles: [:cron] do
  runner &quot;Handle.where(&#39;updated_at &amp;gt;= ?&#39;, 1.minute.ago).reindex!&quot;
end
&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;The result order is based on several criteria:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the number of typos,&lt;/li&gt;
  &lt;li&gt;the matching attributes: the name/handle is more important than the description,&lt;/li&gt;
  &lt;li&gt;the proximity between matched words,&lt;/li&gt;
  &lt;li&gt;and the followers count (I also use the “mentions count” if my crawler didn’t get the followers count yet).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I could have improved the results by using the user’s list of
followers/following but I was limited by your &lt;a href=&quot;https://dev.twitter.com/docs/rate-limiting/1.1&quot;&gt;Rate
Limits&lt;/a&gt;. &lt;strong&gt;Instead, I chose to
emphasize your top-users &lt;/strong&gt;(accounts having 10M+ followers).&lt;/p&gt;

&lt;p&gt;Here is the configuration I used&lt;/p&gt;

&lt;p&gt;```ruby
class Handle &amp;lt; ActiveRecord::Base&lt;/p&gt;

&lt;p&gt;include AlgoliaSearch
  algoliasearch per_environment: true, auto_index: false, auto_remove: false do
    # add an extra score attribute
    add_attribute :score&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# add an extra full_name attribute: screen_name + name
add_attribute :full_name

# do not take `full_name`&#39;s words order into account, `full_name` is more important than `description`
attributesToIndex [&#39;unordered(full_name)&#39;, :description]

# list of attributes to highlight
attributesToHighlight [:screen_name, :name, :description]

# use followers_count OR mentions_count to sort results (last sort criteria)
customRanking [&#39;desc(score)&#39;]

# @I_love_you
separatorsToIndex &#39;_&#39;

# tag top-users
tags do
  followers_count &amp;gt; 10000000 ? [&#39;top&#39;] : []
end   end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;def full_name
    # consider screen_name and name equal
    # the name should not match exact so we concatenate it with the screen_name
    [screen_name, “#{screen_name} #{name}”]
  end&lt;/p&gt;

&lt;p&gt;# the custom score
  def score
    return followers_count if followers_count &amp;gt; 0
    if mentions_count &amp;lt; 10
      mentions_count
    elsif mentions_count &amp;lt; 100
      mentions_count * 10
    elsif mentions_count &amp;lt; 1000
      mentions_count * 100
    else
      mentions_count * 1000
    end
  end&lt;/p&gt;

&lt;p&gt;end
```&lt;/p&gt;

&lt;p&gt;The user query is composed by 2 backend queries:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;the first one retrieves all matching top-users (could be replaced by a query targeting your followers/following only)&lt;/li&gt;
  &lt;li&gt;the second one the others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;http://twittersearch.algolia.io/&quot;&gt;&lt;strong&gt;Try it for yourself&lt;/strong&gt;&lt;/a&gt;, and enjoy
relevant and highlighted results after the first keystroke: &lt;a href=&quot;http://twittersearch.algolia.io/&quot;&gt;Twitter Handles
Search&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Our Search-as-a-Service offer has now 10 API Clients!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/07/18/our-search-as-a-service-offer-has-now-10-api-clients/"/>
   <updated>2013-07-18T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/07/18/our-search-as-a-service-offer-has-now-10-api-clients</id>
   <content type="html">&lt;p&gt;We recently reached a new milestone towards the release of our Search as a
Service offer. We’re now proud to offer 10 API clients, covering all major
languages.&lt;/p&gt;

&lt;p&gt;Ease of use was a major focus during development. We began by offering a
complete and easy-to-integrate &lt;a href=&quot;http://docs.algoliav1.apiary.io/&quot;&gt;REST API&lt;/a&gt;.
Providing API clients was a logical way to improve ease of use. You can now
quick start and test the engine with your data in a couple of minutes, with no
prior configuration whatsoever. Each API Client is released under the MIT
License and comes with a quick start and complete documentation:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt;Javascript client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-ruby&quot;&gt;Ruby client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-python&quot;&gt;Python client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-php&quot;&gt;PHP client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-objc&quot;&gt;iOS and OS X client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-android&quot;&gt;Android client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-java&quot;&gt;Java client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-csharp&quot;&gt;C# client for Windows, Windows Phone and Silverlight&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-node&quot;&gt;Node.js client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-cmd&quot;&gt;Command line client for linux/mac&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This variety of languages and platforms reveals the diversity of our beta
testers:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Customer size: from a small startup developing their MVP, to a big social network searching in their 130M+ users.&lt;/li&gt;
  &lt;li&gt;Volume: from a few queries to tens of millions per day. &lt;/li&gt;
  &lt;li&gt;Technical environments: mobile, desktop, and web apps.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Interested in trying it out yourself? Ask for an
&lt;a href=&quot;http://www.algolia.com/pricing/&quot;&gt;invite&lt;/a&gt;!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Asian Language support in our Offline Search SDK 2.2</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/07/08/excellent-asian-languages-support-in-our-offline-search-sdk-2-2/"/>
   <updated>2013-07-08T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/07/08/excellent-asian-languages-support-in-our-offline-search-sdk-2-2</id>
   <content type="html">&lt;p&gt;Like most search engines, version 2.1 did not include any specific processing
for Asian Languages. Version 2.2 significantly improves Asian language support
(Chinese, Japanese, Korean) by including specific processing like the
automatic conversion between Simplified Chinese and Traditional Chinese using
the &lt;a href=&quot;http://www.unicode.org/charts/unihan.html&quot;&gt;Unicode UniHan Database&lt;/a&gt;. This
advanced processing was only possible because we built our own &lt;a href=&quot;http://blog.algolia.com/why-develop-our-own-unicode-library/&quot;&gt;Unicode
library&lt;/a&gt;. Many
thanks to &lt;a href=&quot;https://twitter.com/stephencremin&quot;&gt;Stephen&lt;/a&gt; for his help!&lt;/p&gt;

&lt;p&gt;This release also contains other improvements we released first for our SaaS
version:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The out-of-the-box ranking was greatly improved when queries contained more than two words,&lt;/li&gt;
  &lt;li&gt;Indexing speed was greatly improved on mobile (2 times more efficient),&lt;/li&gt;
  &lt;li&gt;Search speed was improved by about 20%.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We hope you’ll like these new features, and as ever, we welcome your feedback!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>New iOS and OS X API clients for our Search-as-a-Service offer</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/06/24/check-out-the-new-iosos-x-clients-for-our-search-as-a-service-offer/"/>
   <updated>2013-06-24T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/06/24/check-out-the-new-iosos-x-clients-for-our-search-as-a-service-offer</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2013/06/objC.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/objC.png&quot; alt=&quot;Build new things with our iOS and OS X API
client.&quot; /&gt;&lt;/a&gt;One week after releasing our &lt;a href=&quot;http://blog.algolia.com/discover-our-new-java-android-search-as-a-service-api-clients-at-droidcon-paris/&quot;&gt;Java &amp;amp; Android
clients&lt;/a&gt;, we are happy to release our &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-objc&quot;&gt;iOS and
OS X API&lt;/a&gt; clients for
our search-as-a-service offer.&lt;/p&gt;

&lt;p&gt;In order to ease the setup, we support Cocoapods. Installation of the client
just requires one line in your Podfile:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pod &#39;AlgoliaSearch-Client&#39;, &#39;~&amp;gt; 1.0&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;And don’t forget we also provide developers with an &lt;a href=&quot;http://www.algolia.com/doc/ios/&quot;&gt;offline
SDK&lt;/a&gt; that they can use to search directly on
iOS devices with no connection to the network. Developers now  have the
perfect tools to build a great search experience both online and offline.&lt;/p&gt;

&lt;p&gt;With this new client, we now have API Clients for the most popular languages
and platforms. They are all released under the MIT license and available on
our Github account:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-objc&quot;&gt;iOS and OS X client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-java&quot;&gt;Java client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-android&quot;&gt;Android client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-ruby&quot;&gt;Ruby client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-python&quot;&gt;Python client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-php&quot;&gt;PHP client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt;Javascript client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-node&quot;&gt;Node.js client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-cmd&quot;&gt;Command line client for linux/mac&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ease of integration just improved again! Your feedback (and pull requests) is
most welcome.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>New Java & Android Search-as-a-Service API Clients at DroidCon Paris!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/06/17/discover-our-new-java-android-search-as-a-service-api-clients-at-droidcon-paris/"/>
   <updated>2013-06-17T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/06/17/discover-our-new-java-android-search-as-a-service-api-clients-at-droidcon-paris</id>
   <content type="html">&lt;p&gt;Our Search-as-a-Service offer is progressing toward its official release. We
launched our &lt;a href=&quot;https://github.com/algolia/algoliasearch-client-java&quot;&gt;Java&lt;/a&gt; and
&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-android&quot;&gt;Android &lt;/a&gt;search API
Clients at &lt;a href=&quot;http://fr.droidcon.com/2013/&quot;&gt;DroidCon Paris&lt;/a&gt; today! Come to see
us if you’re attending!&lt;/p&gt;

&lt;p&gt;And don’t forget we also provide developers with an &lt;a href=&quot;http://www.algolia.com/doc/android/&quot;&gt;offline
SDK&lt;/a&gt; they can use to search directly on
Android devices with no connection to the network. Developers now have the
perfect tools to build a great search experience both online and offline.&lt;/p&gt;

&lt;p&gt;The Android API Client is based on the Java client and adds support of
asynchronous API calls. You can thus easily trigger a search query from the UI
thread and get the result in a listener without any additional line of code.
You have just to implement the IndexListener interface.&lt;/p&gt;

&lt;p&gt;With these two new clients, we now have eight API Clients released under the
MIT license to simplify integration of Algolia Search as a Service:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-java&quot;&gt;Java Client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-android&quot;&gt;Android Client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-ruby&quot;&gt;Ruby client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-python&quot;&gt;Python client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-php&quot;&gt;PHP client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt;Javascript client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-node&quot;&gt;Node.js client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-cmd&quot;&gt;Command line client for linux/mac&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ease of integration just improved again! Your feedback (and pull requests) is
most welcome.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Discover our 6 new Search-as-a-Service API Clients!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/05/28/discover-our-6-new-search-as-a-service-api-clients/"/>
   <updated>2013-05-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/05/28/discover-our-6-new-search-as-a-service-api-clients</id>
   <content type="html">&lt;p&gt;We &lt;a href=&quot;http://blog.algolia.com/our-saas-version-is-in-beta/&quot;&gt;launched the private beta&lt;/a&gt; of our Search-as-a-Service offer two months ago. In that time we
received very positive feedback from our beta testers and we couldn’t thank
them enough for the help they provided. To date, they have sent over 1M
indexation jobs and over 5M queries, and the trend is increasing.&lt;/p&gt;

&lt;p&gt;Today we are happy to continue simplifying the experience with the release of
six API Clients under the MIT license:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-cmd&quot;&gt;Command line client for linux/mac&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-ruby&quot;&gt;Ruby client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-python&quot;&gt;Python client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-php&quot;&gt;PHP client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-js&quot;&gt;Javascript client&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://github.com/algolia/algoliasearch-client-node&quot;&gt;Node.js client&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ease of integration just improved again! Your feedback (and pull requests) is
most welcome.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search Offline 2.1 is out!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/05/24/algolia-search-offline-2-1-is-out/"/>
   <updated>2013-05-24T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/05/24/algolia-search-offline-2-1-is-out</id>
   <content type="html">&lt;p&gt;We are pleased to introduce a new version of Algolia Search Offline for iOS,
Android and OS X (Windows versions will come soon).&lt;/p&gt;

&lt;p&gt;Version 2.1 significantly improves the out-of-the box relevance of Algolia
Search. We are now confident we have the best relevance on the market. We will
discuss our ranking approach compared to traditional methods in another post.
For now, the two main improvements offered in this version are:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;* When the query string has one word that is the entire content of a field, we will display it first. You can try it with the &quot;arm&quot; query on our Crunchbase demonstration to get the idea: [http://bit.ly/searchcrunchbase](http://bit.ly/searchcrunchbase) (it uses the same relevance approach).   * More importance is given to proximity than to the order of attributes. For example, the query &quot;managing p&quot; will now match first &quot;Managing Partner&quot; in the &quot;Title&quot; attribute instead of &quot;P&quot; in the &quot;Name&quot; attribute followed by &quot;Managing&quot; in the &quot;Title&quot;. This is the case even if the order of the attributes is [&quot;Name&quot;, &quot;Title&quot;, ...].
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;While you can control ranking with the setRankingOrder method, you will
benefit from these improvements by default.&lt;/p&gt;

&lt;p&gt;This new release also introduces some new features:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A way to efficiently serialize latitude/longitude and float values in your custom objects (reduce the size of serialized objects by up to 80%).&lt;/li&gt;
  &lt;li&gt;A method to compile an index in an old version format. This is useful when indexes are created server side and then pushed to applications that support old versions of Algolia.&lt;/li&gt;
  &lt;li&gt;All characters in tag filters are now supported.&lt;/li&gt;
  &lt;li&gt;It is now possible to do a logic OR between tags in filters. For example, you can search all contacts that match the query “paul” and have the tag “friend” OR the tag “classmate”.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We hope you’ll like these new features, and as ever, we welcome your feedback!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Instant Search through the iOS App Store</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/05/21/instant-search-on-ios-app-store/"/>
   <updated>2013-05-21T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/05/21/instant-search-on-ios-app-store</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.algolia.com/demo/appstore/&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/appstore.jpg&quot; alt=&quot;App Store&quot; /&gt;&lt;/a&gt;If
you have an iOS device you probably search the App Store regularly for apps
you have heard about. Following the recent AppGratis ousting from the
AppStore, there were claims that the App Store search function is broken. That
was our trigger to try something ourselves that could serve both as a good
demo and help us to explore new use-cases! &lt;a href=&quot;http://www.algolia.com/demo/appstore/&quot;&gt;Check it
out!&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;obtaining-the-data&quot;&gt;Obtaining the data&lt;/h2&gt;

&lt;p&gt;So first, we needed to obtain the data. Apple provides an API to accredited
developers, but given that this can be fairly difficult to attain, we
considered other solutions. Crawling was our second option, but that approach
has its own caveats: you need to play nice with their servers or you get
banned (very) quickly. We didn’t want to spend days implementing our own
distributed crawler and definitely didn’t have the time to do a sequential and
polite crawling. It is in these moments that you are glad to have an external
team to do the job for you.&lt;/p&gt;

&lt;p&gt;We chose to perform the crawling with &lt;a href=&quot;http://www.grepsr.com&quot;&gt;grepsr&lt;/a&gt;, a
service we found via a simple Google search. After a few exchanges we were
confident that they were up to the job, and they ended up exceeding our
expectations. Not only did they crawl the pages, but they also scraped the
apps’ attributes to provide us with a clean dataset. After a few days we had
our full dataset ready for indexing.&lt;/p&gt;

&lt;h2 id=&quot;indexing&quot;&gt;Indexing&lt;/h2&gt;

&lt;p&gt;Indexing was actually the easiest part. We uploaded the data in JSON format to
our backend and used these simple settings:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
&quot;attributesToIndex&quot;: [&quot;name&quot;, &quot;author&quot;, &quot;category&quot;],
&quot;attributesToHighlight&quot;: [&quot;name&quot;, &quot;author&quot;,&quot;category&quot;, &quot;description&quot;],
&quot;customRanking&quot;: [&quot;desc(score)&quot;, &quot;asc(name)&quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our dataset included the 630k applications currently published in the US app
store. For each of them we index the name, author and category, but also
include their icon, score, and description for display and sorting.&lt;/p&gt;

&lt;p&gt;The score is a simple computation between the number of comments and the
average ranking: &lt;code&gt;rating * log2(nbComments) * 10000&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;searching&quot;&gt;Searching&lt;/h2&gt;

&lt;p&gt;Similar to our &lt;a href=&quot;http://blog.algolia.com/instant-search-on-crunchbase/&quot;&gt;CrunchBase demo&lt;/a&gt;, we trigger a query directly after page load and again after each
keystroke. Additional queries are automatically triggered when scrolling to
the bottom of the page.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://platypus-creation.com&quot;&gt;Guillaume Esquevin&lt;/a&gt; did the front-end for us
and a first version of the demo was up and ready in no time. Take a look at
how simple and fast it is to search for an app!&lt;/p&gt;

&lt;p&gt;In the end we did receive access to the Apple API, which we may use later on
to keep the data in sync.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search Offline SDK now supports Cocoapods</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/04/25/algolia-search-offline-sdk-now-supports-cocoapods/"/>
   <updated>2013-04-25T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/04/25/algolia-search-offline-sdk-now-supports-cocoapods</id>
   <content type="html">&lt;p&gt;We have great news for our iOS and OS X users: our Offline SDK is now
available as a &lt;em&gt;&lt;a href=&quot;http://www.cocoapods.org/&quot;&gt;CocoaPods&lt;/a&gt; _dependency&lt;/em&gt;._&lt;/p&gt;

&lt;p&gt;Cocoapods is a popular dependency management tool that lets you specify the
libraries (dependencies) you want to use for your project in an easy-to-edit
text file (Podfile). It then fetches all the required libraries and sets up
your Xcode workspace.&lt;/p&gt;

&lt;p&gt;You can now set up Algolia Search Offline in your iOS project with this line
in your Podfile:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pod &#39;AlgoliaSearchOffline-iOS-SDK&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You can also set up Algolia Search Offline in your OS X project with this
line:&lt;/p&gt;

&lt;p&gt;&lt;code&gt;pod &#39;AlgoliaSearchOffline-OSX-SDK&#39;&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Once you’re done, simply use the “pod install” command to set up Algolia
Search Offline in your project. Now it’s easy to manage library dependencies
for iOS and OS X projects!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>V2: Search by Geolocation in our Offline Search SDK</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/04/16/v2-our-new-offline-search-sdk-with-geo-search-and-other-features/"/>
   <updated>2013-04-16T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/04/16/v2-our-new-offline-search-sdk-with-geo-search-and-other-features</id>
   <content type="html">&lt;p&gt;While our latest news focused on the Algolia Search cloud offer (you can still
join the &lt;a href=&quot;http://blog.algolia.com/our-saas-version-is-in-beta/)&quot;&gt;beta&lt;/a&gt;, we’re
pleased to introduce a major new version of Algolia Search offline: V2! It is
available today for iOS, Android and OS X. Windows Phone and Windows versions
will be released as soon as they are ready. A few months in the making, these
new features were built on early customer feedback and will simplify
integration.&lt;/p&gt;

&lt;h2 id=&quot;algolia-becomesthe-easiest-way-to-search-by-geolocation&quot;&gt;Algolia becomes the easiest way to search by geolocation!&lt;/h2&gt;

&lt;p&gt;The ease of integration is a constant concern for us and that’s why we
carefully consider every new feature. Two important features made it in this
version:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Geo-search means the ability to search around a location or inside a bounding box. Results can be sorted by distance and of course geo-queries can be combined with textual ones. We added a dedicated tutorial in the doc to get up to speed with this new feature in no time (for &lt;a href=&quot;http://www.algolia.com/doc/ios/#iOS_Geoloc&quot;&gt;iOS&lt;/a&gt; and &lt;a href=&quot;http://www.algolia.com/doc/android/#android_Geoloc)&quot;&gt;Android&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Tag filters enable restriction of results to specific tags. We received this demand a number of times in order to avoid the creation of too many specialized indexes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These new features are also available in the beta of our cloud version!&lt;/p&gt;

&lt;h2 id=&quot;improved-performance-and-ranking&quot;&gt;Improved performance and ranking&lt;/h2&gt;

&lt;p&gt;With some hard work… and a lot of profiling, we have been able to get a 10%
gain in performance on every query.&lt;/p&gt;

&lt;p&gt;In V1, name matches were always considered more important than other
attributes, but we didn’t consider differences between other attributes. This
changed in V2: ranking priority now respects the order in which you indicate
attributes in the textToIndex method. It’s more powerful while actually being
more consistent with no specific processing of the name field.&lt;/p&gt;

&lt;p&gt;But this improvement comes at the cost of a slightly bigger index and longer
computation. If index size is important or if you need to earn a few
nanoseconds more, you can optimize it away with the increaseCompression
method. You’ll get a 10 to 30% reduction in index size and an additional 20%
boost in performance (that’s 30% total compared to V1!).&lt;/p&gt;

&lt;h2 id=&quot;easy-just-got-easier&quot;&gt;Easy just got easier&lt;/h2&gt;

&lt;p&gt;Integrating search in an app has never been so easy. For V2 we took into
account all the excellent feedback we received, and wherever it was possible
we simplified the API:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;No distinction between suggest and search methods. We wanted to match the expected use-cases of the SDK but it was causing more confusion than anything else. So there is now only one way to send queries to an index: the search method.&lt;/li&gt;
  &lt;li&gt;With the addition of geo-search, the index class was becoming crowded. We simplified this by decoupling the search approach and query definition. A small set of search methods enable the developer to choose if the search will be synchronous, use a callback, or batch several queries. And a simple SearchQuery class defines the nature of the queries themselves: geolocation, use of prefixes, tag filters, etc.&lt;/li&gt;
  &lt;li&gt;Out of simple strings for which we provide a helper, every indexable object now has a UID. Our use of a “name” for this role led to a few difficulties when collisions were possible (persons for example). There are no longer any privileged attributes.&lt;/li&gt;
  &lt;li&gt;License key initialization is now done using a static method. It is a best practice that was actually necessary to build a &lt;a href=&quot;http://blog.algolia.com/algolia-search-is-now-available-for-rubymotion/&quot;&gt;RubyMotion gem&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Specific to Android, we also added an AbstractIndexable abstract class.
Instead of implementing the Indexable interface, you now have the option of
directly extending AbstractIndexable that takes care of optional methods for
you.&lt;/p&gt;

&lt;p&gt;Specific to iOS, you can now directly index core data entities with the
setCoreDataEntityDescription selector. No need to create a wrapper.&lt;/p&gt;

&lt;h2 id=&quot;still-able-to-read-v1-indexes&quot;&gt;Still able to read V1 indexes&lt;/h2&gt;

&lt;p&gt;If for any reason you cannot replace or reindex your data, V2 is still able to
search in a V1 index. However, as the name attribute was removed you do need
to implement the IndexableLegacy interface. If you then publish changes, the
new index will be in the V2 format.&lt;/p&gt;

&lt;p&gt;We’re really sorry to make our Windows Phone and Windows customers wait. Feel
free to torment us with your needs, it’s great motivation to finish more
quickly ;)&lt;/p&gt;

&lt;p&gt;If you’re still reading, I guess it’s time for you to test this new version of
the Algolia Search Offline SDK. &lt;a href=&quot;http://www.algolia.com/get-started/&quot;&gt;Get started&lt;/a&gt;!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Introducing a RubyMotion search gem by Algolia!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/04/16/algolia-search-is-now-available-for-rubymotion/"/>
   <updated>2013-04-16T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/04/16/algolia-search-is-now-available-for-rubymotion</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2013/04/rubymotion1.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/rubymotion1-270x300.png&quot; alt=&quot;Rubymotion search gem by Algolia is now
live!&quot; /&gt;&lt;/a&gt;If you are a Ruby developer and have
an iPhone, chances are you already now about the cool project that is
&lt;a href=&quot;http://www.rubymotion.com/&quot;&gt;RubyMotion&lt;/a&gt;! I quote:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“It lets you quickly develop and test native iOS applications for iPhone or
iPad, all using the awesome Ruby language you know and love.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And it rocks! It’s actually used by the Ruby on Rails sponsor 37signals.&lt;/p&gt;

&lt;p&gt;What if you could use your favorite search engine along with your favorite
language to create iOS apps? That’s exactly what we propose with Algolia’s
RubyMotion search gem that seamlessly integrates in your Ruby project. You
know the trick:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt; 
gem &#39;motion-algolia-search&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The gem code is open source. You can fork it from
&lt;a href=&quot;https://github.com/algolia/motion-algolia-search&quot;&gt;github&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Special thanks to the RubyMotion team and especially to
&lt;a href=&quot;https://twitter.com/joffreyjaffeux&quot;&gt;Joffrey&lt;/a&gt; for this integration!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>We are NEXT Berlin Finalists!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/04/11/we-are-finalists-at-next-berlin/"/>
   <updated>2013-04-11T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/04/11/we-are-finalists-at-next-berlin</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://nextberlin.eu/2013/04/next13-start-up-pitch-these-are-
the-12-finalists/&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/NextBerlin-300x155.png&quot; alt=&quot;NEXT Berlin Finalists&quot; /&gt;&lt;/a&gt;The &lt;a href=&quot;http://nextberlin.eu/&quot;&gt;NEXT Berlin Conference&lt;/a&gt; will
take place on April 23rd &amp;amp; 24th in one of the most active entrepreneurial
ecosystems in Europe!  More than 100 experts will share their knowledge with
an expected audience of 2000 attendees.&lt;/p&gt;

&lt;p&gt;If you follow our newsletter or social presence, chances are you saw our call
for help to participate in the NEXT Berlin startup competition. We sincerely
thank you for your votes! They placed us in the 30 top startups to be
considered for the final. The judges then selected us as one of the &lt;a href=&quot;http://nextberlin.eu/2013/04/next13-start-up-pitch-these-are-the-12-finalists/&quot;&gt;12
finalists&lt;/a&gt; to pitch during the conference. We are thrilled to be able
to present Algolia to Berlin!&lt;/p&gt;

&lt;p&gt;If you happen to be attending NEXT Berlin, ping me if you’d like to meet!
(@dessaigne on twitter, or nicolas at algolia dot com).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Instant Search on CrunchBase</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/03/26/instant-search-on-crunchbase/"/>
   <updated>2013-03-26T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/03/26/instant-search-on-crunchbase</id>
   <content type="html">&lt;p&gt;After launching the Beta Cloud version of Algolia, we wanted to demonstrate
what it can do. We built a search engine using CrunchBase data, so
entrepreneurs can easily search for their company or themselves. &lt;a href=&quot;http://www.algolia.com/demo/crunchbase/&quot;&gt;Check it
out!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;You can search for companies, people and financial organizations, using
multiple attributes. Results are updated after each keystroke and matching
characters are highlighted. And of course it tolerates typos. In this post
we’ll explain in more detail how it works.&lt;/p&gt;

&lt;h2 id=&quot;indexation&quot;&gt;Indexation&lt;/h2&gt;

&lt;p&gt;The CrunchBase API is unfortunately rather poor. There is no way to know the
latest update. So we dump it regularly and push it to our servers in JSON
format after pruning unnecessary attributes and adding images encoded in
base64.&lt;/p&gt;

&lt;p&gt;We actually create 3 indexes for companies (117k+ entries), persons (152k+
entries) and financial organizations (9k+ entries). The JSON files, including
images, are respectively 150MB, 70MB &amp;amp; 7MB.  The full indexation takes about 5
seconds (excluding upload time). Resulting index sizes are respectfully 124MB,
85MB and 7,5MB.&lt;/p&gt;

&lt;p&gt;Indexation is done simultaneously in 3 datacenters: US-West, US-East &amp;amp; Europe.
Additional datacenters are on the roadmap.&lt;/p&gt;

&lt;h2 id=&quot;instant-search&quot;&gt;Instant Search&lt;/h2&gt;

&lt;p&gt;We trigger a query directly after page load and again after each keystroke. To
simplify communication with the server, we created a javascript client
(contact us if you want to use it before its release). We then simply call the
search function indicating the callback that will handle resulting hits
asynchronously. More details to follow once we’ve written the doc!&lt;/p&gt;

&lt;p&gt;We automatically choose the server closest to your location by using &lt;a href=&quot;http://aws.amazon.com/route53/&quot;&gt;Amazon
Route 53&lt;/a&gt;. Once the DNS lookup is resolved, it
lets us get low enough latencies that the response feels nearly instantaneous
(if you test it from North America or Europe). From DSL connections, we obtain
search latencies of about 90ms in San Francisco, 75ms in New York and 65ms in
London. About 20ms are used for querying the index, 5ms for compressing the
data and 5ms for uncompressing. The remaining time is the actual transfer of
the data and depends of your location and the quality of your connection.&lt;/p&gt;

&lt;p&gt;If you’re a hacker, you may also remark the presence of an API key in the
javascript. It cannot be hidden as we directly query our servers from the
browser. The operations it enables are however restricted to search only, you
would need to use a different key to update entries for example. You can
create and revoke as many API keys you need directly from the API.&lt;/p&gt;

&lt;h2 id=&quot;hits-display&quot;&gt;Hits Display&lt;/h2&gt;

&lt;p&gt;No designer worked on the demo, but we hope it doesn’t show! We execute the 3
queries simultaneously and display the results by blocks of 20 hits.
Additional queries are automatically triggered when scrolling to the bottom of
the page.&lt;/p&gt;

&lt;p&gt;We display approximate results with a transparent background to clearly
differentiate them.&lt;/p&gt;

&lt;p&gt;You can use the arrow keys to navigate inside the results.&lt;/p&gt;

&lt;h2 id=&quot;ranking&quot;&gt;Ranking&lt;/h2&gt;

&lt;p&gt;We use the standard ranking order. By descending priority:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Exact matches before approximate matches;&lt;/li&gt;
  &lt;li&gt;User-defined order of attributes;&lt;/li&gt;
  &lt;li&gt;Distance between the matching term and the beginning of the attribute;&lt;/li&gt;
  &lt;li&gt;Proximity between terms in multi-word queries;&lt;/li&gt;
  &lt;li&gt;User defined score.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the order of attributes, we use {name, twitter, organization or people,
description}. This translates into very simple settings. Here are the settings
of the persons index, for example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;{
  &quot;attributesToIndex&quot;: [&quot;name&quot;, &quot;twitter&quot;, &quot;unordered(companies)&quot;, &quot;description&quot;],
  &quot;attributesToHighlight&quot;: [&quot;name&quot;, &quot;twitter&quot;, &quot;companies&quot;, &quot;description&quot;],
  &quot;customRanking&quot;: [&quot;desc(size)&quot;, &quot;asc(name)&quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;By default, all attributes are indexed and highlighted: “attributesToIndex” &amp;amp;
“attributesToHighlight” enable us to precisely define what to index (and in
what order) and what to highlight. The “unordered” modifier disable ranking
between values of a multi-valued attributes.&lt;/p&gt;

&lt;p&gt;For the user defined score (“customRanking” in settings) , we sort by
decreasing order of CrunchBase entry size and then by alphabetical order.&lt;/p&gt;

&lt;h2 id=&quot;help-us&quot;&gt;Help us&lt;/h2&gt;

&lt;p&gt;This is just a demo but we’d like to continue improving it! Please tell us
what you think and send your suggestions: contact at algolia dot com&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Online Search in the Cloud: Version is in Beta!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/03/18/our-saas-version-is-in-beta/"/>
   <updated>2013-03-18T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/03/18/our-saas-version-is-in-beta</id>
   <content type="html">&lt;p&gt;Imagine all the power and simplicity of Algolia Search, but available online,
from any connected device. Welcome to our Cloud!&lt;/p&gt;

&lt;p&gt;Up to now, our instant, typo-friendly search was only available locally on
your device. You could only index data stored directly in your app. While that
was great for offline apps, it was not so fantastic for rapidly changing data
server-side. All that has just changed! You can now use our search engine
online, enabling you to change your data at any frequency and return
consistantly up-to-date search results in your apps. Interested? Request your
invitation to the Beta from the &lt;a href=&quot;http://www.algolia.com/features/&quot;&gt;features
page&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;And don’t forget you can combine it with our offline SDK, for great search
performance whatever the connectivity!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>FREE Search SDK: Algolia is Now Available for Free!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/03/12/algolia-search-is-now-available-for-free/"/>
   <updated>2013-03-12T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/03/12/algolia-search-is-now-available-for-free</id>
   <content type="html">&lt;p&gt;Yes, you read that right! We’re not talking about a free trial, but of a
completely FREE version of our SDK. It is often difficult to implement a good
search experience, so we want to democratize access to easy-to-integrate and
first class search features! All you have to do is to display non-intrusive
Algolia branding.&lt;/p&gt;

&lt;p&gt;This branded offer is already available on our website. Don’t delay, &lt;a href=&quot;http://www.algolia.com/get-started/&quot;&gt;register
today&lt;/a&gt;! Check out our &lt;a href=&quot;http://www.algolia.com/usecases/&quot;&gt;use-cases
section&lt;/a&gt; to discover possible
implementations and see how Sharypic, Offline dictionaries, and Sush.io have
integrated Algolia in their apps.&lt;/p&gt;

&lt;p&gt;Help us spread the word. We want every app developer to be able to take
advantage of this offer!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Round table at Microsoft TechDays 2013</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/02/19/round-table-at-microsoft-techdays-2013/"/>
   <updated>2013-02-19T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/02/19/round-table-at-microsoft-techdays-2013</id>
   <content type="html">&lt;p&gt;I had the pleasure to be invited by &lt;a href=&quot;https://twitter.com/deltakosh&quot;&gt;David
Catuhe&lt;/a&gt; to participate in a round table about
Windows8 development during &lt;a href=&quot;http://www.microsoft.com/france/mstechdays/&quot;&gt;Microsoft TechDays
2013&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;I was joined by &lt;a href=&quot;http://blog.maneu.net&quot;&gt;Christopher Maneu&lt;/a&gt; from Deezer and
&lt;a href=&quot;fr.linkedin.com/pub/guillaume-leborgne/27/5b7/48&quot;&gt;Guillaume Leborgne&lt;/a&gt; from
MCNext, both deeply involved in Windows development. David (cropped from the
photo) led the discussion with &lt;a href=&quot;http://www.microsoft.com/france/microsoft-en-france/microsoft-france/equipe-dirigeante/jean-ferre.aspx&quot;&gt;Jean Ferré&lt;/a&gt;, who
leads the developers, platform and ecosystem division at Microsoft France.&lt;/p&gt;

&lt;p&gt;The discussion was very interesting and openly addressed the late start of
Microsoft on mobile. They seem to have spared no effort to ease the work of
developers, for example by opening the platform to development in
HTML5/Javascript. I confess I initially thought it was a strange choice for
native apps but it seems to have attracted quite a few web developers.&lt;/p&gt;

&lt;p&gt;This round table was a great opportunity to meet smart people and gain insight
into the Microsoft platform! Thanks also to the journalists in attendance who
covered Algolia in the IT press.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Meet us at the Mobile World Congress! - The Algolia Blog</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/02/19/meet-us-at-the-mobile-world-congress/"/>
   <updated>2013-02-19T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/02/19/meet-us-at-the-mobile-world-congress</id>
   <content type="html">&lt;p&gt;We’ll be in Barcelona next week for the Mobile World Congress! Last year, more
than 67,000 attendees participated in the event.&lt;/p&gt;

&lt;p&gt;We will use this opportunity to launch our new website along with a brand new
offer… Algolia for FREE! Stay tuned!&lt;/p&gt;

&lt;p&gt;If you happen to be attending MWC too, ping me if you’d like to discuss over a
coffee :) (@dessaigne on twitter, or nicolas at algolia dot com).&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>We ranked Second at Start In Paris!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/01/29/we-ranked-second-at-start-in-paris/"/>
   <updated>2013-01-29T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/01/29/we-ranked-second-at-start-in-paris</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.startinparis.com/&quot;&gt;Start In Paris&lt;/a&gt; is a monthly event where 5
startups have the opportunity to pitch their service to the Paris startup
community. After a first selection and then a public vote, we were selected as
one of 5 finalists of the #22 edition that took place yesterday, January the
28th!&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/StartInParis.gif&quot; alt=&quot;Start In Paris&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Algolia has greatly evolved over the last few months, so it was an excellent
occasion for us to test a new pitch! And the response has truly exceeded our
expectations. After a 5 minute pitch we received a rush of questions,
displaying interest and insight from the 400-strong audience!&lt;/p&gt;

&lt;p&gt;While we were the only tech startup to pitch to an audience including only a
few developers, we ranked second in votes, just behind &lt;a href=&quot;http://www.kitchentrotter.com/&quot;&gt;Kitchen
Trotter&lt;/a&gt;, our fellow Seedcamp finalist from
last December. Congrat to them, they were truly excellent!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Edit 03-Feb-2013]&lt;/strong&gt; Check out &lt;a href=&quot;https://twitter.com/AlexisNiki&quot;&gt;Alexis Niki&lt;/a&gt; great feedback about the event on &lt;a href=&quot;http://www.rudebaguette.com/2013/02/01/three-storytelling-tips-for-french-startups-when-pitching/&quot;&gt;Rude Baguette&lt;/a&gt; &lt;strong&gt;[/Edit]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2013/01/StartInParis.jpg&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/StartInParis-1024x768.jpg&quot; alt=&quot;Nicolas at Start In Paris&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Sharypic benefits from Algolia Search!</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/01/28/sharypic-benefits-from-algolia-search/"/>
   <updated>2013-01-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/01/28/sharypic-benefits-from-algolia-search</id>
   <content type="html">&lt;p&gt;Demonstrating how Algolia Search functions in the wild, in this post we will
discuss a recent integration with &lt;a href=&quot;http://sharypic.com&quot;&gt;sharypic&lt;/a&gt;, another
Paris-based startup focussed on photo sharing at events.&lt;/p&gt;

&lt;p&gt;Sharypic is a &lt;a href=&quot;http://www.sharypic.com/&quot;&gt;web&lt;/a&gt; and &lt;a href=&quot;https://itunes.apple.com/us/app/sharypic-event-photo-sharing/id490922939?mt=8&quot;&gt;mobile
app&lt;/a&gt; dedicated to collaborative photo sharing, focused on
enabling users to easily gather photos from attendees during and after an
event. The platform allows users to collect and share photos from all devices,
including mobiles (via Twitter and Instagram), cameras, and computers, and
from already existing albums on Facebook, Picassa, and Flickr. One of their
killer features is the ability to stream photos to a live PhotoWall at the
venue and to an embeddable slideshow widget. This increases engagement both
with event attendees and with an online audience. On sharypic one of the
primary ways that users discover events is via a search bar, in addition to
pages highlighting recent and popular events.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://blog.algolia.com/sharypic-benefits-
from-algolia-search/sharypic/&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/Sharypic.png&quot; alt=&quot;Sharypic&quot; /&gt;&lt;/a&gt;The existing mobile search function relied on
users accurately typing an event’s name into the search field, which limited
the results (especially on smartphones where typos are common). By integrating
Algolia Search into the mobile app, sharypic users can now type just a few
letters of a search term, or enter it incorrectly (‘pqris’ instead of
‘Paris’), and the results will display the corrected term within event names,
locations, descriptions, or hashtags.&lt;/p&gt;

&lt;p&gt;Martin Fourcade, one of sharypic’s co-founders, said “For our users, it’s
exactly what we needed. They can show the best photos of their events to
friends without bugging their smartphone and whining about the internet
connection. I’m lazy when it comes to typing on my smartphone, impatient when
it comes to waiting for server responses… now everything is done with a few
keystrokes!”&lt;/p&gt;

&lt;p&gt;Sharypic’s other co-founder François-Joseph Grimault hopes that this new
intelligent search will enable users to find specific content more easily,
possibly leading to increased exploration on the platform. Time will tell how
the new search feature affects user behaviour, but reducing user frustration
through quick and efficient search is a step in the right direction.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;&lt;a href=&quot;https://itunes.apple.com/us/app/sharypic-event-photo-sharing/id490922939?mt=8&quot;&gt;Download&lt;/a&gt; the latest version of the sharypic app, including
integrated Algolia Search, and have fun with photo sharing at your next
event!&lt;/em&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Why Android APK Format is a Mistake</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/01/24/why-android-apk-format-is-a-terrible-mistake/"/>
   <updated>2013-01-24T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/01/24/why-android-apk-format-is-a-terrible-mistake</id>
   <content type="html">&lt;p&gt;When I started to develop for Android it appeared to me that an APK file was
just an archive, a simple approach that you can find in many systems today.
Files are extracted from the archive at installation and you can access them
via the file-system.&lt;/p&gt;

&lt;p&gt;This seemed even more reasonable since Android uses Linux which is very good
in respect to POSIX standards.&lt;/p&gt;

&lt;p&gt;But I was completely wrong! An APK is not a mere archive: the application
starts from and uses the APK at runtime! This is a horrible decision that will
probably hurt Android for a long time…&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Edit 28-Jan-2013]&lt;/strong&gt; The goal of this post was to express my point of view about the bad properties of using directly the APK file at runtime versus relying on the file system. I used memory-mapped file to illustrate this but the post is incorrect on that topic. There is in fact a way to memory-map a file directly from the APK: you can use an extension for which files are stored uncompressed inside the APK (mp3, jpg, …) and use the &lt;code&gt;AssetManager.openFD()&lt;/code&gt; or &lt;code&gt;Resources.openRawResourceFD()&lt;/code&gt; to have offset/length inside the APK file.&lt;/p&gt;

&lt;p&gt;All my thanks to Jay Freeman for his excellent feedback. His comments helped
me to understand my mistake and to improve our Android integration!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[/Edit]&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;what-is-the-problem-with-the-apk-format&quot;&gt;What is the Problem with the APK format?&lt;/h3&gt;

&lt;p&gt;Let’s look at our own example. At Algolia, we have designed an efficient
binary data-structure that is able to answer instant-search queries in just a
few milliseconds, even with a very big data set (for example with all the
world cities’ names from Geonames: 3M+ entries). This data-structure is
designed to be used directly on disk without being copied in memory. To obtain
optimal performance, we use a &lt;a href=&quot;http://en.wikipedia.org/wiki/Memory-mapped_file&quot;&gt;memory-mapped
file&lt;/a&gt; which is standard on
all platforms, especially on Linux.&lt;/p&gt;

&lt;p&gt;We have been able to use memory-mapped files on all platforms, except on
Android!  In fact you can only retrieve an InputStream from a file packaged in
an APK. So the only solution to use a memory-mapped file is to copy the
resource from the APK on disk and then to use the file-system. This seems like
re-implementing an installer in each application.&lt;/p&gt;

&lt;h3 id=&quot;is-the-apk-so-bad-why-did-they-design-it-this-way&quot;&gt;Is the APK so bad? Why did they design it this way?&lt;/h3&gt;

&lt;p&gt;I imagine that Android developers chose this approach to solve some pitfalls
of file-systems. I can think for example about solving performance problems
when you have a lot of small files in one folder, or reducing the size of
applications on the device (resources are compressed in the APK and
decompressed only when the application uses them, which actually contributes
to the sluggish image of Android).&lt;/p&gt;

&lt;p&gt;I may of course be wrong, there may be other more important reasons for this
approach. But if not, Android should have thought more about the consequences
of their choice: in the long term, the APK constraints are more serious than
those small pitfalls that could have been solved in other ways.&lt;/p&gt;

&lt;p&gt;But wait… Android applications can contain dynamic libraries (.so files) via
NDK. Isn’t it the principle of dynamic libraries to be memory-mapped? In fact
I am pretty sure they discovered this problem when working on NDK since
dynamic libraries are automatically extracted from APK file at installation
and stored in an application directory in ‘/data/data’. I am wondering why
they decided to implement this hack instead of fixing the problem…&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Developing an API, a SDK or worse, a whole platform, is extremely difficult.
Let’s face it, it’s unavoidable to ship some badly designed components or
inconsistent APIs. We definitely need to listen to developers’ feedback even
when it hurts. Actually, the real difficulty comes when it’s time to put
things right without alienating existing users!&lt;/p&gt;

&lt;p&gt;By the way, if you know more about APK design choices, I’m interested to hear
from you!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Seedcamp: Tips and Advice From a Finalist - The Algolia Blog</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/01/15/seedcamp-tips-and-advice-from-a-finalist/"/>
   <updated>2013-01-15T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/01/15/seedcamp-tips-and-advice-from-a-finalist</id>
   <content type="html">&lt;p&gt;About one month ago, we were given the opportunity to participate in
&lt;a href=&quot;http://www.seedcamp.com/&quot;&gt;Seedcamp&lt;/a&gt; Paris 2012. In this post I’ll try to
think back to that time and provide feedback, along with some advice if you’re
considering going in that direction. In short, I can already say that this
experience has revolutionized the way we drive the company!&lt;/p&gt;

&lt;h2 id=&quot;seedcamp2&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/seedcamp.png&quot; alt=&quot;Seedcamp&quot; /&gt;&lt;/h2&gt;

&lt;h2 id=&quot;the-application&quot;&gt;The Application&lt;/h2&gt;

&lt;p&gt;Everything starts with a good application… or a rushed one in our case! At
that time (end of October) we were fully focused on product development and
finishing everything needed for our launch (documentation, video, etc.). While
we knew about Seedcamp coming to Paris in early December, we initially saw it
as a potential distraction from more important stuff… we could not have been
more wrong!&lt;/p&gt;

&lt;p&gt;Our opinion changed after a lunch with &lt;a href=&quot;https://twitter.com/PhilippeLaval&quot;&gt;Philippe
Laval&lt;/a&gt;, former Seedcamp alumni with his
company Kwaga (now &lt;a href=&quot;https://www.writethat.name/)&quot;&gt;WriteThat.name&lt;/a&gt;, whom I had
the pleasure to meet a few times in my previous jobs. In a couple of hours,
Philippe opened our eyes to the broad requirements for successfully launching
a startup. Product is clearly one, but there are so many others we could not
ignore. His description of how his Seedcamp participation helped him a few
years back was enough to convince us we had to give it a shot.&lt;/p&gt;

&lt;p&gt;Each step of the process brought its own rewards, starting with the
application! It is a simple form but it contains excellent questions about
positioning, monetization, competition and more. The best thing about it was
that we were forced to write down our vision for the company and this simple
process made us think harder than we had ever done before. We ended up
convincing ourselves more fully of what we were doing and why, with facts and
arguments to defend our vision. Of course, we would present the company
completely differently today! We continued to learn at an accelerated pace in
the following weeks. Despite some imperfections, participating in a Seedcamp
final is definitely a must.&lt;/p&gt;

&lt;h2 id=&quot;the-almighty-pitch-preparation&quot;&gt;The Almighty Pitch Preparation&lt;/h2&gt;

&lt;p&gt;About a couple of weeks before the event,  we received the good news: we were
in! The promise to keep our success confidential was a bit frustrating, but
honestly we were overjoyed! However, there was no time to celebrate as
preparations for the event began immediately.&lt;/p&gt;

&lt;p&gt;We already knew about the format and what to expect from the Seedcamp team
from what we gathered on the web. But there is a great leap from knowing to
actually preparing to participate! And with all the regular day-(to-night-)to-
day activities that our startup entailed, time was short.&lt;/p&gt;

&lt;p&gt;We started by focusing on the pitch: 3 minutes, in English, to say a lot. We
rapidly drafted a first version and began to iterate, adding essential
information and removing anything not worth mentioning. It may seem
straightforward, but including everything from the problem, solution, vision,
market, competition, monetization and team in a three minute deck is no easy
task. It is, however,  an excellent way to learn how to better explain your
startup! We learned to be concise - every word counts, and I began to memorize
each and every one of them. I had given speeches of various kinds on many
occasions in the past but I had never learned a text by heart. If you’ve never
done it before, it is more difficult than you may think. For a long time, I
was so concerned to get the wording right that any mistake would send me
fumbling for my next words. I had to practice dozens of times to feel
comfortable enough to pay attention to simple things like intonation!&lt;/p&gt;

&lt;p&gt;Some advice: start working on your pitch as early as possible and get as much
feedback as you can. We were able to organize some pitch training sessions
with startup personalities and I can’t stress how useful this proved to be!
(Our greatest thanks to &lt;a href=&quot;https://twitter.com/wesselkooyman&quot;&gt;Wessel&lt;/a&gt;,
&lt;a href=&quot;https://twitter.com/LiamBoogar&quot;&gt;Liam&lt;/a&gt;,
&lt;a href=&quot;https://twitter.com/PhilippeLaval&quot;&gt;Philippe&lt;/a&gt; and
&lt;a href=&quot;http://us.yakaz.com/about/whosYakaz.php)&quot;&gt;Fred&lt;/a&gt;. But wait, isn’t there a
training session on the eve of the event? Yes, and it is incredibly useful.
But if you don’t like the idea of changing everything overnight, work on your
draft and seek feedback beforehand! The preparation session will be all the
more focused for it. Also, if you can, do test your presentation with the
actual computer and projector that will be used the next day. While in our
case the conference room was really nice, the projector was very low-res and
our embedded video would not render at all. Fortunately we had the time to
record a new one with all fonts in bold…&lt;/p&gt;

&lt;h2 id=&quot;prepare-your-mentoring-session-too&quot;&gt;Prepare your Mentoring Session too!&lt;/h2&gt;

&lt;p&gt;Out of the 20 teams participating, only two or three get an investment, so the
odds are tough. You may be lucky and seduce the Seedcamp team, but if not
don’t waste your opportunity to get the most out of the mentoring sessions!
This is an incredible opportunity: about 80 mentors, many of them expert in
some field key to the success of your company, and all there ready to help.
Believe me, you don’t want to miss that! You would have a hard time to get
their attention at any other time.&lt;/p&gt;

&lt;p&gt;So be prepared! Think hard about the important questions (tip: usually the
ones that hurt) and look at the mentors’ bios, articles, and anything else you
can dig up. If there’s a fit, that’s a win! Don’t take it lightly, this is
probably harder than preparing your pitch. You’re probably thinking you only
have one chance to make a good first impression with your pitch, while you
can’t shame yourself too badly by being underprepared for the mentoring
sessions. You’re right… but I’m convinced it is much more fruitful to
concentrate on getting answers and advice that could mean success over failure
for your company (a passable pitch may not be enough to get a Seedcamp
investment but good advice might reap untold rewards). Convinced? Have a look
at &lt;a href=&quot;http://klinger.io/post/36812415337/startup-mentoring-sessions-how-to-get-the-most-out-of&quot;&gt;Andreas Klinger excellent post&lt;/a&gt; to get on track!&lt;/p&gt;

&lt;p&gt;In our case, Julien did most of the work preparing for mentoring while I
concentrated on the pitch. Could we have done more? Probably. Should we have
done more? Yes. One month after the event, I think we put a good level of
effort into the pitch preparation, but we should have taken some more time on
the mentoring preparation. Honestly, I think we were good, with a clear list
of questions and we were ready to shut up and listen. But we could have
researched the mentors more thoroughly, especially the ones not on our
schedule.&lt;/p&gt;

&lt;h2 id=&quot;d-day&quot;&gt;D Day&lt;/h2&gt;

&lt;p&gt;Your pitch is ready, you’ve got all mentors covered, you slept &lt;del&gt;8&lt;/del&gt;
&lt;del&gt;6&lt;/del&gt; &lt;del&gt;4&lt;/del&gt; as many hours as you could… let’s do this! First,
get up early. Arrive at least 30 minutes before the start of the event. Then
you have time to relax, get friendly with other teams and actually take the
opportunity to speak with a few mentors before the event.&lt;/p&gt;

&lt;p&gt;After a relatively short presentation by the Seedcamp team, it will be time
for the pitches! 20 of them, 3 minutes each. Attention tends to drift, which
is why your pitch has to be captivating. Now is your chance to shine and put
all your practice to the test! We were lucky to go first as we were sorted in
alphabetical order. Other participants thought that was unlucky but I was
thankful! I had an opportunity to grab the audience’s attention and there was
no time for stress to build up in anticipation before our turn… and
everything went all right! It was actually one of my best performances, much
better than during training the previous day.&lt;/p&gt;

&lt;p&gt;One thing we could have improved was leveraging the pitch for communication.
There are two things you can easily do - take some photos or a video, and
tweet about your experience! Also, always have your twitter handle visible on
the slides. You may think it is enough to put it on the first and last slides
but what if someone watching wants to tweet during your pitch? Make it easy
for them!&lt;/p&gt;

&lt;h2 id=&quot;time-for-mentoring&quot;&gt;Time for Mentoring&lt;/h2&gt;

&lt;p&gt;OK, so you are prepared for the mentoring and have researched all the mentors?
Some good ones are certainly not in your schedule so go and meet them during
the breaks! And either ask them to participate in your open sessions (mentors
are free to pick the teams they want for the last two sessions) or directly
ask them the questions that trouble you. Don’t expect them to remember
everything you said during your pitch (they just saw 20 of them!) so get a
short intro ready. It is also better to have a quick demo instead of too many
words.&lt;/p&gt;

&lt;p&gt;You’re now up for 5 or 6 sessions of  intense discussion with mentors. Andreas
provides excellent &lt;a href=&quot;http://klinger.io/post/36812415337/startup-mentoring-sessions-how-to-get-the-most-out-of&quot;&gt;advice&lt;/a&gt; on the pitfalls and potential
benefits of these sessions. Don’t forget, mentors are there to help you, they
won’t attack you. Don’t try to convice them you’re right, just listen what
they have to say. Don’t lose time explaining every aspect of your startup,
instead ask specific questions about their experience. And don’t be shy to ask
for introductions. Either they will or they won’t, but it doesn’t hurt to ask!&lt;/p&gt;

&lt;p&gt;Of course nothing is ever perfect. All mentors are not equal and some of them
may not even show up to your scheduled session (don’t blame them, they usually
have a hectic schedule and your startup may not have an activity they relate
to). Anyway, you don’t need to speak with all of them. It is much better to
enjoy profound and fruitful discussions with a few.&lt;/p&gt;

&lt;h2 id=&quot;followups&quot;&gt;Followups&lt;/h2&gt;

&lt;p&gt;The day concludes with a party - in our case at a nice wine bar. As you can
guess, every team was quite exhausted and didn’t stay late. A handful would be
invited back the next day to discuss potential participation in the program.
The selection process is a little obscure, with no clue provided as to their
criteria. This is a bit frustrating as I would have appreciated to know why
they didn’t select us.&lt;/p&gt;

&lt;p&gt;Keep in mind that mentors will have been approached by many people and may
forget the intro they promised you. Connect with them, thank them for their
precious advice, and kindly remind them of the introductions they promised.
And if you had a really good discussion with some of them, see if they would
be happy to continue a more regular mentorship role.&lt;/p&gt;

&lt;h2 id=&quot;takeaways&quot;&gt;Takeaways&lt;/h2&gt;

&lt;p&gt;To get the best out of your Seedcamp final, you should invest a lot of time in
preparation. Don’t bet everything on being accepted, the pitch day and
mentoring alone is definitely worth your effort. The preparation itself helped
us to focus on key questions and strategic decisions. We then had a priceless
opportunity to test our ideas with experts in many domains and to ask them
focused questions. That was like 6 months worth of mentorship in one day and
it profoundly affected our strategy for 2013! The event also boosted our
network - we contacted many people directly after the event and a few have
even become regular mentors.&lt;/p&gt;

&lt;p&gt;The Seedcamp team is amazing but there is some room for improvement. We got
excellent feedback on our pitch during the training,  but unfortunately, it
was lacking after the actual event. We were forwarded a few very nice comments
from mentors, but that was it. While we had the opportunity to discuss
directly with mentors, I would have loved to have some feedback from the
Seedcamp team. I understand they do not want to encourage debate over their
selection decisions, but understanding their reasoning would certainly be
useful.&lt;/p&gt;

&lt;p&gt;From listening to other participants about their experience, be aware that if
you are selected for investment, the paperwork is time-consuming! Do not plan
too many developments for your startup or you may be disappointed by the poor
progress you’ll make during that time. And don’t forget that the Seedcamp US
trip is early the following year and that is something to prepare for too!
Another important thing we overlooked when applying is the need to
(re)incorporate your company in the UK. This is not such a big deal in the
first year as you will have help from Seedcamp but what about afterwards,
especially if you operate from your home country? Each country’s legislation
is highly specific and you may have some headaches in store. Don’t forget to
prepare for this before the end of the Seedcamp program.&lt;/p&gt;

&lt;p&gt;In conclusion, Seedcamp Paris lived up to its reputation. Asked if we would do
it again, we would certainly answer yes! And I sincerely encourage other
startups to give it a go!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Android NDK: How to Reduce Binaries Size - The Algolia Blog</title>
   <link href="https://github.com/svenhutchinson/extensions/2013/01/10/android-ndk-how-to-reduce-libs-size/"/>
   <updated>2013-01-10T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2013/01/10/android-ndk-how-to-reduce-libs-size</id>
   <content type="html">&lt;p&gt;When we started Algolia Development for Android, binary size optimization was
not one of our main concerns. In fact we even started to develop in JAVA
before switching to C/C++ for &lt;a href=&quot;http://blog.algolia.com/need-performance-on-mobile-use-c-cpp/&quot;&gt;reasons of performance&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;We were reminded of the importance of binary size by &lt;a href=&quot;http://android.cyrilmottier.com&quot;&gt;Cyril
Mottier&lt;/a&gt; who informed us that it would be
difficult to integrate our lib in &lt;a href=&quot;https://play.google.com/store/apps/details?id=com.cyrilmottier.android.avelov&quot;&gt;AVelov&lt;/a&gt; Android Application because its
size. AVelov is 638KB and Algolia was 850KB, which would mean that AVelov
would more than double in size with Algolia Search embedded.&lt;/p&gt;

&lt;p&gt;To address this problem we managed to reduce Algolia binary size from 850KB to
307KB. In this post we share how we did it.&lt;/p&gt;

&lt;h3 id=&quot;do-not-use-exceptions-and-rtti&quot;&gt;Do not use Exceptions and RTTI&lt;/h3&gt;

&lt;p&gt;We actually do not use exceptions in our native lib, but for the sake of
completeness, I’ll cover this point too.&lt;/p&gt;

&lt;p&gt;C++ exceptions and RTTI are disabled by default but you can enable them via
&lt;em&gt;APP_CPPFLAGS&lt;/em&gt; in your &lt;em&gt;Application.mk&lt;/em&gt; file and use a compatible STL, for
example:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;APP_CPPFLAGS += -fexceptions -frtti
APP_STL := stlport_shared
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Whilst using exceptions and RTTI can help you to use existing code, it will
obviously increase your binary size. If you have a way to remove them, go for
it! Actually, there’s another reason to avoid using C++ exceptions: their
support is still far from perfect. For example if was impossible for us to
catch a C++ exception and launch a Java exception in JNI. The following code
results in a crash (will probably be fixed in a future release of the Android
NDK toolchain):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;try {
    ...
} catch (std::exception&amp;amp; e) {
    env-&amp;gt;ThrowNew(env-&amp;gt;FindClass(&quot;java/lang/Exception&quot;), &quot;Error occured&quot;);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;do-not-use-iostream&quot;&gt;Do not use iostream&lt;/h3&gt;

&lt;p&gt;When starting to investigate our library size following Cyril’s feedback, we
discovered that Algolia binaries had vastly increased in size since our last
release (from 850KB to 1.35MB)! We first suspected the Android NDK toolchain
since we upgraded it and tested different toolchains, but we only observed
minor changes.&lt;/p&gt;

&lt;p&gt;By dichotomy search in our commits, we discovered that a single line of code
was responsible for the inflation:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;std::cerr &amp;lt;&amp;lt; .... &amp;lt;&amp;lt; std::endl;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;As incredible as it may sound, using iostream increases a lot the binary size.
Our tests shown that it adds a least 300KB per architecture! You must be very
careful with iostream and prefer to use __android_log_print method:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;#include &amp;lt;android/log.h&amp;gt;
#define APPNAME &quot;MyApp&quot;

__android_log_print(ANDROID_LOG_VERBOSE, APPNAME, &quot;The value of 1 + 1 is %d&quot;, 1+1);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Make sure you also link against the logging library, in your Android.mk file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LOCAL_LDLIBS := -llog
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&quot;use--fvisibilityhidden&quot;&gt;Use -fvisibility=hidden&lt;/h3&gt;

&lt;p&gt;An efficient way to reduce binary size is to use the &lt;a href=&quot;http://gcc.gnu.org/wiki/Visibility&quot;&gt;visibility
feature&lt;/a&gt; of gcc. This feature lets you
control which functions will be exported in the symbols table. Hopefully, JNI
comes with a &lt;em&gt;JNIEXPORT&lt;/em&gt; macro that flags JNI functions as public. You just
have to check that all functions used by JNI are prefixed by JNIEXPORT, like
this one:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;JNIEXPORT void JNICALL Java_ClassName_MethodName
(JNIEnv *env, jobject obj, jstring javaString)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then you have just to add &lt;em&gt;-fvisibility=hidden&lt;/em&gt; for C and C++ files in
&lt;em&gt;Android.mk&lt;/em&gt; file:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LOCAL_CPPFLAGS += -fvisibility=hidden
LOCAL_CFLAGS += -fvisibility=hidden
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In our case the binaries were down to 809KB (-5%) but remember the gains may
be very different for your project. Make your own measures!&lt;/p&gt;

&lt;h3 id=&quot;discard-unused-functions-with-gc-sections&quot;&gt;Discard Unused Functions with gc-sections&lt;/h3&gt;

&lt;p&gt;Another interesting approach is to remove unused code in the binary. It can
drastically reduce its size if for example part of your code is only used for
tests.&lt;/p&gt;

&lt;p&gt;To enable this feature, you just have to change the C and C++ compilation
flags and the linker flags in &lt;em&gt;Android.mk&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LOCAL_CPPFLAGS += -ffunction-sections -fdata-sections
LOCAL_CFLAGS += -ffunction-sections -fdata-sections 
LOCAL_LDFLAGS += -Wl,--gc-sections
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Of course you can combine this feature with the visibility one:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;LOCAL_CPPFLAGS += -ffunction-sections -fdata-sections -fvisibility=hidden
LOCAL_CPPFLAGS += -ffunction-sections -fdata-sections -fvisibility=hidden
LOCAL_CFLAGS += -ffunction-sections -fdata-sections  LOCAL_LDFLAGS += -Wl,--gc-sections
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This optim only got us a 1% gain, but once combined with the previous
visibility one, we were down to 691KB (-18.7%).&lt;/p&gt;

&lt;h3 id=&quot;remove-duplicated-code&quot;&gt;Remove Duplicated Code&lt;/h3&gt;

&lt;p&gt;You can remove duplicated code with the –icf=safe option of the linker. Be
careful, this option will probably remove your code inlining, you must check
that this flag does not impact performance.&lt;/p&gt;

&lt;p&gt;This option is not yet available on the mips architecture so you need to add
an architecture check in &lt;em&gt;Android.mk&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ifneq ($(TARGET_ARCH),mips)
  LOCAL_LDFLAGS += -Wl,--icf=safe
endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;And if you want to combine this option with gc-sections:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ifeq ($(TARGET_ARCH),mips)
  LOCAL_LDFLAGS += -Wl,--gc-sections
else
  LOCAL_LDFLAGS += -Wl,--gc-sections,--icf=safe
endif
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We actually only obtained a 0.8% gain in size with this one. All previous
optimizations combined, we were now at 687KB (-19.2%).&lt;/p&gt;

&lt;h3 id=&quot;change-the-default-flags-of-the-toolchain&quot;&gt;Change the Default Flags of the Toolchain&lt;/h3&gt;

&lt;p&gt;If you want to go even further, you can change the default compilation flags
of the toolchain. Flags are not identical accross architectures, for example:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;inline-limit is set to 64 for arm and set to 300 for x86 and mips&lt;/li&gt;
  &lt;li&gt;Optimization flag is set to -Os (optimize for size) for arm and set to -O2 (optimize for performance) for x86 and mips&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As arm is used by the large majority of devices, we have applied arm settings
for other architectures. Here is the patch we applied on the toolchain
(version r8d):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;--- android-ndk-r8d/toolchains/mipsel-linux-android-4.6/setup.mk
+++ android-ndk-r8d.new/toolchains/mipsel-linux-android-4.6/setup.mk
@@ -41,12 +41,12 @@
 TARGET_C_INCLUDES := 
     $(SYSROOT)/usr/include

-TARGET_mips_release_CFLAGS := -O2 
+TARGET_mips_release_CFLAGS := -Os 
                               -g 
                               -DNDEBUG 
                               -fomit-frame-pointer 
                               -funswitch-loops     
-                              -finline-limit=300
+                              -finline-limit=64

 TARGET_mips_debug_CFLAGS := -O0 
                             -g 
--- android-ndk-r8d/toolchains/x86-4.6/setup.mk
+++ android-ndk-r8d.new/toolchains/x86-4.6/setup.mk
@@ -39,13 +39,13 @@

 TARGET_CFLAGS += -fstack-protector

-TARGET_x86_release_CFLAGS := -O2 
+TARGET_x86_release_CFLAGS := -Os 
                              -g 
                              -DNDEBUG 
                              -fomit-frame-pointer 
                              -fstrict-aliasing    
                              -funswitch-loops     
-                             -finline-limit=300
+                             -finline-limit=64

 # When building for debug, compile everything as x86.
 TARGET_x86_debug_CFLAGS := $(TARGET_x86_release_CFLAGS)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We were good for a 8.5% gain with these new flags. Once combined with previous
optimizations, we were now at 613KB (-27.9%).&lt;/p&gt;

&lt;h3 id=&quot;limit-the-number-of-architectures&quot;&gt;Limit the Number of Architectures&lt;/h3&gt;

&lt;p&gt;Our final suggestion is to limit the number of architectures. Supporting
armeabi-v7a is mandory for performance if you have a lot of floating point
computation, but armeabi will provide a similar result if you do not need a
FPU. As for mips processors… well they just are not in use on the market
today.&lt;/p&gt;

&lt;p&gt;And if binary size is really important to you, you can just limit your support
to armeabi and x86 architectures in &lt;em&gt;Application.mk&lt;/em&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;APP_ABI := armeabi x86
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Obviously, this optim was the killer one. Dropping two out of four
architectures halved the binaries size. Overall we obtained a size of 307KB, a
64% gain from the initial 850KB (not counting the bump at 1.35MB due to
iostream).&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;I hope this post will help you to reduce the size of your native libraries on
Android since default flags are far from optimal. Don’t expect to obtain the
same size reductions, they will highly depend on your specific usage. And if
you know other methods to reduce binary size, please share in the comments!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Simplicity is the most Complex Feature!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/12/28/simplicity-is-the-most-complex-feature/"/>
   <updated>2012-12-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/12/28/simplicity-is-the-most-complex-feature</id>
   <content type="html">&lt;p&gt;I’ve been convinced for a long time that simplicity is the most important
property of a product. Long-gone are the 90s when a product was admired for
its complexity. But I am also convinced that this is the most complex property
to achieve and maintain as time passes by.&lt;/p&gt;

&lt;p&gt;A good example of an over-complex product is Atlassian JIRA, a bug tracker
that also do scrum management and plenty of other things via dozens of
plugins. It’s basically a toolbox to create the bug tracker adapted to your
company.&lt;/p&gt;

&lt;p&gt;In my previous job, I faced an uncomfortable situation with JIRA because of
its complexity. We used it for bug tracking and scrum management and I tried
to upgrade our old version to the latest one. After some long hours to upgrade
our setup on a test server, I finally got the latest version working but most
of our installed plugins were not available anymore because the authors did
not port their plugins to the new plugin API. Of course each plugin was there
for a reason and I was in a tricky situation: keep the old version with
security issues or upgrade to a new version without our plugins.&lt;/p&gt;

&lt;p&gt;But it was far more vicious: There were about 10 versions between our old
version and the latest one, and I didn’t find any of these versions working
with our set of plugins! In the end, we were forced to keep our old version.&lt;/p&gt;

&lt;p&gt;Atlassian forgot the most important lesson, even with a toolbox: simplicity!
This is probably more expensive for them to keep plugin backward
compatibility, but I would prefer for them to not have any plugin rather than
breaking compatibility at each release. The final system is too complex to be
maintainable and our final decision was to stop paying for JIRA support since
we were blocked with an old release. It is even bad for their business.&lt;/p&gt;

&lt;p&gt;You should be focused on simplicity for your users even it this results in
more complexity for you (like maintaining backward compatibility)! As this
post is strongly related to backward compatibility of API, I encourage you to
reread this famous post of Jeol Spolsky: &lt;a href=&quot;http://www.joelonsoftware.com/articles/APIWar.html&quot;&gt;How microsoft lost the API
war&lt;/a&gt;.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Never, Ever, Hinder the Use of your Products!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/12/21/never-ever-hinder-the-use-of-your-products/"/>
   <updated>2012-12-21T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/12/21/never-ever-hinder-the-use-of-your-products</id>
   <content type="html">&lt;p&gt;One of the worst user experiences I have ever had with software was with the
Sony PS3. I kind of liked this product; I found the user interface very nice
and well organized… but they were much too aggressive about upgrades! They
simply blocked features until the upgrade was done!&lt;/p&gt;

&lt;p&gt;A few weeks ago I wanted to watch a VOD movie with my wife. I launched the
Playstation Store that asked me to upgrade the OS to the latest version.
That’s &lt;strong&gt;45 minutes&lt;/strong&gt; before being able to access the Playstation again! But
wait! Once the new OS was installed, I tried to launch  the Playstation Store
again… This time, it was the Playstation Application that was not up to date
!&lt;/p&gt;

&lt;p&gt;In total it took me over &lt;strong&gt;1 hour&lt;/strong&gt; to do upgrades and guess what, at the end
it was just too late to watch the movie!&lt;/p&gt;

&lt;p&gt;Generally, frequent upgrades are good for your users, and I am sure there are
plenty of bug fixes/improvments in the lastest version. But Sony has just made
the wrong choice in blocking features until the upgrade is done. This is just
plain frustrating for users! On the contrary, Android and iOS propose an
upgrade that you can apply when you want. Best of all, they download in the
background.&lt;/p&gt;

&lt;p&gt;It may sound evident, but it is very important to ensure your users will
always be able able to keep control over their products. You should never
force them to do something they do not want to, like Sony did with the PS3.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search is now in Beta for Microsoft Windows 8 Desktops and Tablets - The Algolia Blog</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/12/20/windows-8-beta-is-out-algolia-search-now-available-for-microsoft-desktops-and-tablets/"/>
   <updated>2012-12-20T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/12/20/windows-8-beta-is-out-algolia-search-now-available-for-microsoft-desktops-and-tablets</id>
   <content type="html">&lt;p&gt;You may have been expecting Windows Phone 8 as our next platform of choice,
but we preferred to go Windows 8 first! With more than 40M sold in a month,
let’s say it’s a slightly more interesting market for now.&lt;/p&gt;

&lt;h2 id=&quot;windows-8-our-first-move-to-the-desktop&quot;&gt;Windows 8: Our First Move to the Desktop&lt;/h2&gt;

&lt;p&gt;Yes, desktop apps are not as dead as many people think, especially now that
both Mac OSX and Windows come with their app stores. Sure, Windows is now
running on tablets - and we also support them - but it will take time before
they surpass desktops.&lt;/p&gt;

&lt;p&gt;What’s more, the new Windows 8 &lt;del&gt;Metro&lt;/del&gt; Modern UI includes a charm bar
with search and autocompletion as the number one feature. Microsoft actually
provides an interface to ease application integration in the charm search
bar… but no library to help you implement it. No problem, here comes Algolia
Search for Windows 8!&lt;/p&gt;

&lt;h2 id=&quot;awesome-features-for-your-apps&quot;&gt;Awesome Features for Your Apps&lt;/h2&gt;

&lt;p&gt;The core technology is exactly the same as the one in our iOS and Android
versions. That means you’ll get exactly the same exceptional performance…
well probably even better depending of the hardware you’re running on. You’ll
also get instant visual feedback, typo-tolerance and multiple attributes
support! See all the features on our
&lt;a href=&quot;http://www.algolia.com/product/&quot;&gt;website&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&quot;easy-to-integrate-in-your-language-of-choice&quot;&gt;Easy to Integrate in your Language of Choice&lt;/h2&gt;

&lt;p&gt;Check out the dedicated &lt;a href=&quot;http://www.algolia.com/doc/win8/&quot;&gt;tutorials&lt;/a&gt;! The
Algolia Search library has been designed to work directly on the platform.
That means you can use it in whatever language you prefer, be it JS or one of
the .Net choices (C#, VB, C++). The tutorials are available in both JS and in
C#.&lt;/p&gt;

&lt;p&gt;Moreover it is fully compatible with Microsoft &lt;strong&gt;Search Contracts&lt;/strong&gt;. It just
became child’s play to integrate Search in your Windows app!&lt;/p&gt;

&lt;h2 id=&quot;hey-microsoft-there-are-a-couple-of-features-you-could-improve&quot;&gt;Hey Microsoft, There are a Couple of Features You Could Improve&lt;/h2&gt;

&lt;p&gt;Windows 8 is clearly a step in the right direction, but we encountered some
problems we didn’t expect!&lt;/p&gt;

&lt;p&gt;First is the multi-arch support. While it’s just straightforward with iOS or
Android (out of the JNI part…), using a native lib forces the developer to
chose an architecture on Windows! Fortunately, Visual Studio Package Generator
handles that correctly and proposes you to select all architectures for your
final export. But well… we’d have preferred it plain and simple.&lt;/p&gt;

&lt;p&gt;Our second deception is a bit more problematic as it prevents one of our very
nice features: typo-tolerant highlighting during autocompletion. It starts
with best of intentions from Microsoft. To remove the burden of implementing
highlight for autocompletion on developers, Windows 8 handles it directly. The
only problem is that it cannot be replaced by our own :( So you can obtain
hits even if your query contains typos, but hits containing text different
from the query won’t be highlighted.&lt;/p&gt;

&lt;p&gt;We hope to be able to change this behaviour in the future. In the meantime,
we’re impatient to get your feedback on this beta!
&lt;a href=&quot;http://www.algolia.com/try/&quot;&gt;Register&lt;/a&gt; for your Windows 8 version of Algolia
Search now!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Smart Contacts Demo Hits the App Store!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/12/13/our-smart-contacts-demo-hits-the-app-store/"/>
   <updated>2012-12-13T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/12/13/our-smart-contacts-demo-hits-the-app-store</id>
   <content type="html">&lt;p&gt;After going back and forth a few times with Apple, we are really happy to
announce the availibility of our &lt;a href=&quot;https://itunes.apple.com/gb/app/algolia-smart-contact/id583433043&quot;&gt;Smart
Contacts&lt;/a&gt;
application on the App Store! Even if we built it to demonstrate the amazing
features of our search technology SDK, it can be used as an in-place
replacement of the traditional iPhone Contacts app. Check it up!&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://itunes.apple.com/gb/app/algolia-smart-
contact/id583433043&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/available-on-iphone-app-store-logo.png&quot; alt=&quot;Smart Contacts demo hits the App Store&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;outstanding-search-features&quot;&gt;Outstanding Search Features&lt;/h2&gt;

&lt;p&gt;It plugs directly into your iPhone contacts and classically allows you to
update them or create new ones. What’s more interesting is the Search
integration! It features:&lt;a href=&quot;https://blog.algolia.com/wp-content/uploads/2012/12
/SmartContact-iphone5.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/SmartContact-iphone5-489x1024.png&quot; alt=&quot;Smart Contacts Screenshot&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Instant search&lt;/strong&gt; with autocompletion and &lt;strong&gt;visual feedback&lt;/strong&gt; as you type&lt;/li&gt;
  &lt;li&gt;Search on &lt;strong&gt;all contacts attributes&lt;/strong&gt; (name, company, notes, etc.)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Typo tolerance&lt;/strong&gt; to account for smartphone small keyboards&lt;/li&gt;
  &lt;li&gt;And even &lt;strong&gt;search by initials&lt;/strong&gt;!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;ios-api-limitations&quot;&gt;iOS API Limitations&lt;/h2&gt;

&lt;p&gt;There are a few of features we would have loved to integrate that were not
possible due to limitations in iOS APIs: group management, in place
replacement of contacts in the phone app (that’s maybe a lot to ask!), and
ranking based on contact popularity.&lt;/p&gt;

&lt;h2 id=&quot;free-your-imagination&quot;&gt;Free your Imagination!&lt;/h2&gt;

&lt;p&gt;If you ever wanted to see Algolia Search in action, now is the time. Check it
up with your own data and imagine what Algolia can do for the application you
develop!&lt;/p&gt;

&lt;p&gt;And don’t forget your 5 stars ranking ;)&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>We are SeedCamp Finalists!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/11/30/we-are-seedcamp-finalists/"/>
   <updated>2012-11-30T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/11/30/we-are-seedcamp-finalists</id>
   <content type="html">&lt;p&gt;Hey, we are thrilled to announce our nomination among the &lt;a href=&quot;http://www.rudebaguette.com/2012/11/30/here-are-the-20-startups-selected-for-seedcamp-paris/&quot;&gt;Seedcamp Paris
finalists&lt;/a&gt;! The event will take place next week on Monday,
just before &lt;a href=&quot;http://paris.leweb.co/&quot;&gt;LeWeb 2012&lt;/a&gt; (by the way we’ll be there,
feel free to ping us if you’d like to meet).&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/seedcamp.png&quot; alt=&quot;Seedcamp Finalists&quot; /&gt;&lt;/p&gt;

&lt;p&gt;From what we learned from all over the place, the day’s mentorship alone is
worth it. We’re now fully committed to the event preparation! I’ll try to
write a followup post with our impressions.&lt;/p&gt;

&lt;p&gt;[Edit 15-Jan-2013] Here it is with some &lt;a href=&quot;http://blog.algolia.com/seedcamp-tips-and-advice-from-a-finalist/&quot;&gt;tips and
advice&lt;/a&gt;
[/Edit]&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Why Autocomplete in Twitter Mobile App Sucks</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/11/29/why-autocomplete-in-twitter-on-mobile-sucks/"/>
   <updated>2012-11-29T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/11/29/why-autocomplete-in-twitter-on-mobile-sucks</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/11/ScreenshotTwitter.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/ScreenshotTwitter.png&quot; alt=&quot;A better Twitter mobile app experience with Algolia
Search.&quot; /&gt;&lt;/a&gt;Autocomplete is so
intuitive,that it seems like it would be easy to implement. However, most
mobile apps that offer it provide a pretty poor user experience. Let’s look at
the Twitter mobile app as an example.&lt;/p&gt;

&lt;p&gt;Twitter proposes autocompletion when you create a new tweet. The idea is to
make suggestions after the ‘#’ and ‘@’ characters. It’s actually very nice to
gain time, especially when you’re tweeting with a small virtual keyboard…
but it sucks!&lt;/p&gt;

&lt;h2 id=&quot;avoid-roundtrips-to-server-for-autocompletion&quot;&gt;Avoid Roundtrips to Server for Autocompletion&lt;/h2&gt;

&lt;p&gt;The first reason is that when you’re on the go, latency is often too high on
mobile, leading to unusable autocomplete -  except if you’re very slow to
type. Twitter developers chose to develop this functionality server-side,
probably with lucene, and to expose it via APIs to their mobile app. That’s
good for reusability but not so much for usability…&lt;/p&gt;

&lt;h2 id=&quot;beware-of-the-suggestions-ranking&quot;&gt;Beware of the Suggestions Ranking&lt;/h2&gt;

&lt;p&gt;The second reason is the ranking is just obscure. Yesterday I sent a tweet to
@cocoanetics and the screenshot on the left shows the suggestions I got when
typing “@c”. I would greatly prefer to see Twitter handles before names and it
would never come to my mind to look for “Marie Cecile” with “@c”!&lt;/p&gt;

&lt;h2 id=&quot;explain-the-matches&quot;&gt;Explain the Matches&lt;/h2&gt;

&lt;p&gt;Last but not least there is no visual feedback to show me why the app proposes
a given user. So ok let me think… the ‘c’ was reffering to “Cécile” in
“Marie-Cécile”! A bit far fetched!&lt;/p&gt;

&lt;p&gt;Now let’s imagine the Twitter mobile app with instant autocompletion even
offline, intuitive ranking, and visual feedback… Appealing, isn’t it?
Twitter if you listen, check it up, I’m sure you’ll love &lt;a href=&quot;http://www.algolia.com/product/&quot;&gt;Algolia
Search&lt;/a&gt;!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search is Out!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/11/21/algolia-search-is-out/"/>
   <updated>2012-11-21T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/11/21/algolia-search-is-out</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/11/hand.jpg&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/hand-203x300.jpg&quot; alt=&quot;Now introducing Algolia Search&quot; /&gt;&lt;/a&gt;After 4 betas and much priceless feedback, we
are really excited to announce the release of Algolia Search! We launched it
Monday during the 60th edition of &lt;a href=&quot;http://algolia.us5
.list-manage1.com/track/click?u=4cb821b85eca457f3c8a4df2f&amp;amp;id=c46402f441&amp;amp;e=df9a
44f8b5&quot;&gt;Mobile Monday Paris&lt;/a&gt;! If you don’t know what Algolia Search can do for your app, take a
look at its &lt;a href=&quot;http://www.algolia.com/product/&quot;&gt;amazing features&lt;/a&gt; or just watch
the &lt;a href=&quot;http://www.algolia.com/?video=1&quot;&gt;video&lt;/a&gt;!&lt;/p&gt;

&lt;p&gt;This release also means that you can now integrate it directly into your apps
and publish them! We wanted to have a simple and clear pricing plan: You can
have all the benefits of Algolia Search in one Android or iOS App for only
$590! Think about it, that’s less than the day-rate of a mobile developer in
many countries. Compare it to the many days you would need to integrate SQL
Lite FTS for poor features.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://www.algolia.com/try/&quot;&gt;Try Algolia Search for free&lt;/a&gt; for 30-days!&lt;/p&gt;

&lt;p&gt;We are also very excited to introduce our new
&lt;a href=&quot;http://www.algolia.com&quot;&gt;website&lt;/a&gt; alongside this launch. You’ll be able to
access up-to-date documentation easily, to &lt;a href=&quot;http://www.algolia.com/try/&quot;&gt;try and
download&lt;/a&gt; Algolia Search in a few clicks and, of
course, to order the product! Check it out and let us know what you think!&lt;/p&gt;

&lt;p&gt;Thanks again to our beloved beta testers. Stay tuned for more news!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>The Ordeal of Obtaining an Apple Developer Professional Account</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/11/12/the-ordeal-of-obtaining-an-apple-developer-professional-account/"/>
   <updated>2012-11-12T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/11/12/the-ordeal-of-obtaining-an-apple-developer-professional-account</id>
   <content type="html">&lt;p&gt;I recently had a pretty bad user experience when I upgraded my personal Apple
developer account into a professional one.&lt;/p&gt;

&lt;p&gt;To sum things up, we officially created Algolia in early October and I decided
to convert my personal Apple Developer Account in order to have our
applications published under the “Algolia” name. This process is not available
online, but after a quick call, people at Apple sent me the link for the
process. It is actually pretty simple: They just need you to fill some
information about your company and to accept their EULA.&lt;/p&gt;

&lt;p&gt;Well, actually some of this information was pretty obscure. They needed our
D-U-N-S® number… Some time ago, Apple was doing the job of checking that
your company is a real one, but they decided to delegate this job to an
external company (D&amp;amp;B). It looks like a good idea, doesn’t it? After all this
is not their core competency and D&amp;amp;B may be doing a really good job for this
task…&lt;/p&gt;

&lt;p&gt;The short answer is no, it wasn’t a good idea at all! I started to check how
to get this famous D-U-N-S® and after some time to understand the antiquated
website of D&amp;amp;B, I finally found the contact address. One week later I finally
received our D-U-N-S®. But that’s not all, Apple then asked us to wait for the
synchronization between D&amp;amp;B and Apple… which can take up to 14days!&lt;/p&gt;

&lt;p&gt;Hey guys, I don’t know if you realize how this is ridiculous to wait 14 days
for a simple database synchronization! You have just no idea what 14 days
means for a young startup :)&lt;/p&gt;

&lt;p&gt;As you can imagine, I was already quite frustrated… but this was just the
beginning. After the 14 days, Apple recognized the DUNS number… but a field
was missing. They didn’t have the legal type of our company. They then asked
me to contact D&amp;amp;B and a new nightmare started at this level: D&amp;amp;B was saying
that the entry was correct while Apple was asking me to contact D&amp;amp;B to correct
the entry! There’s nothing worst than to stand be between two big companies
who pass the buck to each other.&lt;/p&gt;

&lt;p&gt;Hopefully Apple was far smarter than D&amp;amp;B and they finally accepted to bypass
the missing field if I sent them directly our legal documents.&lt;/p&gt;

&lt;p&gt;It is crucial to pay attention to all your users’ problems and solve them as
soon as possible. They may sometimes look like details to you, but that’s what
your customers will remember about your company. Of course, we try to apply
this lesson to ourselves. Feel free to tell us if something’s going wrong!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Painless integration, crystal clear documentation, please welcome Algolia Search beta 4!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/10/19/painless-integration-crystal-clear-documentation-please-welcome-algolia-search-beta-4/"/>
   <updated>2012-10-19T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/10/19/painless-integration-crystal-clear-documentation-please-welcome-algolia-search-beta-4</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com
/wp-content/uploads/2012/10/CitiesSuggestIPhone5Slide3.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/CitiesSuggestIPhone5Slide3-300x194.png&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Last month has been truly electrifying! We joined our friends at
&lt;a href=&quot;http://www.yakaz.com/&quot;&gt;Yakaz&lt;/a&gt; in their office space, we participated in many
events… and most exciting of all, we spent days and nights reworking the
product! Today we are really proud to present you the result of this time well
spent!&lt;/p&gt;

&lt;p&gt;I know I told some of you beta3 would be the last, but we could not ignore
your excellent feedback. So here comes Algolia Search beta4, a true revolution
(I hope this is not trademarked!) in mobile search!&lt;/p&gt;

&lt;p&gt;Here come the major improvements:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A completely &lt;strong&gt;reworked API&lt;/strong&gt; that we just love to use everywhere. The time to fully understand the library has been reduced to nearly nothing thanks to all your feedback. We are proud to have the easiest to use search library ever made!&lt;/li&gt;
  &lt;li&gt;A completely &lt;strong&gt;rewritten documentation&lt;/strong&gt; with detailed API and step-by-step tutorials. You should be able to make your first queries in a matter of minutes!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Easy highlight&lt;/strong&gt; for &lt;strong&gt;multiple fields queries&lt;/strong&gt;. A bit cryptic? Stay with me… just imagine a Contact application where you can search for your contact by any field, i.e., name, company, address or even notes. Algolia Search now provides easy-to-use highlighting of any matching words. It is even able to generate a snippet when the text is too long. Check out the tutorials to learn more! Highlighting relevant results just became child’s play!&lt;/li&gt;
  &lt;li&gt;A greatly &lt;strong&gt;improved out-of-the-box relevance&lt;/strong&gt;. Our mission is to simplify search: we want the best possible relevance by default so you can forget these long hours of tuning :)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;But that’s not all, many smaller improvements were also included in this
release:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Support of &lt;strong&gt;advanced queries&lt;/strong&gt;. Take again our tutorial contact application, wouldn’t it be great to be able to search by initials? You can now implement this cool feature in a couple of minutes without any headache on relevance tuning.&lt;/li&gt;
  &lt;li&gt;Support for &lt;strong&gt;ARC and no ARC&lt;/strong&gt;. In the previous beta we added an iOS version for people that do not use &lt;a href=&quot;http://developer.apple.com/library/mac/#releasenotes/ObjectiveC/RN-TransitioningToARC/Introduction/Introduction.html&quot;&gt;Automatic Reference Counting (ARC)&lt;/a&gt;. We now have only one version that supports projects with and without ARC. If you do not use ARC, all objects received from Algolia Search are autoreleased.&lt;/li&gt;
  &lt;li&gt;Support for &lt;strong&gt;user objects backward compatibility&lt;/strong&gt;. As the index is also an objects store, you can modify your object members and still read older indexes! It is very easy to implement, just check the tutorials.&lt;/li&gt;
  &lt;li&gt;The release also fixes a few bugs that we discovered during your and our intensive testing.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It would not have been possible without the help of our many beta testers,
thank you all! Special thanks to &lt;a href=&quot;https://twitter.com/krmarkel&quot;&gt;Kris&lt;/a&gt;,
&lt;a href=&quot;https://twitter.com/dinh_viet_hoa&quot;&gt;Hoa&lt;/a&gt; and
&lt;a href=&quot;https://twitter.com/sarfata&quot;&gt;Thomas&lt;/a&gt; whose guidance has been priceless.&lt;/p&gt;

&lt;p&gt;So… what’s next? Many things! This time I really believe this is the last
beta. The final release is just around the corner. Of course, we appreciate
your feedback nonetheless and always will! You can also expect a new website
and a few apps in the app store! Who said a contact app?&lt;/p&gt;

&lt;p&gt;Stay tuned!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>A few thoughts after Apps World</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/10/07/a-few-thoughts-after-apps-world/"/>
   <updated>2012-10-07T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/10/07/a-few-thoughts-after-apps-world</id>
   <content type="html">&lt;p&gt;Last week provided me with an occasion to feel the tempo of the mobile
ecosystem at Apps World in London. Here are a few thoughts about what I saw.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/appsworld-300x224.jpg&quot; alt=&quot;&quot; /&gt;There were many many mobile agencies
exhibiting… and local UK agencies were dwarfed in number by offshore ones,
hailing mainly from India. Eastern European countries also had an important
presence, especially Poland. It seems that the golden days of apps development
are behind us. Most big companies now outsource their apps offshore. It also
means that it’s becoming very important for local agencies to differentiate
themselves. I actually pitched many of them about Algolia Search and
differences in reactions were interesting. Most Indian based agencies didn’t
have a second look; They preferred to wait for “requirements” from their
customers. On the other hands European ones were on average much more
interested in what they could do with such a lib. The most geniune interest
always came from technical guys when they were present. By the way, if I could
give advice to any agency participating in such a event, please come with at
least a developer, and at best your CTO. You would gain much credibility and
differentiation!&lt;/p&gt;

&lt;p&gt;Out of all of the agencies, a few other disciplines were well represented…
actually I may say “too much” represented as it often indicates an over-
crowded field and a battle for survival!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Testing and QA services&lt;/strong&gt;. Offshore Indian firms are also very active in this space.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ad platforms and payment tools&lt;/strong&gt;. I didn’t know there were so many options to choose from! Competition seemed harsh to get the attention of the few apps developers attending.&lt;/li&gt;
  &lt;li&gt;And most of all &lt;strong&gt;cross-platform HTML5 frameworks&lt;/strong&gt;! I’m not a big fan of PhoneGap and consorts, even if I admit it’s a good choice for some apps, especially “enterprise” ones. The space is so crowded with offers now, that many may not survive the next year! By the way if you want to offer a framework and want to differentiate yourself with a cutting-edge search functionality, you know how to contact me ;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/blackberry-300x224.jpg&quot; alt=&quot;Blackberry at Apps World&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Two companies had a particularly important presence at the event compared to
what we could have expected:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;RIM&lt;/strong&gt;, with probably the nicest booth of all. They proposed BlackBerry porting classes, offered developer guidance and gave several workshop speeches. After their recent commitment to &lt;a href=&quot;http://devblog.blackberry.com/2012/09/built-for-blackberry-10k-developer-commitment/&quot;&gt;paying BlackBerry 10 developers a minimum of $10K&lt;/a&gt;, they continue to do all they can to attract developers. But I’m afraid I agree with Charlie Kindel that &lt;a href=&quot;http://ceklog.kindel.com/2012/09/26/paying-developers-is-a-bad-idea/&quot;&gt;paying developers is a bad idea&lt;/a&gt;!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Twilio&lt;/strong&gt;, actively promoting their voice and SMS APIs. Their immense success reminds us that there are still billions of feature phones out there!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The other less surprising major players included Samsung and Microsoft, but no
Google and no Apple (not unexpected!). Of course, they were present in many
conversations! I had for example a very interesting chat with &lt;a href=&quot;http://twistedhq.com&quot;&gt;Adam
Hościło&lt;/a&gt; about the many opportunities provided by the
new iOS 6 Passbook. It’s opening a golden area for many in the next few
months!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Upcoming Mobile App Conferences: Apps World, Mobility for Business, Appdays</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/09/28/upcoming-events-appsworld-mobility-for-business-appdays/"/>
   <updated>2012-09-28T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/09/28/upcoming-events-appsworld-mobility-for-business-appdays</id>
   <content type="html">&lt;p&gt;With the summer behind us, the period is pretty active. It’s really difficult
to attend all the great events, big and small, organized out there. After
&lt;a href=&quot;http://www.mobilemondayfrance.org/&quot;&gt;Mobile Monday&lt;/a&gt;,
&lt;a href=&quot;http://france.thefailcon.com/&quot;&gt;Failcon&lt;/a&gt; and the first meeting of
&lt;a href=&quot;http://appsterdam.rs/&quot;&gt;Appsterdam&lt;/a&gt; Paris this week, here are the major mobile
app conferences we’re attending in the next few weeks!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.apps-world.net/europe/&quot;&gt;Appsworld&lt;/a&gt;, the 2nd and 3rd of October in London. It’s a major event attended by lot of mobile industry professionals. There are expecting up to 5000 participants!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://www.mobility-for-business.com/&quot;&gt;Mobility for business&lt;/a&gt;, the 11th and 12th of October in Paris. A big event too, they are expecting about 3000 attendees!&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;http://appdays.fr/&quot;&gt;Appdays&lt;/a&gt;, the 9th of November in Paris. A more human sized event (200 participants) and definitely a place to be!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If you happen to participate to one of these, get in touch for some passionate
discussion around mobile apps development!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search Beta 3 is out!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/09/24/algolia-search-beta-3-is-out/"/>
   <updated>2012-09-24T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/09/24/algolia-search-beta-3-is-out</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/09/CitiesSuggestIOSPortraitSmall.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/CitiesSuggestIOSPortraitSmall-155x300.png&quot; alt=&quot;Algolia Search Beta 3&quot; /&gt;&lt;/a&gt;We are pleased to
announce Algolia Search Beta 3, our third release with a strong focus on
performance.&lt;/p&gt;

&lt;p&gt;As for the previous release, we would like to sincerely thank all of our beta
testers for their excellent feedbacks!&lt;/p&gt;

&lt;p&gt;Here what’s new in this beta3.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;iOS &amp;amp; Android changes:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ultra fast loading&lt;/strong&gt;: indexes are now loaded in a few milliseconds (always less&lt;br /&gt;
than 10ms!)  With the Beta 2, an index of 500MB could take up to 20 seconds to
load.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ultra fast search on big indexes&lt;/strong&gt;: Beta 2 was able to search up to 100k entries&lt;br /&gt;
in real time. Beta3 can search in &lt;strong&gt;5M entries in real time&lt;/strong&gt; (and probably&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;more!). Our main use case was to search in all titles of the English version
of&lt;/p&gt;

&lt;p&gt;Wikipedia on a IPhone 3GS. The speedup is also very nice for small datasets,&lt;/p&gt;

&lt;p&gt;the near-zero CPU usage increases battery life compared to Beta 2.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Highlight is now always done on longest match. In previous version a query ‘anq’ could highlight “Angeles” in&lt;br /&gt;
two different ways: “&lt;strong&gt;Ang&lt;/strong&gt;eles” or “&lt;strong&gt;An&lt;/strong&gt;geles”, with this version you will
always obtain “&lt;strong&gt;Ang&lt;/strong&gt;eles” which is easier to&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;understand for end-users.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Improved proximity scoring when a query contains multiple words.&lt;/li&gt;
  &lt;li&gt;Fixed two memory leaks that could lead to problems with very heavy usage.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;iOS specific changes:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Added a version without ARC that allows to target iOS &amp;gt;= 3.0&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search Beta 2 is out!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/09/03/algolia-search-beta-2-is-out/"/>
   <updated>2012-09-03T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/09/03/algolia-search-beta-2-is-out</id>
   <content type="html">&lt;p&gt;We are pleased to announce the launch of Algolia Search Beta 2, our second
release!&lt;/p&gt;

&lt;p&gt;We would like to sincerely thank all of our beta testers for the great
feedback. You really helped us to make Algolia Search a first-class product
guys! Please continue your feedbacks!&lt;/p&gt;

&lt;p&gt;And here what’s new in this beta2.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;iOS &amp;amp; Android changes:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Improved performance for big data sets (up to three times faster). In our tests, we successfully used a 3 millions entries data set on a old iPhone 3GS. The index was 250MB large!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Documentation changes:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Reworked the overview&lt;/li&gt;
  &lt;li&gt;Fixed a lot of typos and small errors&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;iOS specific changes:&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Added an AlgoliaSearch.h header that includes all public headers&lt;/li&gt;
  &lt;li&gt;Prefixed all public classes by AS&lt;/li&gt;
  &lt;li&gt;Changed addEntry selector in ASIndexWriter to be more similar to NSMutableDictionary API&lt;/li&gt;
  &lt;li&gt;Removed internal objects from public headers&lt;/li&gt;
  &lt;li&gt;Changed ASAsyncIndexSearcher API to implement the delegate pattern&lt;/li&gt;
&lt;/ul&gt;

</content>
 </entry>
 
 <entry>
   <title>Results of the Evernote DevCup</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/08/22/results-of-the-evernote-devcup/"/>
   <updated>2012-08-22T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/08/22/results-of-the-evernote-devcup</id>
   <content type="html">&lt;p&gt;Time flies! I just realized we didn’t offer any feedback about our
participation in the Evernote DevCup back in July.&lt;/p&gt;

&lt;p&gt;First of all, thank you so much for your support! We ranked 14th out of 174
contestants in public voting! That actually exceeded our expectations as we
aimed for the 20th position (so drinks are on Julien!)&lt;/p&gt;

&lt;p&gt;But even with all of your support, we didn’t make it to the finals. We would
have loved to fly to San Francisco, but the &lt;a href=&quot;http://blog.evernote.com/2012/07/27/announcing-the-2012-evernote-devcup-finalists/&quot;&gt;six
finalists&lt;/a&gt; all feature rich apps that merit their position. Congrats
guys, and good luck! The conference is in a couple of days now, and I can’t
wait to find out who will win the cup!&lt;/p&gt;

&lt;p&gt;As for us, it was a truly great experience! Remember our
&lt;a href=&quot;http://blog.algolia.com/were-participating-to-the-evernote-devcup/&quot;&gt;post&lt;/a&gt;
announcing our participation? Well, outside the &lt;em&gt;slight&lt;/em&gt; frustration of not
going to SF, the couple of days we spent building the Search for Evernote app
was really worth it!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;We were able to correct a few corner case bugs which this new use case highlighted. It’s always better to find them yourself than let app developers stumble upon them :)&lt;/li&gt;
  &lt;li&gt;We developed a new feature enabling prefix search on all words.&lt;/li&gt;
  &lt;li&gt;Our participation led to an improved awareness of the company and helped our SEO.&lt;/li&gt;
  &lt;li&gt;We created a new demo of the search lib which is much more compelling than Cities Suggest in many situations. It is actually a bit more than a demo for some people - as of today, it has 317 active users on google play!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;That got us thinking… we may do this kind of contest again. But this time
we’ll aim higher!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Algolia Search beta is out!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/08/16/algolia-search-beta-is-out/"/>
   <updated>2012-08-16T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/08/16/algolia-search-beta-is-out</id>
   <content type="html">&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/08/searchForEvernoteSmall.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/searchForEvernoteSmall.png&quot; alt=&quot;&quot; /&gt;&lt;/a&gt;After a few months in the
making, our first mobile library is finally ready to hit the shelves! Well,
nearly! Before releasing it, we want all the feedback you can give us to
ensure it’s bug-free, easy to use and responsive to your needs.&lt;/p&gt;

&lt;p&gt;If you subscribed to the beta, you should already have received your access
info. If not, you can request it directly on www.algolia.com.&lt;/p&gt;

&lt;p&gt;You’ll be able to download both the iOS and the Android versions, along with
all necessary documentation. Feel free to ask for any clarification or
additional info. We’ll do a few technical posts which explore the product
internals in the coming months.&lt;/p&gt;

&lt;p&gt;We’re now eager to read your feedback! You just have one address to remember
to report bugs, request features, or anything beta related: beta@algolia.com&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Free marketing @ WWDC 2012!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/08/01/free-marketing-wwdc2012/"/>
   <updated>2012-08-01T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/08/01/free-marketing-wwdc2012</id>
   <content type="html">&lt;p&gt;Let’s rewind time a bit. Back in June was the famous Apple Developer
Conference, aka WWDC 2012. Algolia didn’t even have a website at that time,
but what we did have is a friend who would attend:
&lt;a href=&quot;https://twitter.com/sarfata/&quot;&gt;Thomas&lt;/a&gt;! That was an occasion we could not
pass!&lt;/p&gt;

&lt;p&gt;Thomas agreed to speak about us a bit and to invite people to visit our
website. That simple action defined our deadline to have a website up and
running. But wait! That would be better if people could also find the site
when Googling our company name. That meant a few days to allow for indexing…
and a tight deadline!&lt;/p&gt;

&lt;p&gt;About two weeks of brainstorming and implementation went into the &lt;a href=&quot;http://www.algolia.com&quot;&gt;web
site&lt;/a&gt;. Our goal was to have a clear presentation of
our mobile search lib… and to be found on Google! And you know what? It’s
damn difficult to do so in so short a time! Our site was up and running two
days before the conf and we immediately submitted it to all search engines.
Unfortunately we were not in first position when Googling for Algolia :(&lt;/p&gt;

&lt;p&gt;Fortunately, things improved without delay. Two actions were particularly
useful in helping our search rankings: our participation to the &lt;a href=&quot;http://blog.algolia.com/were-participating-to-the-evernote-devcup/&quot;&gt;Evernote
DevCup&lt;/a&gt;,
and our blog opening! We quickly got the pole position for our brand and
started to rank well for some key queries like &lt;a href=&quot;https://www.google.com/search?q=mobile+instant+suggest&quot;&gt;mobile instant
suggest&lt;/a&gt; :)&lt;/p&gt;

&lt;p&gt;We also thought about creating some posters that explain our technology, but
eventually we were so concentrated on the web site that we passed.&lt;/p&gt;

&lt;p&gt;Result: Some awareness, one subscription to beta and more importantly, a
running website! Next marketing related action would be to have a demo ready
for LeWeb in London, but that’s &lt;a href=&quot;http://blog.algolia.com/great-discussions-at-leweb12-london/&quot;&gt;another story&lt;/a&gt;…&lt;/p&gt;

&lt;p&gt;And here is what you could see on WWDC whiteboards:&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/07/wwdc1.jpg&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/wwdc1.jpg&quot; alt=&quot;WWDC Message 1&quot; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/07/wwdc2.jpg&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/wwdc2.jpg&quot; alt=&quot;WWDC Message 2&quot; /&gt;&lt;/a&gt;Thank you again for your help Thomas!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>C/C++ is still the only way to have high performance on Mobile</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/24/need-performance-on-mobile-use-c-cpp/"/>
   <updated>2012-07-24T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/24/need-performance-on-mobile-use-c-cpp</id>
   <content type="html">&lt;p&gt;When it comes to programming languages and performance, you can read all and
its opposite on the web. It’s definitely a very controversial topic!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;[Edit 15-Nov-2012]&lt;/strong&gt; I had questions on &lt;a href=&quot;http://redd.it/136hny&quot;&gt;reddit&lt;/a&gt; about the data-structures and algorithms we used. We develop an &lt;a href=&quot;http://www.algolia.com&quot;&gt;embedded search engine&lt;/a&gt; for mobile, and tests were done on our own data-structure that is far more efficient than SQLite or other platform options for this use-case. &lt;strong&gt;[/Edit]&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For Algolia the story started when researching an instant suggest algorithm. I
used Java for two reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Main reason&lt;/strong&gt;: our first client was using Java on Google App Engine&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Secondary&lt;/strong&gt;: at that stage, I was doing a lots of refactoring and Eclipse is very efficient for these tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Once our algorithm was designed, I started to optimize performance on a
desktop computer (core I7 950). For this, I indexed all titles of the English
version of Wikipedia (4 millions titles). I optimized the Java code mainly by
reducing the number of allocations. All instant suggest queries were then
faster than 10ms.&lt;/p&gt;

&lt;p&gt;As we planned from the begining to support iOS and Android, I needed to
optimize for high performance on mobile. I then ported the Java code to
Android and ended up with a few modifications (we needed to support old
Android versions which have not a full support of Java SDK).&lt;/p&gt;

&lt;p&gt;In order to test performance, I created a small “demo” app: CitiesSuggest, a
mobile application based on Geonames database to look for a city name. I
filled the index with all places with a known population. In the end, the
database contained 270 000 city names.&lt;/p&gt;

&lt;p&gt;As could be expected, the resulting application was quite sluggish on my
Galaxy S2. The worst queries could take more than one second of CPU.&lt;/p&gt;

&lt;p&gt;I then applied all possible methods described in the &lt;a href=&quot;http://developer.android.com/guide/practices/performance.html&quot;&gt;Anroid
documentation&lt;/a&gt;
and was able to reduce the response time to 700ms for the longest queries.
This is better but still gives end-users an impression of sluggishness!
Fortunately, common queries worked well enough to present our very first demos
at &lt;a href=&quot;http://blog.algolia.com/great-discussions-at-leweb12-london/&quot;&gt;LeWeb’12 London&lt;/a&gt;. I was subsequently able to improve the user experience a lot
by adding asynchronous support. At that point, we decided to start
implementing the objective-C version for iOS.&lt;/p&gt;

&lt;p&gt;I started a new implementation fully done in objective-C from scratch without
any premature optimization. I then developed the same CitiesSuggest
application for iOS. I first got stuck with some basic UI stuff. For example I
needed to reimplement an UILabel that supports highlighting! The standard
UILabel does no support this, and other implementations like Three20 just have
too many dependencies (you can download AlgoliaUILabel on
&lt;a href=&quot;http://github.com/algolia/UILabel&quot;&gt;github&lt;/a&gt;, I released  the code under Apache
licence). Once the UI was ready, I could see the actual performance was
catastrophic! Instant suggest queries were between 200ms and 10 seconds on an
iPhone 4S!&lt;/p&gt;

&lt;p&gt;After profilling, I discovered that 95% of the time was spent in Objective-C
messaging and ARC. Actually, I have millions of calls to very small methods
with 1 or 2 lines of code, and I found a very good explanation in the internal
of objc_msgSend (mainly on &lt;a href=&quot;http://www.mikeash.com/pyblog/friday-qa-2009-03-20-objective-c-messaging.html)&quot;&gt;mikeask.com&lt;/a&gt;. There is in fact a hash table
lookup behind objc_msgSend! This explains most of my performance problems.&lt;/p&gt;

&lt;p&gt;To fix these problems, I started to replace all this low level objective-C
implementation by a C++ implementation with inlined methods. Eventually, I
finished with Objective-C code for high level classes while all the core was
C++.&lt;/p&gt;

&lt;p&gt;This change has dramatically improved performance with instant-search queries
between 2ms and 90ms on a iPhone 4S. I struggled to find complex enough
queries to reach 90ms! This resulted in a very nice user experience with a
remarkably slick demo :)&lt;/p&gt;

&lt;p&gt;After this succes, I decided to use the same C++ code on Android with Android
NDK. With this approach I reduced our maximum query time from 700ms to 80ms on
a Galaxy S2. But I was really disappointed by the Android display, as I did
not reach the same level of interactive experience that I had with iOS. The
display of results stays slower on Android, probably because I did not spend
enough time to optimize this part.&lt;/p&gt;

&lt;p&gt;In the end, I lost a lot of time with Java and Objective-C trying to optimize
code when the real solution was to use C/C++. I am fully convinced that it is
just not possible to reach the same speed with Objective-C only or Java only.&lt;/p&gt;

&lt;p&gt;And there is also another good property with C++ code: Blackberry supports
C++, and there is large chance that Windows Phone 8 SDK will support C++ when
released in a few weeks. Actually, I do not see any other alternative than
C/C++ when you are looking for performance on mobile devices, which is our
case :)&lt;/p&gt;

&lt;p&gt;I hope this article will prevent you from spending as much time on
Java/Objective-C optimizations as I did.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>iOS: When Automatic Reference Counting is a Bad Idea</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/12/ios-when-arc-is-a-bad-idea/"/>
   <updated>2012-07-12T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/12/ios-when-arc-is-a-bad-idea</id>
   <content type="html">&lt;p&gt;I started developing for iOS in 2009 by learning about the Objective-C
language. At that time ARC (Automatic Reference Counting) was not yet
available and developers were responsible for alloc/release/autorelease. I
found it pretty straightforward as it was very similar to C++ and the
resulting code was very self-explanatory.&lt;/p&gt;

&lt;p&gt;When ARC was released at the end of 2011 it made a great impression on me and
looked like the perfect feature for any programmer coming from the Java world
who was not familiar with memory management. I started using ARC and
discovered a major flaw that completely changed my mind. Here is an example :&lt;/p&gt;

&lt;p&gt;[Edit 28-Jan-2013] This post describes a bug in ARC that was fixed in Xcode
4.4.[/Edit]&lt;/p&gt;

&lt;p&gt;Let’s start with an example in C++, the sample contains a constructor that
allocates two vectors, a destructor that destroys them and a compute method
that just performs a swap between the two vectors. This code is perfectly
valid and a swap is the perfect operation when you have two sets of data to
maintain because this is very efficient (just two pointers copy, no data
copy).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;class Example {
public:
  Example() {
    nextPositions = new std::vector&amp;lt;int&amp;gt;();
    currentPositions = new std::vector&amp;lt;int&amp;gt;();
  }
  ~Example() {
    delete nextPositions;
    delete currentPositions;
  }

  void compute() {
    // some code here
    std::swap(nextPositions, currentPositions);
    // some other code here
  }

private:
  std::vector&amp;lt;int&amp;gt;* nextPositions;
  std::vector&amp;lt;int&amp;gt;* currentPositions;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Before ARC the objective-C code was very similar and perfectly valid:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// headers
@interface Example : NSObject {
  NSMutableArray* nextPositions;
  NSMutableArray* currentPositions;
}
-(void) compute;
@end

// implementation
@implementation Example
-(id) init {
  self = [super init];
  if (!self)
    return nil;
  nextPositions = [[NSMutableArray alloc] init];
  currentPositions = [[NSMutableArray alloc] init];
  return self;
}

-(void) dealloc {
  [super dealloc];
  [nextPositions release];
  [currentPositions release];
}

-(void) compute
{
  // some processing stuff here
  NSMutableArray* tmp = nextPositions;
  nextPositions = currentPositions;
  currentPositions = tmp;
  // some processing stuff here
}
@end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The semantics are very clear, it is exactly the same as in C++.&lt;/p&gt;

&lt;p&gt;So when you start using ARC you tend to do exactly the same thing with less
code, and you just delete the dealloc method:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// headers
@interface Example : NSObject {
  NSMutableArray* nextPositions;
  NSMutableArray* currentPositions;
}
-(void) compute;
@end

// implementation
@implementation Example
-(id) init {
  self = [super init];
  if (!self)
    return nil;
  nextPositions = [[NSMutableArray alloc] init];
  currentPositions = [[NSMutableArray alloc] init];
  return self;
}

-(void) compute {
  // some processing stuff here
  NSMutableArray* tmp = nextPositions;
  nextPositions = currentPositions;
  // Wrong, at that step this is too late! nextPositions was deallocated
  currentPositions = tmp;
  // some processing stuff here
}
@end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The error does not come from a missing strong attribute, because instance
variables are strong by default. The problem is that ARC does not generate
code in the variable assignation. You should explicitely add properties and
use “self.variableName” notation like in the next example. I would encourage
ARC designers to read this excellent article by Joel Spolsky &lt;a href=&quot;http://www.joelonsoftware.com/articles/Wrong.html&quot;&gt;“Making Wrong
Code Look Wrong”&lt;/a&gt;. This ARC
usage is a perfect example of wrong code that looks perfect but leads me to
the conclusion that ARC is not trustworthy.&lt;/p&gt;

&lt;p&gt;Here is the correct version:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;// headers
@interface Example : NSObject {
  NSMutableArray* nextPositions;
  NSMutableArray* currentPositions;
}
-(void) compute;
@property (strong, nonatomic) NSMutableArray* nextPositions;
@property (strong, nonatomic) NSMutableArray* currentPositions;
@end

// implementation
@implementation Example
-(id) init {
  self = [super init];
  if (!self)
    return nil;
  nextPositions = [[NSMutableArray alloc] init];
  currentPositions = [[NSMutableArray alloc] init];
  return self;
}

-(void) compute {
  // some processing stuff here
  NSMutableArray* tmp = self.nextPositions;
  self.nextPositions = self.currentPositions;
  self.currentPositions = tmp;
  // some processing stuff here
}
@synthesize nextPositions;
@synthesize currentPositions;
@end
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am surprised Apple hasn’t corrected that flaw yet. This is a major issue as
ARC does not generate code for variable affectation like it does for
properties (if one of you reads this post and has a complete explanation,
please tell me!):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Is it because of a performance issue? I would prefer to have no ARC at all than to see such a behavior.&lt;/li&gt;
  &lt;li&gt;Is this case too complex to be handled? The problem is it undermines ARC’s utility and might get stuck at the prototype stage.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;To me, this is a perfect example of a technology driven product. The engineers
know their product so well that they forget to step back and look at it with a
fresh eye to analyse the full complexity of their system.&lt;/p&gt;

&lt;p&gt;And that leaves me with two important lessons we’ll try to apply to our
products:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Always organize user tests, even when your users are developers themselves!&lt;/li&gt;
  &lt;li&gt;Always keep a fresh eye when trying to simplify a product (this one may prove particularly difficult!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;I hope you’ll tell us when we will (inevitably) break these rules!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Search for Evernote: We're in the Evernote DevCup!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/08/were-participating-to-the-evernote-devcup/"/>
   <updated>2012-07-08T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/08/were-participating-to-the-evernote-devcup</id>
   <content type="html">&lt;p&gt;You mint already be familiar with Evernote. It’s a great company that delivers
an impressive product that I use often, both professionally and personally.
When we heard about them organizing their second developer competition, we
immediately thought about the fantastic opportunity it could be for Algolia!&lt;/p&gt;

&lt;p&gt;Let’s sum up:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;It’s an excellent use case for our first lib: search in Evernote mobile apps is quite awful and we could really bring a better user experience!&lt;/li&gt;
  &lt;li&gt;It’s a good incentive to create a second demo (after Cities Suggest) that’s more convincing, especially for Evernote’s users.&lt;/li&gt;
  &lt;li&gt;It’s an opportunity to get some media coverage :)&lt;/li&gt;
  &lt;li&gt;And most of all it’s an excellent occasion to pitch our lib to the Evernote team. We would love to have them as an happy customer!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you see, even if we don’t make it to the finals, the decision was a no-
brainer! But, wait… we’d love to go to the finals! &lt;strong&gt;And you can help us!&lt;/strong&gt;
Part of the competition is to get the maximum public support. You want to hep
us? Just go to our &lt;a href=&quot;http://devcup.evernote.com/submissions/8585-search-for-evernote&quot;&gt;submission
page&lt;/a&gt; and
vote once a day! Tell your friends! Tell your grandma! You can even log in via
facebook ;)&lt;/p&gt;

&lt;p&gt;Want to know more about our app “Search for Evernote”? Here comes the video.
You can also download the app directly from
&lt;a href=&quot;http://www.algolia.com/evernote.html&quot;&gt;http://www.algolia.com/evernote.html&lt;/a&gt;&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Why develop our own Unicode Library? - The Algolia Blog</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/05/why-develop-our-own-unicode-library/"/>
   <updated>2012-07-05T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/05/why-develop-our-own-unicode-library</id>
   <content type="html">&lt;p&gt;At one time or another, most developers come across bugs or problems with
Unicode (about 3,720,000 results on google for the request &lt;a href=&quot;http://www.google.com/search?q=unicode+bug+developer&quot;&gt;unicode bug
developer&lt;/a&gt; at the time
of this writing). Let me tell you about my experience in the last decade and
why we have now implemented our own unicode Library to produce exactly the
same result across devices/languages.&lt;/p&gt;

&lt;p&gt;I first started to use Unicode in 2004 when I was developing a Text Mining
software specialized on information extraction. This software was fully
implemented in C++ and I used &lt;a href=&quot;http://www.google.com/url?q=ht
tp%3A%2F%2Fwww-01.ibm.com%2Fsoftware%2Fglobalization%2Ficu%2F&amp;amp;sa=D&amp;amp;sntz=1&amp;amp;usg=
AFQjCNHZa7RaPrYgI3i22oL77_ZBjvF4vw&quot;&gt;IBM ICU library&lt;/a&gt; to be Unicode compliant (all strings were
stored in UTF16). I also used some normalization functions of ICU based on
decomposition, but I did not notice any major problem at that time. I started
to understand the dark side of Unicode later when I used it in other languages
like Java, Python, and later in Objective-C. My first surprise was when I
understood that a simple isAlpha(unicodechar c) method can return different
results!&lt;/p&gt;

&lt;p&gt;I started to look in details at the standard and downloaded UnicodeData.txt
(the file that contains most of the information about the standard, you can
grab the latest version
&lt;a href=&quot;ftp://ftp.unicode.org/Public/UNIDATA/UnicodeData.txt)&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;This file contains descriptions of all Unicode characters. Third column
represents “General Category” and is documented as:&lt;/p&gt;

&lt;h2 id=&quot;general-categories&quot;&gt;&lt;strong&gt;General Categories&lt;/strong&gt;&lt;/h2&gt;

&lt;p&gt;The values in this field are abbreviations for the following. Some of the
values are normative, and some are informative. For more information, see the
Unicode Standard.&lt;/p&gt;

&lt;h4 id=&quot;normative-categories&quot;&gt;Normative Categories&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lu&lt;/strong&gt;: Letter, Uppercase&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ll&lt;/strong&gt;: Letter, Lowercase&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lt&lt;/strong&gt;: Letter, Titlecase&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mn&lt;/strong&gt;: Mark, Non-Spacing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mc&lt;/strong&gt;: Mark, Spacing Combining&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Me&lt;/strong&gt;: Mark, Enclosing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nd&lt;/strong&gt;: Number, Decimal Digit&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nl&lt;/strong&gt;: Number, Letter&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No&lt;/strong&gt;: Number, Other&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zs&lt;/strong&gt;: Separator, Space&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zl&lt;/strong&gt;: Separator, Line&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zp&lt;/strong&gt;: Separator, Paragraph&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cc&lt;/strong&gt;: Other, Control&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cf&lt;/strong&gt;: Other, Format&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cs&lt;/strong&gt;: Other, Surrogate&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Co&lt;/strong&gt;: Other, Private Use&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Cn&lt;/strong&gt;: Other, Not Assigned (no characters in the file have this property)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;informative-categories&quot;&gt;Informative Categories&lt;/h4&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Lm&lt;/strong&gt;: Letter, Modifier&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lo&lt;/strong&gt;: Letter, Other&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pc&lt;/strong&gt;: Punctuation, Connector&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pd&lt;/strong&gt;: Punctuation, Dash&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ps&lt;/strong&gt;: Punctuation, Open&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pe&lt;/strong&gt;: Punctuation, Close&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pi&lt;/strong&gt;: Punctuation, Initial quote (may behave like Ps or Pe depending on usage)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pf&lt;/strong&gt;: Punctuation, Final quote (may behave like Ps or Pe depending on usage)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Po&lt;/strong&gt;: Punctuation, Other&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sm&lt;/strong&gt;: Symbol, Math&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sc&lt;/strong&gt;: Symbol, Currency&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sk&lt;/strong&gt;: Symbol, Modifier&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;So&lt;/strong&gt;: Symbol, Other&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;As you can see there is quite a lot of categories, some of them are very easy
to understand like “Lu” (Letter, uppercase) and “Ll” (Letter, lowercase) but
some of them are more complex like “Lo” (Letter, other)  and “No” (Number,
other), and this is exactly where the first problem begins.&lt;/p&gt;

&lt;p&gt;Let’s take the unicode character U+00BD(½) as an example. It is quite common
to describe spare parts and is defined as “No”… except that some unicode
libraries consider that this is not a number and return false to
isNumber(unicodeChar) method (e.g., Objective-C).&lt;/p&gt;

&lt;p&gt;In fact the two most used methods, isAlpha(unicodeChar) and
isNumber(unicodeChar), are not directly defined by the Unicode standard and
are subject to interpretation.&lt;/p&gt;

&lt;p&gt;The consequence is that results are not the same across devices/languages! In
our case this is a problem because our compiled index is portable, and we want
to have exactly the same results on different devices/languages.&lt;/p&gt;

&lt;p&gt;However, this is not the only problem! Unicode normalization is also a tricky
topic. The Unicode standard defines a way to decompose characters (Characters
decomposition mapping), for example U+00E0(à) which is decomposed as U+0061(a)
+ U+0300( ̀). But most of the time you do not want a decomposition but a
normalization: get the most basic form of a string (lowercase without accents,
marks, …). This is key to be able to search and compare words. For example,
the normalization of the French word “Hétérogénéité” will be normalized as
“heterogeneite”.&lt;/p&gt;

&lt;p&gt;To compute this normalized form, most people compute the lowercase form of a
word (well defined by the Unicode standard), then compute the decomposed form
and finally remove all the diacritics. However, this is not enough.
Normalization can not always be reduced to just a matter of removing marks.
For example the standard German letter ß is widely used and
replaced/understood as “ss” (you can enter ß in your favorite web search
engine and you will discover that it also search for “ss”). The problem is
that there is no decomposition for “ß” in the Unicode standard because this
letter is not a letter with marks.&lt;/p&gt;

&lt;p&gt;To solve that problem, we need to look in the &lt;a href=&quot;http://unicode.org/repos/cldr-tmp/trunk/diff/supplemental/character_fallback_substitutions.html&quot;&gt;Character Fallback Substitution
table&lt;/a&gt; that is not
part of most of Unicode library implementations. This substitution table
defines that “ß” can be replaced by “ss,”. There are plenty of other examples;
For instance, 0153(œ) and 00E6(æ), letters of the French language, can be
replaced by “oe” and “ae”.&lt;/p&gt;

&lt;p&gt;At the end, this led us to implement our own Unicode library to ensure that
our isAlpha(unicodechar) and isNumber(unicodechar) methods have a unique
behavior on all devices/languages and to implement a normalize(unicodestring)
method that contains character fallback substitution table. By the way our
implementation of normalization is far more efficient because we implemented
it in one step instead of three (lowercase + decomposition + diacritics
removal).&lt;/p&gt;

&lt;p&gt;I hope you found this post useful and gained a better understanding of the
Unicode standard and the limits of standard Unicode libraries. Feel free to
contribute comments or ask for precisions.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Great discussions at LeWeb'12 London</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/03/great-discussions-at-leweb12-london/"/>
   <updated>2012-07-03T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/03/great-discussions-at-leweb12-london</id>
   <content type="html">&lt;p&gt;On June 19 &amp;amp; 20th, I had the chance to participate to &lt;a href=&quot;http://london.leweb.co/&quot;&gt;LeWeb 2012
London&lt;/a&gt; edition. This year theme was “Faster than
Real Time” and we had an impressive list of speakers! But the true value of
LeWeb is elsewhere: It’s in the 1283 people from 52 countries who were present
and with whom you could network!&lt;/p&gt;

&lt;p&gt;They chose &lt;a href=&quot;http://match.presdo.com/&quot;&gt;Presdo Match&lt;/a&gt; to help people meet and
honestly… this tool would benefit from some improvements, especially a
mobile version! Still, I was able to find no fewer than 100 participants
having the “mobile” keyword in their profile and, from there, organize a
handful of meetings. Thanks to all of you who accepted to meet me or whom I
met unplanned, with a special thanks to &lt;a href=&quot;http://hello24.com/&quot;&gt;Paul Ardeleanu&lt;/a&gt;,
&lt;a href=&quot;http://www.linkedin.com/in/goras&quot;&gt;Gora Sudindranath&lt;/a&gt;, &lt;a href=&quot;http://twitter.com/lindseycholmes&quot;&gt;Lindsey C.
Holmes&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/#!/portart&quot;&gt;Marius
Rostad&lt;/a&gt;, &lt;a href=&quot;https://twitter.com/#!/kevinmcdonagh&quot;&gt;Kevin
McDonagh&lt;/a&gt; and &lt;a href=&quot;http://www.alexdelivet.com/&quot;&gt;Alexandre
Delivet&lt;/a&gt; for their precious feedbacks about
Algolia.&lt;/p&gt;

&lt;p&gt;[caption id=”attachment_82” align=”alignright” width=”180”]&lt;a href=&quot;https://blog.algolia.com/wp-
content/uploads/2012/07/citiessuggest-leweb.png&quot;&gt;&lt;img src=&quot;/algoliasearch-jekyll-hyde/assets/citiessuggest-leweb-180x300.png&quot; alt=&quot;Cities Suggest
Demo&quot; /&gt;&lt;/a&gt; Cities Suggest demo @
LeWeb[/caption]&lt;/p&gt;

&lt;p&gt;I had the opportunity to do the very first demonstrations of our instant
suggest lib, and that was both exhilarating and frustrating! We chose to
develop a small proof of concept suggesting city names from anywhere in the
world. Here’s what I learned:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;A demo is better than many words! Even if most people knew what I meant by “google instant suggest”, the demo was key in clarifying our offering.&lt;/li&gt;
  &lt;li&gt;Even if we chose cities because it was easy to demonstrate (thanks to the geonames database), it can be interesting in itself!&lt;/li&gt;
  &lt;li&gt;100ms seemed a pretty fast response time in our initial testing, but it’s actually way too slow to have a smooth user experience.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Over all that was a very good experience, and I came back with a few
improvements to implement (most coming from my own frustration showing the
demo while the feedback was actually very positive!)&lt;/p&gt;

&lt;p&gt;The most important piece of feedback was about the perceived sluggishness of
the app. We decided to implement an asynchronous version of the lib. Beware,
it actually comes with a drawback for our users; It’s significantly more
difficult to integrate. But it did not take long for us to decide it was the
way to go, since the perception of speed is so natural that the benefit far
outweighs the longer integration code. We’ll now work on simplifying it!&lt;/p&gt;

&lt;p&gt;We’ll soon do a post about this demo. In the meantime, stay tuned!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>Svenson has done it!</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/02/paul-has-done-it/"/>
   <updated>2012-07-02T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/02/paul-has-done-it</id>
   <content type="html">&lt;p&gt;Welcome to The Algolia Blog! It’s always difficult to write the first post of
a blog! What should I talk about? The company, the founders, the business, the
culture? And all that knowing that virtually nobody will read except diggers
in a few years (hopefully)!&lt;/p&gt;

&lt;p&gt;Let’s concentrate instead on what we’ll be blogging about. Company news
obviously, but not only. I expect we’ll write quite a few posts about
technology, algorithms, entrepreneurship, marketing, and whatever else we’ll
want to share with you :)&lt;/p&gt;

&lt;p&gt;And most important, feel free to participate in comments or by contacting us
directly. We appreciate your feedback!&lt;/p&gt;

&lt;p&gt;Welcome to the Algolia blog!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>Let's start the adventure</title>
   <link href="https://github.com/svenhutchinson/extensions/2012/07/02/lets-start-the-adventure/"/>
   <updated>2012-07-02T00:00:00+07:00</updated>
   <id>https://github.com/svenhutchinson/extensions/2012/07/02/lets-start-the-adventure</id>
   <content type="html">&lt;p&gt;Welcome to The Algolia Blog! It’s always difficult to write the first post of
a blog! What should I talk about? The company, the founders, the business, the
culture? And all that knowing that virtually nobody will read except diggers
in a few years (hopefully)!&lt;/p&gt;

&lt;p&gt;Let’s concentrate instead on what we’ll be blogging about. Company news
obviously, but not only. I expect we’ll write quite a few posts about
technology, algorithms, entrepreneurship, marketing, and whatever else we’ll
want to share with you :)&lt;/p&gt;

&lt;p&gt;And most important, feel free to participate in comments or by contacting us
directly. We appreciate your feedback!&lt;/p&gt;

&lt;p&gt;Welcome to the Algolia blog!&lt;/p&gt;

</content>
 </entry>
 

</feed>
